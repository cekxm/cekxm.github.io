<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Optical Flow | 计算机视觉 </title> <meta name="author" content="Erkang Chen"> <meta name="description" content="RAFT, SEA-RAFT, Neuflow"> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link defer href="/assets/css/bootstrap-toc.min.css?6f5af0bb9aab25d79b2448143cbeaa88" rel="stylesheet"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://cekxm.github.io/blog/2026/optical_flow/"> <script src="/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>initTheme();</script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> 计算机视觉 </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/">blog </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications </a> </li> <li class="nav-item "> <a class="nav-link" href="/projects/">projects </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="row"> <div class="col-sm-3"> <nav id="toc-sidebar" class="sticky-top"></nav> </div> <div class="col-sm-9"> <div class="post"> <header class="post-header"> <h1 class="post-title">Optical Flow</h1> <p class="post-meta"> Created in January 09, 2026 </p> <p class="post-tags"> <a href="/blog/2026"> <i class="fa-solid fa-calendar fa-sm"></i> 2026 </a> </p> </header> <article class="post-content"> <div id="markdown-content"> <h2 id="raft">RAFT</h2> <p><img src="/images/2026-01-09-optical_flow/image-20260108232610993.png" alt="image-20260108232610993" class="img-fluid" data-zoomable=""></p> <h3 id="核心架构与组成部分">核心架构与组成部分</h3> <p>RAFT 主要由以下三个核心阶段组成：</p> <ul> <li> <strong>特征提取（Feature Extraction）：</strong> <ul> <li>使用一个卷积特征编码器对两帧输入图像进行处理，提取每个像素的特征向量 。</li> <li>此外，还包含一个上下文编码器（Context Encoder），仅从第一帧图像中提取特征，用于后续迭代更新时的补充信息。</li> </ul> </li> <li> <strong>计算视觉相似度（Computing Visual Similarity）：</strong> <ul> <li> <strong>4D 相关体（4D Correlation Volumes）：</strong> 通过计算两帧图像特征向量之间的内积，构建一个包含所有像素对相关性的 4D 体。</li> <li> <strong>相关性金字塔（Correlation Pyramid）：</strong> 对 4D 相关体进行多尺度池化，生成一组不同分辨率的相关性卷。这种设计使模型能同时获取大位移和小位移的信息，且由于保留了高分辨率维度，能更好地捕捉小而快移动物体的运动。</li> </ul> </li> <li> <strong>迭代更新（Iterative Updates）：</strong> <ul> <li> <strong>GRU 单元：</strong> 采用一个基于门控循环单元（GRU）的轻量级更新模块，它通过在相关性金字塔中执行“查表”操作来检索特征，并迭代地更新光流场。</li> <li>与之前常见的“由粗到精”（coarse-to-fine）设计不同，RAFT 始终在固定高分辨率下维护和更新单一的光流场。</li> </ul> </li> </ul> <p>在 RAFT（Recurrent All-Pairs Field Transforms）光流估计方法中，<strong>不需要</strong>像传统的“由粗到精”（coarse-to-fine）方法那样对图像或特征图进行显式的 Warp（重采样/扭曲）操作 。</p> <h2 id="sea-raft">SEA-RAFT</h2> <p><img src="/images/2026-01-09-optical_flow/image-20260108233119443.png" alt="image-20260108233119443" class="img-fluid" data-zoomable=""></p> <p>SEA-RAFT 旨在通过对原始 RAFT 架构的优化，实现更简单（Simple）、更高效（Efficient）和更准确（Accurate）的光流估计 2。其核心改进包括引入了新的损失函数、直接回归初始光流、刚体运动预训练以及架构简化。</p> <h3 id="核心改进与技术特点">核心改进与技术特点</h3> <ul> <li> <strong>混合拉普拉斯损失（Mixture of Laplace Loss）：</strong> <ul> <li>SEA-RAFT 摒弃了标准 RAFT 使用的 \(L_1\) 损失，转而训练网络预测混合拉普拉斯分布的参数。</li> <li>该设计允许模型量化预测的不确定性，特别是在重度遮挡导致的歧义情况下，通过不同的混合分量来应对，从而显著减少过拟合并提升泛化能力。</li> </ul> </li> <li> <strong>直接回归初始光流（Directly Regressed Initial Flow）：</strong> <ul> <li>原始 RAFT 将光流初始化为零，这往往偏离真实值较远，需要大量迭代才能收敛。</li> <li>SEA-RAFT 通过复用现有的上下文编码器（Context Encoder），直接根据输入的双帧图像预测一个初始光流估计。</li> <li>这一简单的改变以极低的额外开销大幅减少了所需的迭代次数，提升了效率。</li> </ul> </li> <li> <strong>大尺度刚体运动预训练（Rigid-Flow Pre-Training）：</strong> <ul> <li>模型首先在 TartanAir 数据集上进行预训练。虽然该数据集仅包含由相机运动产生的静态场景位移（刚体运动），但其高度的真实感和场景多样性显著增强了模型的跨数据集泛化能力。</li> </ul> </li> <li> <strong>架构简化（Architectural Simplifications）：</strong> <ul> <li> <strong>标准化主干：</strong> 将 RAFT 原有的定制化编码器替换为标准的 ResNet 模型，使得训练更加稳定。</li> <li>高效 RNN：** 将原始的卷积 GRU 替换为由 ConvNext 模块组成的简单 RNN，这使得模型更容易集成新的神经构建块，且更易于扩展到大规模数据集。</li> </ul> </li> </ul> <h2 id="flowseek">FlowSeek</h2> <p>M. Poggi and F. Tosi, “FlowSeek: Optical Flow Made Easier with Depth Foundation Models and Motion Bases,” in Proc. IEEE/CVF Int. Conf. Comput. Vis. (ICCV), Oct. 2025, pp. 5667-5679.</p> <p><img src="/images/2026-01-09-optical_flow/image-20260109130959464.png" alt="image-20260109130959464" class="img-fluid" data-zoomable=""></p> <p>FlowSeek 是一种在 2025 年 ICCV 上提出的新型光流估计方法，其核心理念是通过引入<strong>深度基础模型（Depth Foundation Models）</strong>和<strong>经典运动基底（Motion Bases）</strong>来简化光流任务的训练并提升其泛化能力。</p> <p>以下是 FlowSeek 方法的详细介绍：</p> <h3 id="1-核心设计理念融合三大领域">1. 核心设计理念：融合三大领域</h3> <p>FlowSeek 的架构设计处于以下三个领域的交汇点：</p> <ul> <li> <strong>先进光流架构：</strong> 以 <strong>SEA-RAFT</strong> 作为骨干网络（Backbone），继承了其混合拉普拉斯损失和高效的迭代更新机制。</li> <li> <strong>深度基础模型 (VFMs)：</strong> 集成了如 <strong>Depth Anything v2</strong> 等在大规模数据集上预训练的模型，利用其丰富的几何和语义先验信息。</li> <li> <strong>经典运动参数化：</strong> 引入了 30 年前经典的低维运动基底理论，将相机运动诱导的光流简化为 6 个自由度的线性组合。</li> </ul> <h3 id="2-详细架构组成">2. 详细架构组成</h3> <p>FlowSeek 在 SEA-RAFT 的基础上增加了以下关键模块：</p> <ul> <li> <strong>特征增强：</strong> 利用深度基础模型的解码器特征 \(\Phi\) 增强原始的卷积特征 \(F\)，从而构建更具几何感知力的 4D 相关体。</li> <li> <strong>BasesNet（基底网络）：</strong> 核心创新模块。它根据预测的逆深度图 \(D_0\) 计算出 8 个运动基底矢量（包括平移和旋转分量），并提取运动特征 \(H_B\)。</li> <li> <strong>上下文增强：</strong> 将预测的深度图与原始图像一同输入 ContextNet，以提取更强的上下文特征 \(C\) 和初始隐藏状态 \(H^0\) 。</li> <li> <strong>迭代更新：</strong> 改进后的 UpdNet 在迭代过程中同时参考相关性查找结果、隐藏状态以及来自运动基底的特征。</li> </ul> <h3 id="3-主要优势与改进点">3. 主要优势与改进点</h3> <ul> <li> <strong>极低的硬件成本：</strong> FlowSeek 仅需 <strong>单张消费级 GPU（如 RTX 3090）</strong> 即可完成训练，相比于 SEA-RAFT 等方法所需的 8 张 GPU，硬件预算降低了约 8 倍。</li> <li> <strong>卓越的泛化能力：</strong> 通过利用深度先验，FlowSeek 在未见过的场景（如 Sintel 和 KITTI）中表现出极强的 Zero-shot 泛化性能，比 SEA-RAFT 提升了 10% 到 15%。</li> <li> <strong>更细腻的细节表现：</strong> 深度基础模型的引入使得光流预测在物体边缘和精细结构上更加准确，解决了传统模型在跨域测试时细节缺失的问题。</li> </ul> <table> <thead> <tr> <th><strong>特性</strong></th> <th><strong>SEA-RAFT</strong></th> <th><strong>FlowSeek</strong></th> </tr> </thead> <tbody> <tr> <td><strong>先验知识</strong></td> <td>仅依赖图像特征</td> <td>图像特征 + 深度图 + 运动基底</td> </tr> <tr> <td><strong>硬件需求</strong></td> <td>通常需要 8x 3090 GPU</td> <td><strong>1x 3090 GPU</strong></td> </tr> <tr> <td><strong>性能 (Spring EPE)</strong></td> <td>~4.79 (S版)</td> <td><strong>~3.31 (L版)</strong></td> </tr> <tr> <td><strong>关键改进</strong></td> <td>混合损失、直接回归初始流</td> <td><strong>基础模型特征融合、BasesNet</strong></td> </tr> <tr> <td><strong>复杂度</strong></td> <td>较低</td> <td>较高（需运行额外的深度模型）</td> </tr> </tbody> </table> <h2 id="neuflow-v2">NeuFlow-v2</h2> <p>Z. Zhang, A. Gupta, H. Jiang, and H. Singh, “NeuFlow v2: Push High-Efficiency Optical Flow To the Limit,” in 2024 IEEE/RSJ Int. Conf. Intell. Robots Syst. (IROS), 2024, doi: 10.1109/IROS58592.2024.10802353.</p> <p><img src="/images/2026-01-09-optical_flow/image-20260109130930368.png" alt="image-20260109130930368" class="img-fluid" data-zoomable=""></p> <p><strong>NeuFlow-V2</strong>（全称：NeuFlow v2: Push High-Efficiency Optical Flow To the Limit）是 2024 年提出的一款专为<strong>边缘设备和实时机器人应用</strong>设计的高效光流估计算法。</p> <p>它在 NeuFlow-V1 的基础上进行了深度优化，核心目标是：在保持与 SOTA（当前最佳）方法相当精度的同时，极大地降低计算开销。</p> <h3 id="1-核心技术创新点">1. 核心技术创新点</h3> <ul> <li> <strong>极简骨干网络 (Simple Backbone)：</strong> <ul> <li>与传统方法（如 RAFT 使用较重的卷积网络）不同，NeuFlow-V2 认为光流任务更依赖<strong>低级特征</strong>而非高级语义。</li> <li>它直接从不同尺度的图像金字塔（1/2, 1/4, 1/8）中提取特征，每个卷积块仅包含两层卷积。这种设计大幅减少了计算量，同时保留了更多的纹理细节。</li> </ul> </li> <li> <strong>全局匹配与交叉注意力 (Cross-Attention &amp; Global Matching)：</strong> <ul> <li>为了处理大位移运动，它在 1/16 低分辨率尺度上引入了 <strong>Cross-Attention</strong>。</li> <li>这增强了图像间特征的判别性，通过全局匹配计算出一个初始光流，为后续迭代提供一个良好的起点。</li> </ul> </li> <li> <strong>轻量级 RNN 迭代模块：</strong> <ul> <li> <strong>抛弃 GRU/LSTM：</strong> 原始 RAFT 使用的 GRU 单元计算相对复杂。NeuFlow-V2 使用基于简单卷积层的 RNN 结构来整合隐藏状态、当前光流和 Warp 后的相关性特征。</li> <li> <strong>数值稳定性：</strong> 引入了 <code class="language-plaintext highlighter-rouge">HardTanh</code> 函数来约束隐藏状态的范围，解决了简单 RNN 容易出现的梯度消失或爆炸问题。</li> </ul> </li> <li> <strong>多尺度特征融合：</strong> <ul> <li>通过将 1/16 尺度的全局上下文信息与 1/8 尺度的局部细节特征进行融合，弥补了轻量级骨干网络感受野较小的缺点。</li> </ul> </li> </ul> <h3 id="2-性能表现-效率王者">2. 性能表现 (效率王者)</h3> <p>NeuFlow-V2 的最大亮点在于其极致的运行效率，这使它成为目前在嵌入式硬件上表现最好的模型之一：</p> <table> <thead> <tr> <th><strong>特性</strong></th> <th><strong>表现说明</strong></th> </tr> </thead> <tbody> <tr> <td><strong>推理速度</strong></td> <td>在 <strong>NVIDIA Jetson Orin Nano</strong> 上可达到 <strong>20+ FPS</strong> (512x384 分辨率)。</td> </tr> <tr> <td><strong>加速比</strong></td> <td>相比于 RAFT 或 GMFlow 等主流方法，实现了 <strong>10x - 70x</strong> 的加速。</td> </tr> <tr> <td><strong>精度水平</strong></td> <td>在 Sintel 和 KITTI 基准测试中，精度接近 SEA-RAFT 等 SOTA 模型，但计算成本极低。</td> </tr> <tr> <td><strong>跨域泛化</strong></td> <td>尽管模型轻量，但其设计确保了在真实世界场景（非训练集）中依然保持稳健的预测效果。</td> </tr> </tbody> </table> <h3 id="3-与-raft--sea-raft-的区别">3. 与 RAFT / SEA-RAFT 的区别</h3> <table> <thead> <tr> <th><strong>维度</strong></th> <th><strong>RAFT / SEA-RAFT</strong></th> <th><strong>NeuFlow-V2</strong></th> </tr> </thead> <tbody> <tr> <td><strong>主要目标</strong></td> <td>追求最高精度（科研/离线处理）</td> <td><strong>追求极致实时性（边缘端/机器人）</strong></td> </tr> <tr> <td><strong>迭代核心</strong></td> <td>复杂的 ConvGRU 单元</td> <td>简单的 CNN-based RNN</td> </tr> <tr> <td><strong>匹配方式</strong></td> <td>4D 相关体 + 局部查找</td> <td>全局匹配 (1/16) + 局部细化</td> </tr> <tr> <td><strong>应用场景</strong></td> <td>服务器端视频处理</td> <td><strong>无人机导航、移动机器人 SLAM</strong></td> </tr> </tbody> </table> <h2 id="对比">对比</h2> <p>FlowSeek 和 NeuFlow-V2 代表了光流估计领域的两个极端：<strong>FlowSeek 追求极致的泛化精度与细节还原</strong>（利用基础模型先验），而 <strong>NeuFlow-V2 追求极致的计算效率与嵌入式部署性能</strong>。</p> <p>以下是两者的详细对比分析：</p> <hr> <h3 id="1-epe-误差精度与泛化能力">1. EPE 误差（精度与泛化能力）</h3> <p><strong>结论：FlowSeek 在绝对精度和零样本（Zero-shot）泛化能力上显著领先。</strong></p> <ul> <li> <strong>FlowSeek (高精度标杆)：</strong> <ul> <li> <strong>核心优势：</strong> 它引入了“深度基础模型”（如 Depth Anything v2），使模型具备了强大的空间几何感知能力。</li> <li> <strong>性能表现：</strong> 在 Sintel Final 和 KITTI 数据集上，其精度比之前的 SOTA 模型 SEA-RAFT 提升了约 <strong>10%-15%</strong>。在 Spring 这种复杂数据集上，其 EPE 表现极其出色（L 版本可达到约 <strong>3.31</strong>）。</li> <li> <strong>细节还原：</strong> 能够精确捕捉物体边缘，解决了很多模型在处理细小物体或快速运动时的模糊问题。</li> </ul> </li> <li> <strong>NeuFlow-V2 (高效率平衡)：</strong> <ul> <li> <strong>核心优势：</strong> 在极低功耗下维持了“可接受”的高精度。</li> <li> <strong>性能表现：</strong> 其精度接近但略逊于 SEA-RAFT 和 RAFT。在 Sintel 数据集上的 EPE 通常在 <strong>2.0-3.0</strong> 左右（取决于具体测试子集和训练阶段）。</li> <li> <strong>局限性：</strong> 为了换取速度，它使用了极简的骨干网络，在处理极复杂场景（如重度遮挡或光照剧烈变化）时，精度上限不如 FlowSeek。</li> </ul> </li> </ul> <hr> <h3 id="2-计算量与效率计算开销">2. 计算量与效率（计算开销）</h3> <p><strong>结论：NeuFlow-V2 在推理速度和轻量化方面具有压倒性优势；FlowSeek 在训练成本上表现优异。</strong></p> <ul> <li> <strong>NeuFlow-V2 (端侧王者)：</strong> <ul> <li> <strong>推理速度：</strong> 专为边缘计算设计。在 <strong>Jetson Orin Nano</strong> 上能跑到 <strong>20+ FPS</strong>，而同类高精度模型通常只有 1-2 FPS 甚至更低。</li> <li> <strong>架构极简：</strong> 使用简单的 CNN-RNN 替代了复杂的 GRU，去除了冗余的特征提取层，计算量（FLOPs）远低于其他模型。</li> <li> <strong>部署友好：</strong> 它是目前机器人和无人机领域实时光流估计的首选。</li> </ul> </li> <li> <strong>FlowSeek (训练高效，推理较重)：</strong> <ul> <li> <strong>训练成本：</strong> 最大的卖点之一是<strong>单卡可训</strong>。传统 SOTA 模型往往需要 8 张 A100/H100，而 FlowSeek 仅需一张 RTX 3090 即可完成训练。</li> <li> <strong>推理开销：</strong> 尽管在光流分支上进行了优化，但由于其依赖于外部的“深度基础模型”提供先验特征，推理时需要同时运行深度模型和光流模型，总体的计算延迟明显高于 NeuFlow-V2。</li> </ul> </li> </ul> <hr> <h3 id="3-综合对比总结">3. 综合对比总结</h3> <table> <thead> <tr> <th><strong>维度</strong></th> <th><strong>FlowSeek</strong></th> <th><strong>NeuFlow-V2</strong></th> </tr> </thead> <tbody> <tr> <td><strong>主要定位</strong></td> <td>追求最高泛化精度（科研、离线分析）</td> <td>追求极致实时性（机器人、端侧部署）</td> </tr> <tr> <td><strong>EPE 表现</strong></td> <td><strong>极佳 (SOTA 级别)</strong></td> <td>优秀 (接近 SOTA，但略有妥协)</td> </tr> <tr> <td><strong>硬件需求</strong></td> <td>单张 3090 可训，推理需较强 GPU</td> <td><strong>Jetson 等嵌入式设备即可流畅运行</strong></td> </tr> <tr> <td><strong>核心创新点</strong></td> <td>深度基础模型 + 运动基底 (Motion Bases)</td> <td>极简骨干网络 + 轻量 RNN + 全局匹配</td> </tr> <tr> <td><strong>适用场景</strong></td> <td>高精度视频合成、运动捕捉、电影特效</td> <td><strong>无人机避障、SLAM、增强现实 (AR)</strong></td> </tr> </tbody> </table> </div> </article> <br> <hr> <br> <ul class="list-disc pl-8"></ul> <h2 class="text-3xl font-semibold mb-4 mt-12">Enjoy Reading This Article?</h2> <p class="mb-2">Here are some more articles you might like to read next:</p> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2026/Teaching-Tailored-to-Talent/">Teaching Tailored To Talent</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2025/VINS-and-ESVO2/">Vins And Esvo2</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2025/dino/">DINO 如何用于密集预测</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2025/3dtasks/">3D 任务：SFM, MVS, NVS, VO, VIO, SLAM</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2025/matplotlib%E8%BE%93%E5%87%BA%E4%B8%AD%E6%96%87/">Matplotlib输出中文</a> </li> </div> </div> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2026 Erkang Chen. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script defer src="/assets/js/bootstrap-toc.min.js?c82ff4de8b0955d6ff14f5b05eed7eb6"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>addBackToTop();</script> <script type="module" src="/assets/js/search/ninja-keys.min.js?a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script>let searchTheme=determineComputedTheme();const ninjaKeys=document.querySelector("ninja-keys");"dark"===searchTheme?ninjaKeys.classList.add("dark"):ninjaKeys.classList.remove("dark");const openSearchModal=()=>{const e=$("#navbarNav");e.hasClass("show")&&e.collapse("hide"),ninjaKeys.open()};</script> <script>const ninja=document.querySelector("ninja-keys");ninja.data=[{id:"nav-about",title:"about",section:"Navigation",handler:()=>{window.location.href="/"}},{id:"nav-blog",title:"blog",description:"",section:"Navigation",handler:()=>{window.location.href="/blog/"}},{id:"nav-publications",title:"publications",description:"publications by categories in reversed chronological order. generated by jekyll-scholar.",section:"Navigation",handler:()=>{window.location.href="/publications/"}},{id:"nav-projects",title:"projects",description:"A growing collection of your cool projects.",section:"Navigation",handler:()=>{window.location.href="/projects/"}},{id:"post-optical-flow",title:"Optical Flow",description:"RAFT, SEA-RAFT, Neuflow",section:"Posts",handler:()=>{window.location.href="/blog/2026/optical_flow/"}},{id:"post-teaching-tailored-to-talent",title:"Teaching Tailored To Talent",description:"Prompt, Depth-Anything, Diffusion, Image Restoration",section:"Posts",handler:()=>{window.location.href="/blog/2026/Teaching-Tailored-to-Talent/"}},{id:"post-vins-and-esvo2",title:"Vins And Esvo2",description:"VINS, ESVO, SFM",section:"Posts",handler:()=>{window.location.href="/blog/2025/VINS-and-ESVO2/"}},{id:"post-dino-\u5982\u4f55\u7528\u4e8e\u5bc6\u96c6\u9884\u6d4b",title:"DINO \u5982\u4f55\u7528\u4e8e\u5bc6\u96c6\u9884\u6d4b",description:"\u5982\u4f55\u4f7f\u7528DINO, DPT, RoPE",section:"Posts",handler:()=>{window.location.href="/blog/2025/dino/"}},{id:"post-3d-\u4efb\u52a1-sfm-mvs-nvs-vo-vio-slam",title:"3D \u4efb\u52a1\uff1aSFM, MVS, NVS, VO, VIO, SLAM",description:"\u591a\u89c6\u89d2\u51e0\u4f55\uff0c\u65b0\u89c6\u89d2\u751f\u6210",section:"Posts",handler:()=>{window.location.href="/blog/2025/3dtasks/"}},{id:"post-matplotlib\u8f93\u51fa\u4e2d\u6587",title:"Matplotlib\u8f93\u51fa\u4e2d\u6587",description:"\u7b80\u8981\u4ecb\u7ecd",section:"Posts",handler:()=>{window.location.href="/blog/2025/matplotlib%E8%BE%93%E5%87%BA%E4%B8%AD%E6%96%87/"}},{id:"post-mamba",title:"Mamba",description:"\u7b80\u8981\u4ecb\u7ecd",section:"Posts",handler:()=>{window.location.href="/blog/2025/mamba/"}},{id:"post-flow",title:"Flow",description:"\u7b80\u8981\u4ecb\u7ecd",section:"Posts",handler:()=>{window.location.href="/blog/2025/flow/"}},{id:"post-diffusion",title:"Diffusion",description:"\u7b80\u8981\u4ecb\u7ecd",section:"Posts",handler:()=>{window.location.href="/blog/2025/diffusion/"}},{id:"post-nerf-and-gaussian-splatting",title:"NeRF and Gaussian Splatting",description:"Gaussian Splatting, NeRF, Alpha-blending, Point-Based Rendering, Jacobian",section:"Posts",handler:()=>{window.location.href="/blog/2025/gaussianSplatting/"}},{id:"post-colmap",title:"COLMAP",description:"SFM",section:"Posts",handler:()=>{window.location.href="/blog/2025/sfm-mvs-rendering/"}},{id:"post-\u51b2\u6fc0\u4fe1\u53f7\u7684\u5c3a\u5ea6\u53d8\u6362",title:"\u51b2\u6fc0\u4fe1\u53f7\u7684\u5c3a\u5ea6\u53d8\u6362",description:"this is what included images could look like",section:"Posts",handler:()=>{window.location.href="/blog/2025/impulse/"}},{id:"post-\u4fe1\u53f7\u4e0e\u7cfb\u7edf\u8bfe\u7a0b\u7684\u6570\u5b66\u77e5\u8bc6",title:"\u4fe1\u53f7\u4e0e\u7cfb\u7edf\u8bfe\u7a0b\u7684\u6570\u5b66\u77e5\u8bc6",description:"this is what included images could look like",section:"Posts",handler:()=>{window.location.href="/blog/2025/math/"}},{id:"post-fisheye",title:"Fisheye",description:"\u7b80\u8981\u4ecb\u7ecd",section:"Posts",handler:()=>{window.location.href="/blog/2024/fisheye/"}},{id:"post-montecarlo",title:"Montecarlo",description:"\u7b80\u8981\u4ecb\u7ecd",section:"Posts",handler:()=>{window.location.href="/blog/2024/MonteCarlo/"}},{id:"post-\u5c0f\u6ce2\u5206\u6790",title:"\u5c0f\u6ce2\u5206\u6790",description:"\u7b80\u8981\u4ecb\u7ecd",section:"Posts",handler:()=>{window.location.href="/blog/2024/%E5%B0%8F%E6%B3%A2%E5%88%86%E6%9E%90/"}},{id:"post-lifeifei",title:"Lifeifei",description:"\u7b80\u8981\u4ecb\u7ecd",section:"Posts",handler:()=>{window.location.href="/blog/2024/Lifeifei/"}},{id:"post-orgmode",title:"Orgmode",description:"\u7b80\u8981\u4ecb\u7ecd",section:"Posts",handler:()=>{window.location.href="/blog/2024/orgmode/"}},{id:"post-python\u8fd0\u884c\u811a\u672c\u6216\u6a21\u5757",title:"Python\u8fd0\u884c\u811a\u672c\u6216\u6a21\u5757",description:"\u7b80\u8981\u4ecb\u7ecd",section:"Posts",handler:()=>{window.location.href="/blog/2024/Python%E8%BF%90%E8%A1%8C%E8%84%9A%E6%9C%AC%E6%88%96%E6%A8%A1%E5%9D%97/"}},{id:"post-proximal",title:"Proximal",description:"\u7b80\u8981\u4ecb\u7ecd",section:"Posts",handler:()=>{window.location.href="/blog/2024/proximal/"}},{id:"post-visualtransformer",title:"Visualtransformer",description:"\u7b80\u8981\u4ecb\u7ecd",section:"Posts",handler:()=>{window.location.href="/blog/2024/VisualTransformer/"}},{id:"post-pytorch-note",title:"Pytorch Note",description:"\u7b80\u8981\u4ecb\u7ecd",section:"Posts",handler:()=>{window.location.href="/blog/2024/Pytorch-note/"}},{id:"post-android-opencv-ndk",title:"Android Opencv Ndk",description:"\u7b80\u8981\u4ecb\u7ecd",section:"Posts",handler:()=>{window.location.href="/blog/2024/android-opencv-ndk/"}},{id:"post-repvgg",title:"Repvgg",description:"\u7b80\u8981\u4ecb\u7ecd",section:"Posts",handler:()=>{window.location.href="/blog/2024/RepVGG/"}},{id:"post-popularlibrary",title:"Popularlibrary",description:"\u7b80\u8981\u4ecb\u7ecd",section:"Posts",handler:()=>{window.location.href="/blog/2024/popularLibrary/"}},{id:"post-\u5148\u8fdb\u7684\u5b66\u4e60\u65b9\u6cd5",title:"\u5148\u8fdb\u7684\u5b66\u4e60\u65b9\u6cd5",description:"\u7b80\u8981\u4ecb\u7ecd",section:"Posts",handler:()=>{window.location.href="/blog/2024/%E5%85%88%E8%BF%9B%E7%9A%84%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/"}},{id:"post-one-stage-detection",title:"One Stage Detection",description:"\u7b80\u8981\u4ecb\u7ecd",section:"Posts",handler:()=>{window.location.href="/blog/2024/one-stage-detection/"}},{id:"post-polarization",title:"Polarization",description:"\u7b80\u8981\u4ecb\u7ecd",section:"Posts",handler:()=>{window.location.href="/blog/2024/polarization/"}},{id:"post-vae-vqvae-vagan",title:"Vae Vqvae Vagan",description:"\u7b80\u8981\u4ecb\u7ecd",section:"Posts",handler:()=>{window.location.href="/blog/2024/vae-vqvae-vagan/"}},{id:"post-multiple-object-tracking",title:"Multiple Object Tracking",description:"\u7b80\u8981\u4ecb\u7ecd",section:"Posts",handler:()=>{window.location.href="/blog/2024/Multiple-Object-Tracking/"}},{id:"post-\u77e9\u9635",title:"\u77e9\u9635",description:"Matrix",section:"Posts",handler:()=>{window.location.href="/blog/2024/Matrix/"}},{id:"post-typora-and-jekyll",title:"Typora and Jekyll",description:"this is what included images could look like",section:"Posts",handler:()=>{window.location.href="/blog/2024/images/"}},{id:"news-a-simple-inline-announcement",title:"A simple inline announcement.",description:"",section:"News"},{id:"news-a-long-announcement-with-details",title:"A long announcement with details",description:"",section:"News",handler:()=>{window.location.href="/news/announcement_2/"}},{id:"news-a-simple-inline-announcement-with-markdown-emoji-sparkles-smile",title:'A simple inline announcement with Markdown emoji! <img class="emoji" title=":sparkles:" alt=":sparkles:" src="https://github.githubassets.com/images/icons/emoji/unicode/2728.png" height="20" width="20"> <img class="emoji" title=":smile:" alt=":smile:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f604.png" height="20" width="20">',description:"",section:"News"},{id:"projects-project-1",title:"project 1",description:"with background image",section:"Projects",handler:()=>{window.location.href="/projects/1_project/"}},{id:"projects-project-2",title:"project 2",description:"a project with a background image and giscus comments",section:"Projects",handler:()=>{window.location.href="/projects/2_project/"}},{id:"projects-project-3-with-very-long-name",title:"project 3 with very long name",description:"a project that redirects to another website",section:"Projects",handler:()=>{window.location.href="/projects/3_project/"}},{id:"projects-project-4",title:"project 4",description:"another without an image",section:"Projects",handler:()=>{window.location.href="/projects/4_project/"}},{id:"projects-project-5",title:"project 5",description:"a project with a background image",section:"Projects",handler:()=>{window.location.href="/projects/5_project/"}},{id:"projects-project-6",title:"project 6",description:"a project with no image",section:"Projects",handler:()=>{window.location.href="/projects/6_project/"}},{id:"projects-project-7",title:"project 7",description:"with background image",section:"Projects",handler:()=>{window.location.href="/projects/7_project/"}},{id:"projects-project-8",title:"project 8",description:"an other project with a background image and giscus comments",section:"Projects",handler:()=>{window.location.href="/projects/8_project/"}},{id:"projects-project-9",title:"project 9",description:"another project with an image \ud83c\udf89",section:"Projects",handler:()=>{window.location.href="/projects/9_project/"}},{id:"socials-email",title:"Send email",section:"Socials",handler:()=>{window.open("mailto:%63%65%6B%78%6D@%71%71.%63%6F%6D","_blank")}},{id:"socials-google-scholar",title:"Google Scholar",section:"Socials",handler:()=>{window.open("https://scholar.google.com/citations?user=hWo1RTsAAAAJ","_blank")}},{id:"light-theme",title:"Change theme to light",description:"Change the theme of the site to Light",section:"Theme",handler:()=>{setThemeSetting("light")}},{id:"dark-theme",title:"Change theme to dark",description:"Change the theme of the site to Dark",section:"Theme",handler:()=>{setThemeSetting("dark")}},{id:"system-theme",title:"Use system default theme",description:"Change the theme of the site to System Default",section:"Theme",handler:()=>{setThemeSetting("system")}}];</script> <script src="/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> </body> </html>