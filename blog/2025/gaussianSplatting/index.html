<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> NeRF and Gaussian Splatting | 计算机视觉 </title> <meta name="author" content="Erkang Chen"> <meta name="description" content="Gaussian Splatting, NeRF, Alpha-blending, Point-Based Rendering, Jacobian"> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link defer href="/assets/css/bootstrap-toc.min.css?6f5af0bb9aab25d79b2448143cbeaa88" rel="stylesheet"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://cekxm.github.io/blog/2025/gaussianSplatting/"> <script src="/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>initTheme();</script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> 计算机视觉 </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/">blog </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications </a> </li> <li class="nav-item "> <a class="nav-link" href="/projects/">projects </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="row"> <div class="col-sm-3"> <nav id="toc-sidebar" class="sticky-top"></nav> </div> <div class="col-sm-9"> <div class="post"> <header class="post-header"> <h1 class="post-title">NeRF and Gaussian Splatting</h1> <p class="post-meta"> Created in December 25, 2025 </p> <p class="post-tags"> <a href="/blog/2025"> <i class="fa-solid fa-calendar fa-sm"></i> 2025 </a>   ·   <a href="/blog/tag/cv"> <i class="fa-solid fa-hashtag fa-sm"></i> cv,</a>   <a href="/blog/tag/math"> <i class="fa-solid fa-hashtag fa-sm"></i> math</a> </p> </header> <article class="post-content"> <div id="markdown-content"> <p>参考资料：</p> <p>[1] https://towardsdatascience.com/a-comprehensive-overview-of-gaussian-splatting-e7d570081362/</p> <p>[2] B. Kerbl, G. Kopanas, T. Leimkühler, and G. Drettakis, “3D Gaussian splatting for real-time radiance field rendering,” <em>ACM Transactions on Graphics (TOG)</em>, vol. 42, no. 4, pp. 1-14, 2023.</p> <p>代码：</p> <p>[1] <a href="https://github.com/yzslab/gaussian-splatting-lightning" rel="external nofollow noopener" target="_blank">GitHub - yzslab/gaussian-splatting-lightning: A 3D Gaussian Splatting framework with various derived algorithms and an interactive web viewer</a></p> <p>[2] <a href="https://github.com/nerfstudio-project/gsplat" rel="external nofollow noopener" target="_blank">GitHub - nerfstudio-project/gsplat: CUDA accelerated rasterization of gaussian splatting</a>: gsplat is an open-source library for CUDA accelerated rasterization of gaussians with python bindings.</p> <h2 id="point-based-renderingradiance-fieldsgaussian-splatting">Point-Based Rendering，Radiance Fields，Gaussian Splatting</h2> <h3 id="1-技术演进关系从连续场到离散点到球">1. 技术演进关系：从“连续场”到“离散点”，到“球”</h3> <ul> <li> <strong>NeRF (2020):</strong> 采用的是<strong>体渲染 (Volume Rendering)</strong>。它像是在计算光线穿过一片“连续雾气”时的颜色积累。虽然效果好，但每渲染一个像素都要采样数百个点并运行神经网络，速度极慢。</li> <li> <strong>Point-based Rendering (早期):</strong> 传统的基于点的渲染通常只处理离散的像素点。只用离散点有空洞、aliasing 等问题。关于高质量<strong>基于点的渲染（Point-based Rendering）</strong>的开创性工作通过‘<strong>喷溅（Splatting）</strong>’具有大于像素范围的点基元（如圆盘、椭圆盘、椭球体或面元 Surfel）解决了这些问题。</li> <li> <strong>3D Gaussian Splatting (2023):</strong> 它借鉴了 NeRF 的<strong>辐射场（Radiance Field）</strong>概念，但抛弃了昂贵的体渲染采样。它改用一种名为 <strong>Point-based Alpha-blending</strong> 的方案，将场景表示为数百万个“3D 高斯椭球体”。</li> </ul> <hr> <h3 id="2-核心数学联系alpha-blending-是共同语言">2. 核心数学联系：Alpha-blending 是共同语言</h3> <p>无论是 NeRF 还是 3DGS，最终合成像素颜色的数学公式几乎是一样的。对于光线上的 \(N\) 个点，其颜色 \(C\) 的计算公式通常表示为：</p> \[C = \sum_{i=1}^{N} T_i \alpha_i c_i\] <p>其中：</p> <ul> <li>\(c_i\) 是第 \(i\) 个点的颜色。</li> <li>\(\alpha_i\) 是该点的不透明度（Opacity）。</li> <li>\(T_i\) 是累积透射率（前面所有点遮挡后剩下的光强）。</li> </ul> <h2 id="alpha">Alpha</h2> <p>在计算机图形学（包括 NeRF 和 3D Gaussian Splatting）中，\(\alpha\) 通常被定义为<strong>不透明度（Opacity）</strong>。</p> <p>虽然我们常说 \(\alpha\) 代表“透明度”，但从数学定义和计算逻辑上来看，它衡量的是物体“有多实”或者说“遮挡光线的能力”。</p> <h3 id="1-核心定义">1. 核心定义</h3> <ul> <li> <strong>\(\alpha = 1\)：</strong> 完全<strong>不透明</strong>（Opaque）。光线完全无法穿过，背景完全被遮挡。</li> <li> <strong>\(\alpha = 0\)：</strong> 完全<strong>透明</strong>（Transparent）。光线无阻碍穿过，物体完全不可见。</li> <li> <strong>中间值：</strong> 半透明。例如 \(\alpha = 0.5\) 表示该点吸收/贡献了 50% 的光，剩下的 50% 穿过去看背景。</li> </ul> <blockquote> <p>数学公式中的直观体现：</p> <p>在混合公式 \(C = \alpha \cdot C_{src} + (1 - \alpha) \cdot C_{bg}\) 中：</p> <ul> <li>\(\alpha\) 是<strong>源颜色</strong>（物体本身）的权重。</li> <li>\((1 - \alpha)\) 才是<strong>背景颜色</strong>透过来的比例（即真正的透明度 \(Transparency\)）。</li> </ul> </blockquote> <hr> <h3 id="2-在-3d-gaussian-splatting-3dgs-中的含义">2. 在 3D Gaussian Splatting (3DGS) 中的含义</h3> <p>在 3DGS 中，每个高斯球都有一个学习到的 \(\alpha\) 值。这个值在渲染时起到了两个关键作用：</p> <ol> <li> <strong>贡献颜色：</strong> 它决定了这个高斯点对最终像素颜色贡献了多少。</li> <li> <strong>遮挡（Occlusion）：</strong> 它决定了光线在穿过这个点后，还有多少能量能够到达后面的点。 <ul> <li>如果前面的点 \(\alpha=1\)，光线就被“吸干”了，后面的点即使再亮也看不见。这种累积的效果在论文中被称为<strong>累积透射率（Accumulated Transmittance）</strong>。</li> </ul> </li> </ol> <h3 id="3-名词辨析">3. 名词辨析</h3> <p>虽然在口语中经常混用，但在查阅文献或编写代码时请记住：</p> <ul> <li> <strong>\(\alpha\) (Alpha):</strong> 不透明度 (Opacity)。</li> <li> <strong>\(1 - \alpha\):</strong> 透明度 (Transparency / Transmittance)。</li> </ul> <p><strong>有趣的事实：</strong> 在 3DGS 的训练过程中，如果一个高斯点的 \(\alpha\) 变得非常小（比如接近 0），算法会认为这个点“没什么用”并将其<strong>销毁（Pruning）</strong>，从而优化显存。</p> <h2 id="nerf">NeRF</h2> <p><strong>NeRF</strong>（Neural Radiance Fields，神经辐射场）是 2020 年由 Google Research 团队提出的一种革命性技术，它彻底改变了计算机视觉中<strong>三维重建</strong>和<strong>新视角合成（New View Synthesis）</strong>的方法。</p> <p>简单来说，NeRF 的核心思想是：<strong>用一个神经网络来存储和表示整个三维场景。</strong></p> <hr> <h3 id="1-核心工作原理">1. 核心工作原理</h3> <p>NeRF 将三维场景建模为一个连续的<strong>体积函数</strong>。它的输入和输出非常简洁：</p> <ul> <li> <strong>输入：</strong> 一个五维向量，包括空间坐标 \((x, y, z)\) 和观察视角 \((\theta, \phi)\)。</li> <li> <strong>输出：</strong> 该点处的<strong>颜色</strong> (RGB) 和<strong>体积密度</strong>（Density，即该点有多“实”，决定了光线通过的阻力）。</li> </ul> <h3 id="2-主要渲染流程">2. 主要渲染流程</h3> <ol> <li> <strong>光线投射 (Ray Casting)：</strong> 从摄像机发射出一条穿过像素的光线。</li> <li> <strong>采样 (Sampling)：</strong> 在这条光线上选取成百上千个采样点。</li> <li> <strong>神经网络查询：</strong> 将这些点的坐标输入多层感知机（MLP）模型，预测颜色和密度。</li> <li> <strong>体渲染 (Volume Rendering)：</strong> 将光线上所有点的预测值加权融合，计算出最终像素的颜色。</li> </ol> <p>在 NeRF（神经辐射场）中，虽然最终合成图像的步骤也常被通俗地称为 <strong>Alpha-blending</strong>，但其严谨的数学基础是基于物理的<strong>体渲染（Volume Rendering）</strong>模型。</p> <p>NeRF 使用神经网络预测<strong>体积密度（Volume Density）\(\sigma\)</strong>，并通过数值积分将其转换为我们看到的像素颜色。</p> <hr> <h3 id="1-核心物理公式连续形式可以不看">1. 核心物理公式（连续形式）可以不看</h3> <p>当一条光线 \(\mathbf{r}(t) = \mathbf{o} + t\mathbf{d}\) 穿过场景时，其最终合成的颜色 \(C(\mathbf{r})\) 由下式决定：</p> \[C(\mathbf{r}) = \int_{t_n}^{t_f} T(t) \cdot \sigma(\mathbf{r}(t)) \cdot \mathbf{c}(\mathbf{r}(t), \mathbf{d}) \, dt\] <p>其中各分量的含义如下：</p> <ul> <li> <p><strong>\(\sigma(\mathbf{r}(t))\) (Density)：</strong> 体积密度。可以理解为光线穿过该点时被阻挡的概率。\(\sigma\) 越大，该点越“实”。</p> </li> <li> <p><strong>\(\mathbf{c}(\mathbf{r}(t), \mathbf{d})\)：</strong> 该点在观察方向 \(\mathbf{d}\) 下发出的颜色。</p> </li> <li> <p>\(T(t)\) (Transmittance)： 累积透射率。表示光线从起点到 \(t\) 处没被挡住的概率。</p> \[T(t) = \exp\left( -\int_{t_n}^{t} \sigma(\mathbf{r}(s)) \, ds \right)\] </li> </ul> <hr> <h3 id="2-离散化与-alpha-blending-的联系">2. 离散化与 Alpha-blending 的联系</h3> <p>由于计算机无法直接计算连续积分，NeRF 将光线划分为 \(N\) 个小区间，并在每个区间内采样。离散化后的求和公式与传统的 Alpha-blending 逻辑高度一致：</p> \[\hat{C}(\mathbf{r}) = \sum_{i=1}^{N} T_i \cdot \alpha_i \cdot \mathbf{c}_i\] <p>在这个公式中，<strong>\(\alpha_i\)（不透明度）</strong> 是由 <strong>\(\sigma_i\)（密度）</strong> 计算得来的：</p> \[\alpha_i = 1 - \exp(-\sigma_i \delta_i)\] <blockquote> <p><strong>关键变量解释：</strong></p> <ul> <li> <strong>\(\delta_i\)：</strong> 相邻采样点之间的距离。</li> <li> <strong>\(\alpha_i\)：</strong> 这一段区间的“局部不透明度”。如果密度 \(\sigma_i\) 很大，或者步长 \(\delta_i\) 很大，那么这一段就越不透明（\(\alpha_i\) 趋近于 1）。</li> <li> <strong>\(T_i\)：</strong> 到达第 \(i\) 个点时的剩余光强。公式为 \(T_i = \prod_{j=1}^{i-1} (1 - \alpha_j)\)。</li> </ul> </blockquote> <hr> <h3 id="3-sigma-density-与-alpha-alpha-的本质区别">3. \(\sigma\) (Density) 与 \(\alpha\) (Alpha) 的本质区别</h3> <p>虽然它们都描述“物体有多实”，但在 NeRF 中有着重要的物理区别：</p> <table> <thead> <tr> <th><strong>维度</strong></th> <th><strong>体积密度 σ (Density)</strong></th> <th><strong>不透明度 α (Alpha)</strong></th> </tr> </thead> <tbody> <tr> <td><strong>定义域</strong></td> <td>\([0, +\infty)\)，可以是任意正实数。</td> <td>\([0, 1]\)，标准化的概率范围。</td> </tr> <tr> <td><strong>物理含义</strong></td> <td>单位长度内物质的衰减系数，<strong>与步长无关</strong>。</td> <td>某一特定厚度区域的遮挡率，<strong>受采样距离 \(\delta\) 影响</strong>。</td> </tr> <tr> <td><strong>网络输出</strong></td> <td>NeRF 神经网络直接预测的值。</td> <td>通过公式计算出的中间变量。</td> </tr> </tbody> </table> <p>直观理解：</p> <p>\(\sigma\) 就像是“雾的浓度”。雾可以非常浓（\(\sigma\) 很大），但如果你只走了一毫米（\(\delta\) 极小），这层雾对你视线的遮挡（\(\alpha\)）依然很小；只有浓度和路程的乘积足够大时，这段空间才变得不透明。</p> <h2 id="point-based-alpha-blending">Point-based alpha-blending</h2> <h3 id="1-核心公式">1. 核心公式</h3> <p>对于屏幕上的某一个像素，其最终颜色 \(C\) 是通过将覆盖该像素的所有 3D 高斯投影点（按深度由近到远排序）进行叠加得到的：</p> \[C = \sum_{i \in \mathcal{N}} c_i \alpha_i \prod_{j=1}^{i-1} (1 - \alpha_j)\] <p>为了方便理解，我们通常将其拆解为三个物理量：</p> <ul> <li> <strong>\(c_i\) (Color)：</strong> 第 \(i\) 个高斯点在该像素位置的颜色。</li> <li> <strong>\(\alpha_i\) (Opacity)：</strong> 第 \(i\) 个高斯点在该像素位置的<strong>有效不透明度</strong>。</li> <li> <strong>\(T_i = \prod_{j=1}^{i-1} (1 - \alpha_j)\) (Transmittance)：</strong> <strong>累积透射率</strong>。它表示光线从相机出发，穿过前面 \(i-1\) 个点后，还剩下多少能量能到达第 \(i\) 个点。</li> </ul> <hr> <h3 id="2-alpha_i-的计算3d-到-2d-的关键">2. \(\alpha_i\) 的计算：3D 到 2D 的关键</h3> <p>在 Point-based 渲染中，\(\alpha_i\) 并不是一个固定值，而是由高斯函数的空间分布决定的。对于第 \(i\) 个高斯点：</p> \[\alpha_i = \text{Opacity}_i \cdot \exp \left( -\frac{1}{2} (x - \mu_i)^T \Sigma_i^{-1} (x - \mu_i) \right)\] <ul> <li> <strong>\(\text{Opacity}_i\)：</strong> 该点在训练中学习到的基础不透明度。</li> <li> <strong>指数部分：</strong> 描述了 2D 高斯分布。这意味着当你观察这个点时，中心最实，越往边缘越透明。</li> </ul> <h3 id="对比">对比</h3> <p>我们可以清晰地看到，NeRF和Point-based alpha-blending的<strong>成像模型（Image Formation Model）是相同的</strong>。然而，它们的<strong>渲染算法却大相径庭</strong>。</p> <p><strong>NeRF</strong> 是一种连续表示法，它隐式地表示空间是空闲还是被占据；为了找到公式 (2) 中的采样点，需要进行昂贵的随机采样，这随之带来了噪声和巨大的计算开销。</p> <p>相比之下，<strong>点（Points）</strong> 是一种非结构化的离散表示法，它足够灵活，允许几何体的创建、销毁和位移。</p> <h2 id="3d-gaussian-splatting">3D Gaussian Splatting</h2> <p>3D Gaussian Splatting (3DGS) 的反向传播（back propagation, BP）是其训练核心，用于优化高斯点云的参数（如位置 \(\mu\), 协方差 \(\Sigma\), 不透明度 \(\alpha\), 球谐系数 SH）。与 NeRF 的 MLP 优化不同，3DGS 使用<strong>显式参数</strong>（点云属性），通过可微分渲染（differentiable rendering）计算梯度，结合 PyTorch 的 autograd 实现 BP。以下我详细解释 3DGS 的反向传播机制，结合 <strong>yzslab/gaussian-splatting-lightning</strong> 仓库的代码（基于你的使用场景），从数学到实现，尽量图文并茂（文字描述模拟图形），并回答如何在代码中观察 BP。</p> <hr> <h3 id="1-反向传播的总体流程">1. <strong>反向传播的总体流程</strong> </h3> <p>3DGS 的训练目标是通过多视图图像（e.g., lego 数据集的 PNG + transforms.json）监督，优化高斯参数，最小化渲染图像与真实图像的损失（如 L1 + SSIM）。BP 过程涉及：</p> <ol> <li> <strong>前向传播</strong>：从高斯参数 → 投影 → alpha 混合 → 渲染图像。</li> <li> <strong>损失计算</strong>：渲染图像与 GT（ground truth）图像比较。</li> <li> <strong>反向传播</strong>：通过 autograd 计算梯度，更新高斯参数。</li> <li> <strong>密度控制</strong>：非 BP 部分，定期调整点云（克隆/分裂/剔除）。</li> </ol> <p><strong>图示（文字模拟）</strong>：</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>[高斯参数: μ, Σ, α, SH] → [投影: 2D means/scales] → [alpha 混合: RGB] → [Loss: L1+SSIM]
    ↑ (梯度流回)            ↑ (梯度流回)             ↑ (梯度流回)         ← [GT 图像]
</code></pre></div></div> <hr> <h3 id="2-数学原理可微分渲染与梯度计算">2. <strong>数学原理：可微分渲染与梯度计算</strong> </h3> <p>3DGS 的渲染管道是可微分的，梯度通过链式法则从损失函数流回高斯参数。以下拆解关键步骤：</p> <h5 id="21-前向传播渲染"><strong>2.1 前向传播（渲染）</strong></h5> <ul> <li> <strong>输入</strong>：N 个高斯，参数为： <ul> <li>\(\mu_i \in \mathbb{R}^3\)：中心位置。</li> <li>\(\Sigma_i \in \mathbb{R}^{3 \times 3}\)：协方差矩阵（分解为缩放 \(S_i\) 和旋转 \(R_i\)）。</li> <li>\(\alpha_i \in [0,1]\)：不透明度（sigmoid 输出，实际上在计算中 \(\sigma (\alpha_i)\) 是不透明度）。</li> <li>SH 系数：视图相关颜色 \(\mathbf{c}_i(\mathbf{d})\)（球谐函数）。</li> </ul> </li> <li> <strong>投影（Splatting）</strong>： <ul> <li>每个高斯投影到 2D 图像平面： \(\mu_{i,2D} = P \cdot V \cdot \mu_i\) \(\Sigma_{i,2D} = J \cdot W \cdot \Sigma_i \cdot W^T \cdot J^T\) <ul> <li>\(P\): 相机投影矩阵（内参）。</li> <li>\(V\): 视图矩阵（外参）。</li> <li>\(J\): 投影的雅可比矩阵（透视效应）。</li> <li>\(W\): 视图旋转部分。</li> </ul> </li> <li>2D 高斯权重：\(w_i(u,v) = \alpha_i \cdot \exp(-\frac{1}{2} (\mathbf{p} - \mu_{i,2D})^T \Sigma_{i,2D}^{-1} (\mathbf{p} - \mu_{i,2D}))\)。\(w_i\) 相当于 alpha-blending中的alpha.</li> </ul> </li> <li> <strong>Alpha 混合</strong>： <ul> <li>像素颜色： \(C(\mathbf{p}) = \sum_{i=1}^N \mathbf{c}_i \cdot w_i \cdot T_i, \quad T_i = \prod_{j=1}^{i-1} (1 - w_j)\) <ul> <li>\(T_i\): 透射率，模拟光线衰减。</li> <li>按深度排序（front-to-back）。</li> </ul> </li> </ul> </li> </ul> <h5 id="22-损失函数"><strong>2.2 损失函数</strong></h5> <ul> <li>比较渲染图像 \(C(\mathbf{p})\) 与 GT 图像 \(\hat{C}(\mathbf{p})\)： \(\mathcal{L} = \lambda_1 \cdot \|\hat{C} - C\|_1 + \lambda_2 \cdot (1 - \text{SSIM}(\hat{C}, C))\) <ul> <li>典型：\(\lambda_1 = 1, \lambda_2 = 0.2\)（见 <code class="language-plaintext highlighter-rouge">configs/blender.yaml</code>）。</li> </ul> </li> <li>损失是标量，驱动梯度计算。</li> </ul> <h3 id="投影中-jacobian的推导">投影中 Jacobian的推导</h3> <p><strong>Jacobian 矩阵 \(J\)</strong> 描述了从 3D 相机坐标 \((X, Y, Z)\) 到 2D 图像坐标 \((x, y)\) 的透视投影变换的局部线性化过程。</p> <hr> <h4 id="1-透视投影函数">1. 透视投影函数</h4> <p>给定相机的焦距 \(f_x, f_y\) 和光心坐标 \(c_x, c_y\)，3D 空间点 \(P = (X, Y, Z)^T\) 投影到屏幕上的公式为：</p> \[x = f_x \frac{X}{Z} + c_x\] \[y = f_y \frac{Y}{Z} + c_y\] <h4 id="2-jacobian-矩阵-j-的偏导推导">2. Jacobian 矩阵 \(J\) 的偏导推导</h4> <p>Jacobian 矩阵是一个 \(2 \times 3\) 的矩阵，包含了投影函数对 \(X, Y, Z\) 的一阶偏导数：</p> \[J = \begin{pmatrix} \frac{\partial x}{\partial X} &amp; \frac{\partial x}{\partial Y} &amp; \frac{\partial x}{\partial Z} \\ \frac{\partial y}{\partial X} &amp; \frac{\partial y}{\partial Y} &amp; \frac{\partial y}{\partial Z} \end{pmatrix}\] <p>我们可以逐项计算：</p> <ul> <li> <strong>对于 \(x\) 坐标：</strong> <ul> <li> \[\frac{\partial x}{\partial X} = \frac{f_x}{Z}\] </li> <li> \[\frac{\partial x}{\partial Y} = 0\] </li> <li> \[\frac{\partial x}{\partial Z} = -\frac{f_x X}{Z^2}\] </li> </ul> </li> <li> <strong>对于 \(y\) 坐标：</strong> <ul> <li> \[\frac{\partial y}{\partial X} = 0\] </li> <li> \[\frac{\partial y}{\partial Y} = \frac{f_y}{Z}\] </li> <li> \[\frac{\partial y}{\partial Z} = -\frac{f_y Y}{Z^2}\] </li> </ul> </li> </ul> <h4 id="3-最终的-jacobian-矩阵形式">3. 最终的 Jacobian 矩阵形式</h4> <p>将上述结果组合，得到最终在高斯均值点 \((X, Y, Z)\) 处评估的 Jacobian 矩阵：</p> \[J = \begin{pmatrix} \frac{f_x}{Z} &amp; 0 &amp; -\frac{f_x X}{Z^2} \\ 0 &amp; \frac{f_y}{Z} &amp; -\frac{f_y Y}{Z^2} \end{pmatrix}\] <hr> <h4 id="4-在协方差投影中的应用">4. 在协方差投影中的应用</h4> <p>在 3D Gaussian Splatting 的渲染管线中，这个矩阵被用来将 3D 相机空间的协方差矩阵 \(\Sigma_{view}\) 投影到 2D 图像空间 \(\Sigma'\)：</p> \[\Sigma' = J \Sigma_{view} J^T\] <p><strong>物理意义说明：</strong></p> <ul> <li> <strong>\(1/Z\) 项：</strong> 体现了“近大远小”的缩放效果。</li> <li> <strong>\(X/Z^2\) 和 \(Y/Z^2\) 项：</strong> 体现了当 3D 点偏离光轴（即 \(X\) 或 \(Y\) 较大）时，透视投影引起的几何拉伸（各向异性）。这就是为什么屏幕边缘的高斯点往往看起来比中心的更“扁”的原因。</li> </ul> <h3 id="sh-spherical-harmonics球谐函数"><strong>SH (Spherical Harmonics，球谐函数)</strong></h3> <p>在 3D Gaussian Splatting (3DGS) 和 NeRF 中，<strong>View-dependent Colors（视点相关颜色）</strong> 是实现真实感的关键。它能表现出金属的高光、镜面反射以及随着观察角度变化而产生的颜色闪烁。</p> <p>为了在离散的点云表示中实现这一效果，3DGS 采用了 <strong>SH (Spherical Harmonics，球谐函数)</strong>。</p> <hr> <h4 id="1-为什么需要视点相关颜色">1. 为什么需要视点相关颜色？</h4> <p>如果一个物体的颜色是固定的（即 <strong>Lambertian 漫反射表面</strong>），那么无论你从哪个角度看，它都是一样的颜色。但现实世界中：</p> <ul> <li> <strong>金属、玻璃：</strong> 某些角度有强光。</li> <li> <strong>各向异性材质：</strong> 颜色随视角偏转而变化。</li> </ul> <p>传统的点只能存储一个 RGB 值，而 3DGS 为每个高斯点存储了一组 <strong>SH 系数</strong>，使其颜色成为一个关于<strong>观察方向</strong>的函数。</p> <hr> <h4 id="2-什么是球谐函数-spherical-harmonics">2. 什么是球谐函数 (Spherical Harmonics)?</h4> <p><strong>球谐函数</strong>可以类比为“球面上的傅里叶级数”。</p> <ul> <li> <strong>傅里叶级数</strong>是用一堆正弦/余弦波来近似任何<strong>周期信号（一维）</strong>。</li> <li> <strong>球谐函数</strong>是用一组定义在球面上的一组基函数 \(Y_{lm}(\theta, \phi)\) 来近似任何<strong>球面函数（二维方向）</strong>。</li> </ul> <p>在 3DGS 中，每个高斯点不仅仅有一个颜色，而是拥有多层“频率系数”。当你改变视角时，算法会根据当前视角方向 \((\theta, \phi)\)，对这些系数进行加权求和，计算出该视角下的实时 RGB 颜色。</p> <hr> <h4 id="3-数学表达">3. 数学表达</h4> <p>对于一个高斯点，其在视角方向 \(d\) 下的颜色 \(C\) 计算公式为：</p> \[C(d) = \sum_{l=0}^{k} \sum_{m=-l}^{l} c_{lm} Y_{lm}(d)\] <p>其中：</p> <ul> <li> <strong>\(c_{lm}\)：</strong> 这是存储在每个高斯点里的 <strong>SH 系数</strong>（模型要学习的参数）。</li> <li> <strong>\(Y_{lm}(d)\)：</strong> 这是预定义的球谐基函数。</li> <li> <strong>\(k\)：</strong> SH 的阶数（Degree）。</li> </ul> <hr> <h4 id="4-sh-阶数的影响">4. SH 阶数的影响</h4> <p>3DGS 通常使用 <strong>3 阶 SH (Degree 3)</strong>：</p> <ul> <li> <strong>0 阶 (Degree 0):</strong> 只有 1 个系数。代表基础底色（漫反射），无论怎么看颜色都一样。</li> <li> <strong>1-3 阶:</strong> 随着阶数增加，模型可以表现出更复杂、更锐利的高光和环境反射效果。</li> </ul> <p>存储代价：</p> <p>每个高斯点如果使用 3 阶 SH，需要为 R、G、B 三个通道各存储 \((3+1)^2 = 16\) 个系数，总共 48 个系数。这就是为什么 3DGS 的模型文件（.ply）通常比 NeRF 的权重文件大的原因。</p> <p><img src="/images/2025-12-25-gaussianSplatting/1bKNS_UyAOGcQvew-b-pciQ.png" alt="Figure 9: A process of obtaining a view-dependant color (red component) of a point with _ℓmax = 2 and 9 learned coefficients. A sigmoid function maps the value into the [0, 1] interval. Oftentimes, clipping is used instead [Source: Image by the author]" class="img-fluid" data-zoomable=""></p> <h2 id="投影和alpha混合的可微性">投影和alpha混合的可微性</h2> <hr> <p>是的，在 <strong>3D Gaussian Splatting (3DGS)</strong> 中，<strong>投影（Projection/Splatting）</strong> 和 <strong>Alpha 混合（Alpha Blending）</strong> 两个步骤都是<strong>可微分的</strong>（differentiable）。这是 3DGS 能够通过反向传播（back propagation）优化高斯参数（如位置 \(\mu\)、协方差 \(\Sigma\)、不透明度 \(\alpha\)、球谐系数 SH）的关键原因。以下详细解释两者的可微性，结合数学推导、代码实现（基于 <strong>yzslab/gaussian-splatting-lightning</strong> 仓库），并以图文并茂的方式说明（文字模拟图形），回答你的问题。</p> <hr> <h3 id="1-投影projectionsplatting的可微性">1. <strong>投影（Projection/Splatting）的可微性</strong> </h3> <p><strong>投影</strong>步骤将 3D 高斯点云投影到 2D 图像平面，生成每个高斯的 2D 均值 \(\mu_{2D}\)、协方差 \(\Sigma_{2D}\) 和权重 \(w_i\)，用于后续渲染。这个过程是可微的，因为所有变换（矩阵运算、指数函数等）都支持梯度计算。</p> <h4 id="11-数学原理"><strong>1.1 数学原理</strong></h4> <ul> <li> <strong>输入</strong>： <ul> <li>3D 高斯参数：\(\mu_i \in \mathbb{R}^3\)（中心位置）、\(\Sigma_i \in \mathbb{R}^{3 \times 3}\)（协方差，分解为旋转 \(R_i\) 和缩放 \(S_i\)）、\(\alpha_i \in [0,1]\)（不透明度）。</li> <li>相机参数：视图矩阵 \(V\)（外参，4x4）、投影矩阵 \(P\)（内参，透视投影）。</li> </ul> </li> <li> <strong>投影公式</strong>： <ol> <li> <strong>均值投影</strong>： \(\mu_{i,2D} = P \cdot V \cdot \mu_i\) <ul> <li>\(V \cdot \mu_i\)：将 3D 位置从世界坐标系变换到相机坐标系。</li> <li>\(P\)：透视投影（e.g., \(P = \begin{bmatrix} f_x/Z &amp; 0 &amp; c_x \\ 0 &amp; f_y/Z &amp; c_y \\ 0 &amp; 0 &amp; 1 \end{bmatrix}\)），输出 2D 像素坐标。</li> <li> <strong>可微性</strong>：矩阵乘法是线性操作，透视除法 (\(/Z\)) 是可微的（雅可比矩阵 \(J\) 提供导数）。</li> </ul> </li> <li> <strong>协方差投影</strong>： \(\Sigma_{i,2D} = J \cdot W \cdot \Sigma_i \cdot W^T \cdot J^T\) <ul> <li>\(W\)：视图矩阵 \(V\) 的 3x3 旋转部分。</li> <li>\(J\)：投影雅可比矩阵，考虑透视畸变： \(J = \begin{bmatrix} \frac{f_x}{Z} &amp; 0 &amp; -\frac{f_x X}{Z^2} \\ 0 &amp; \frac{f_y}{Z} &amp; -\frac{f_y Y}{Z^2} \end{bmatrix}\)</li> <li>\(\Sigma_i = R_i S_i S_i^T R_i^T\)：3D 协方差分解。</li> <li> <strong>可微性</strong>：矩阵乘法、转置和 \(J\) 的计算（涉及除法）都可微，梯度通过链式法则流回 \(\Sigma_i\)（即 \(S_i, R_i\)）。</li> </ul> </li> <li> <strong>高斯权重</strong>： \(w_i(u,v) = \alpha_i \cdot \exp\left(-\frac{1}{2} (\mathbf{p} - \mu_{i,2D})^T \Sigma_{i,2D}^{-1} (\mathbf{p} - \mu_{i,2D})\right)\) <ul> <li>\(\alpha_i\)：sigmoid 输出，可微。</li> <li>指数函数和矩阵逆（\(\Sigma_{i,2D}^{-1}\)）可微（指数导数为自身，矩阵逆导数基于线性代数）。</li> </ul> </li> </ol> </li> <li> <strong>梯度流</strong>： <ul> <li>损失 \(\mathcal{L}\) 对像素颜色 \(C(\mathbf{p})\) 的梯度 \(\frac{\partial \mathcal{L}}{\partial C}\) 流回 \(w_i\)，再通过 \(w_i\) 流回 \(\mu_{i,2D}, \Sigma_{i,2D}, \alpha_i\)，最终到 \(\mu_i, \Sigma_i, \alpha_i\)。</li> </ul> </li> </ul> <h4 id="12-代码实现yzslab"><strong>1.2 代码实现（yzslab）</strong></h4> <ul> <li> <strong>文件</strong>：<code class="language-plaintext highlighter-rouge">src/render/gs_renderer.py</code>，调用 <code class="language-plaintext highlighter-rouge">gsplat.rasterize_gaussians()</code>。</li> <li> <strong>关键代码</strong>（简化）： <div class="language-python highlighter-rouge"> <div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">project_gaussians</span><span class="p">(</span><span class="n">means</span><span class="p">,</span> <span class="n">scales</span><span class="p">,</span> <span class="n">rotations</span><span class="p">,</span> <span class="n">camera</span><span class="p">):</span>
    <span class="n">means3D</span> <span class="o">=</span> <span class="n">means</span>  <span class="c1"># [N, 3]
</span>    <span class="n">view_matrix</span> <span class="o">=</span> <span class="n">camera</span><span class="p">.</span><span class="n">view</span>  <span class="c1"># [4, 4]
</span>    <span class="n">proj_matrix</span> <span class="o">=</span> <span class="n">camera</span><span class="p">.</span><span class="n">proj</span>  <span class="c1"># [3, 4]
</span>    <span class="n">means2D</span> <span class="o">=</span> <span class="n">proj_matrix</span> <span class="o">@</span> <span class="p">(</span><span class="n">view_matrix</span> <span class="o">@</span> <span class="n">means3D</span><span class="p">)</span>  <span class="c1"># 矩阵乘法
</span>    <span class="n">J</span> <span class="o">=</span> <span class="nf">compute_jacobian</span><span class="p">(</span><span class="n">means3D</span><span class="p">,</span> <span class="n">camera</span><span class="p">.</span><span class="n">focal</span><span class="p">)</span>  <span class="c1"># 雅可比
</span>    <span class="n">cov3D</span> <span class="o">=</span> <span class="nf">scales_to_cov</span><span class="p">(</span><span class="n">scales</span><span class="p">,</span> <span class="n">rotations</span><span class="p">)</span>  <span class="c1"># [N, 3, 3]
</span>    <span class="n">cov2D</span> <span class="o">=</span> <span class="n">J</span> <span class="o">@</span> <span class="p">(</span><span class="n">view_matrix</span><span class="p">[:</span><span class="mi">3</span><span class="p">,:</span><span class="mi">3</span><span class="p">]</span> <span class="o">@</span> <span class="n">cov3D</span> <span class="o">@</span> <span class="n">view_matrix</span><span class="p">[:</span><span class="mi">3</span><span class="p">,:</span><span class="mi">3</span><span class="p">].</span><span class="n">T</span><span class="p">)</span> <span class="o">@</span> <span class="n">J</span><span class="p">.</span><span class="n">T</span>
    <span class="k">return</span> <span class="n">means2D</span><span class="p">,</span> <span class="n">cov2D</span>
</code></pre></div> </div> </li> <li> <strong>可微性</strong>： <ul> <li> <code class="language-plaintext highlighter-rouge">torch.matmul</code>（矩阵乘法）可微。</li> <li> <code class="language-plaintext highlighter-rouge">compute_jacobian</code> 计算 \(J\)（涉及除法 <code class="language-plaintext highlighter-rouge">/Z</code>），PyTorch autograd 自动处理。</li> <li> <code class="language-plaintext highlighter-rouge">gsplat.rasterize_gaussians</code> 是 CUDA 实现的，可微分内核，基于 C++ 和 PyBind11（见 gsplat 源码）。</li> </ul> </li> <li> <strong>调试</strong>：在 <code class="language-plaintext highlighter-rouge">viewer.py</code> 或 <code class="language-plaintext highlighter-rouge">render.py</code> 加断点，打印 <code class="language-plaintext highlighter-rouge">means2D.grad</code> 检查梯度。</li> </ul> <h4 id="13-图示文字模拟"><strong>1.3 图示（文字模拟）</strong></h4> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>3D 高斯 [μ, Σ, α] → [矩阵乘法: V, P] → [2D 均值 μ_2D] → [雅可比 J 变换] → [2D 协方差 Σ_2D]
                                                    ↓
                                                  [高斯权重 w_i: exp(-x^T Σ_2D^-1 x)]
梯度流: Loss ← w_i ← μ_2D, Σ_2D ← μ, Σ, α
</code></pre></div></div> <hr> <h3 id="2-alpha-混合alpha-blending的可微性">2. <strong>Alpha 混合（Alpha Blending）的可微性</strong> </h3> <p><strong>Alpha 混合</strong>将投影后的 2D 高斯按深度排序，累积颜色形成像素值。这个过程也是可微的，因为涉及的排序、乘法和累积操作支持梯度计算。</p> <h4 id="21-数学原理"><strong>2.1 数学原理</strong></h4> <ul> <li> <strong>输入</strong>： <ul> <li>每个高斯的 2D 参数：\(\mu_{i,2D}, \Sigma_{i,2D}, \alpha_i, \mathbf{c}_i\)（颜色，SH 插值）。</li> <li>像素坐标 \(\mathbf{p} = (u,v)\)。</li> </ul> </li> <li> <strong>混合公式</strong>： \(C(\mathbf{p}) = \sum_{i=1}^N \mathbf{c}_i \cdot w_i \cdot T_i, \quad T_i = \prod_{j=1}^{i-1} (1 - w_j)\) <ul> <li>\(w_i = \alpha_i \cdot \exp(-\frac{1}{2} (\mathbf{p} - \mu_{i,2D})^T \Sigma_{i,2D}^{-1} (\mathbf{p} - \mu_{i,2D})\)：高斯权重。</li> <li>\(T_i\)：透射率，模拟光线穿过前 i-1 个高斯的衰减。</li> <li>按深度 \(z_i\)（相机坐标 Z）排序（front-to-back）。</li> </ul> </li> <li> <strong>可微性</strong>： <ul> <li> <strong>颜色</strong>：\(\frac{\partial C}{\partial \mathbf{c}_i} = w_i \cdot T_i\)，线性操作，可微。</li> <li> <strong>权重</strong>：\(w_i\) 依赖 \(\alpha_i, \mu_{i,2D}, \Sigma_{i,2D}\)，已证明可微（见投影）。</li> <li> <strong>透射率</strong>：\(T_i = \prod_{j=1}^{i-1} (1 - w_j)\)，乘法链可微，导数： \(\frac{\partial T_i}{\partial w_k} = -T_i \cdot \frac{1}{1 - w_k} \quad (k &lt; i)\)</li> <li> <strong>排序</strong>：深度排序在渲染中是离散操作（不可微），但 3DGS 用 <strong>tile-based rasterization</strong>（分块光栅化），梯度只流经数值计算（不涉及排序本身），通过 CUDA 实现（如 gsplat 的 radix sort）。</li> </ul> </li> </ul> <h4 id="22-代码实现yzslab"><strong>2.2 代码实现（yzslab）</strong></h4> <ul> <li> <strong>文件</strong>：<code class="language-plaintext highlighter-rouge">src/render/gs_renderer.py</code>，调用 <code class="language-plaintext highlighter-rouge">gsplat.rasterize_gaussians()</code>。</li> <li> <strong>关键代码</strong>（简化）： <div class="language-python highlighter-rouge"> <div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">gsplat</span>
<span class="k">def</span> <span class="nf">render</span><span class="p">(</span><span class="n">gaussians</span><span class="p">,</span> <span class="n">camera</span><span class="p">):</span>
    <span class="n">means2D</span><span class="p">,</span> <span class="n">cov2D</span><span class="p">,</span> <span class="n">opacities</span> <span class="o">=</span> <span class="nf">project_gaussians</span><span class="p">(</span><span class="n">gaussians</span><span class="p">.</span><span class="n">means</span><span class="p">,</span> <span class="n">gaussians</span><span class="p">.</span><span class="n">scales</span><span class="p">,</span> <span class="n">camera</span><span class="p">)</span>
    <span class="n">rgb</span> <span class="o">=</span> <span class="n">gsplat</span><span class="p">.</span><span class="nf">rasterize_gaussians</span><span class="p">(</span>
        <span class="n">means2D</span><span class="p">,</span> <span class="n">cov2D</span><span class="p">,</span> <span class="n">opacities</span><span class="p">,</span> <span class="n">gaussians</span><span class="p">.</span><span class="n">colors</span><span class="p">,</span> <span class="n">camera</span>  <span class="c1"># 排序+混合
</span>    <span class="p">)</span>
    <span class="k">return</span> <span class="p">{</span><span class="sh">"</span><span class="s">rgb</span><span class="sh">"</span><span class="p">:</span> <span class="n">rgb</span><span class="p">}</span>
</code></pre></div> </div> </li> <li> <strong>可微性</strong>： <ul> <li> <code class="language-plaintext highlighter-rouge">gsplat.rasterize_gaussians</code> 是 C++/CUDA 实现，内部计算 alpha 混合的梯度。</li> <li>排序在 tile 内（16x16 像素块），梯度流经 \(w_i, T_i\)，不依赖排序顺序。</li> </ul> </li> <li> <strong>调试</strong>：在 <code class="language-plaintext highlighter-rouge">training_step()</code> 打印 <code class="language-plaintext highlighter-rouge">rgb.grad</code>： <div class="language-python highlighter-rouge"> <div class="highlight"><pre class="highlight"><code><span class="n">rendered</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">renderer</span><span class="p">.</span><span class="nf">render</span><span class="p">(</span><span class="n">gaussians</span><span class="p">,</span> <span class="n">batch</span><span class="p">[</span><span class="sh">"</span><span class="s">camera</span><span class="sh">"</span><span class="p">])</span>
<span class="n">loss</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">compute_loss</span><span class="p">(</span><span class="n">rendered</span><span class="p">[</span><span class="sh">"</span><span class="s">rgb</span><span class="sh">"</span><span class="p">],</span> <span class="n">batch</span><span class="p">[</span><span class="sh">"</span><span class="s">image</span><span class="sh">"</span><span class="p">])</span>
<span class="n">loss</span><span class="p">.</span><span class="nf">backward</span><span class="p">()</span>
<span class="nf">print</span><span class="p">(</span><span class="n">rendered</span><span class="p">[</span><span class="sh">"</span><span class="s">rgb</span><span class="sh">"</span><span class="p">].</span><span class="n">grad</span><span class="p">)</span>  <span class="c1"># 像素梯度
</span></code></pre></div> </div> </li> </ul> <h4 id="23-图示文字模拟"><strong>2.3 图示（文字模拟）</strong></h4> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>[高斯: c_i, w_i] → [排序: z_i] → [T_i = Π(1-w_j)] → [C = Σ(c_i * w_i * T_i)] → Loss
梯度流: Loss ← C ← c_i, w_i ← α_i, μ_i, Σ_i
</code></pre></div></div> <h3 id="排序">排序</h3> <h4 id="1-排序的频率多久进行一次">1. <strong>排序的频率：多久进行一次？</strong> </h4> <p>在 3DGS 中，<strong>排序</strong>是光栅化（rasterization）的一部分，具体用于按深度（z 值）对高斯点进行排序（front-to-back），以正确执行 alpha 混合。排序的频率直接取决于<strong>渲染的调用频率</strong>，因为每次渲染都需要对高斯点进行排序。</p> <h4 id="11-排序的时机"><strong>1.1 排序的时机</strong></h4> <ul> <li> <strong>渲染触发</strong>： <ul> <li>排序发生在每次<strong>前向传播</strong>（forward pass）中，即每次调用 <code class="language-plaintext highlighter-rouge">render()</code> 函数时（包括训练、验证和渲染阶段）。</li> <li>在训练中，<code class="language-plaintext highlighter-rouge">render()</code> 由 <code class="language-plaintext highlighter-rouge">training_step()</code> 调用，每处理一个批次（batch）数据（一张或多张 lego 图像）就渲染一次，因此排序也执行一次。</li> <li> <strong>频率</strong>：<strong>每训练一步（step）</strong>，即每个 batch 都会进行一次排序。</li> </ul> </li> <li> <strong>训练频率</strong>： <ul> <li>你的训练日志显示 300 个 epoch，30,000 步（<code class="language-plaintext highlighter-rouge">epoch=300-step=30000.ckpt</code>），每 epoch 100 个 batch（lego 数据集 <code class="language-plaintext highlighter-rouge">train/</code> 有 100 张图像，<code class="language-plaintext highlighter-rouge">configs/blender.yaml</code> 默认 batch_size=1）。</li> <li> <strong>排序总次数</strong>：30,000 次（每 step 一次）。</li> <li> <strong>时间开销</strong>：排序由 CUDA 加速（gsplat 使用 radix sort），单次排序 ~0.1-1 毫秒（RTX 3090，~100k 高斯），占渲染时间 &lt;10%。</li> </ul> </li> <li> <strong>验证/渲染阶段</strong>： <ul> <li>验证（validation）：每 <code class="language-plaintext highlighter-rouge">val_interval</code>（默认 1000 步，<code class="language-plaintext highlighter-rouge">configs/blender.yaml</code>）渲染验证图像，触发排序。</li> <li>手动渲染：运行 <code class="language-plaintext highlighter-rouge">python render.py --ckpt_path outputs/lego_test/checkpoints/epoch=300-step=30000.ckpt</code>，每次生成一张图像或视频帧都排序一次（e.g., 100 帧视频 → 100 次排序）。</li> </ul> </li> <li> <strong>Viewer</strong>：运行 <code class="language-plaintext highlighter-rouge">python viewer.py --ply_path outputs/lego_test/checkpoints/epoch=300-step=30000-xyz_rgb.ply</code>，交互式查看时，每帧实时渲染，排序随帧率（如 60 FPS → 每秒 60 次）。</li> </ul> <h4 id="12-代码中的排序"><strong>1.2 代码中的排序</strong></h4> <ul> <li> <strong>文件</strong>：<code class="language-plaintext highlighter-rouge">src/render/gs_renderer.py</code>，调用 <code class="language-plaintext highlighter-rouge">gsplat.rasterize_gaussians()</code>。</li> <li> <strong>关键代码</strong>（简化）： <div class="language-python highlighter-rouge"> <div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">gsplat</span>
<span class="k">def</span> <span class="nf">render</span><span class="p">(</span><span class="n">gaussians</span><span class="p">,</span> <span class="n">camera</span><span class="p">):</span>
    <span class="n">means2D</span><span class="p">,</span> <span class="n">cov2D</span><span class="p">,</span> <span class="n">opacities</span> <span class="o">=</span> <span class="nf">project_gaussians</span><span class="p">(</span><span class="n">gaussians</span><span class="p">.</span><span class="n">means</span><span class="p">,</span> <span class="n">gaussians</span><span class="p">.</span><span class="n">scales</span><span class="p">,</span> <span class="n">camera</span><span class="p">)</span>
    <span class="n">rgb</span> <span class="o">=</span> <span class="n">gsplat</span><span class="p">.</span><span class="nf">rasterize_gaussians</span><span class="p">(</span>
        <span class="n">means2D</span><span class="p">,</span> <span class="n">cov2D</span><span class="p">,</span> <span class="n">opacities</span><span class="p">,</span> <span class="n">gaussians</span><span class="p">.</span><span class="n">colors</span><span class="p">,</span> <span class="n">camera</span><span class="p">,</span> <span class="n">block_size</span><span class="o">=</span><span class="mi">16</span>
    <span class="p">)</span>  <span class="c1"># 内部排序
</span>    <span class="k">return</span> <span class="p">{</span><span class="sh">"</span><span class="s">rgb</span><span class="sh">"</span><span class="p">:</span> <span class="n">rgb</span><span class="p">}</span>
</code></pre></div> </div> </li> <li> <strong>排序位置</strong>： <ul> <li> <code class="language-plaintext highlighter-rouge">gsplat.rasterize_gaussians</code>（gsplat 库，<code class="language-plaintext highlighter-rouge">gsplat/_torch_impl.py</code> 和 <code class="language-plaintext highlighter-rouge">cuda/rasterize.cu</code>）在每个 tile（16x16 像素块）内按深度 \(z_i\)（从 3D 均值 \(\mu_i\) 投影得到）排序。</li> <li>代码伪逻辑（CUDA）： <div class="language-c highlighter-rouge"> <div class="highlight"><pre class="highlight"><code><span class="c1">// cuda/rasterize.cu</span>
<span class="k">for</span> <span class="n">each</span> <span class="n">tile</span><span class="o">:</span>
    <span class="n">compute_depths</span><span class="p">(</span><span class="n">means3D</span><span class="p">,</span> <span class="n">camera</span><span class="p">);</span>  <span class="c1">// z_i = (V * μ_i).z</span>
    <span class="n">indices</span> <span class="o">=</span> <span class="n">radix_sort</span><span class="p">(</span><span class="n">depths</span><span class="p">);</span>     <span class="c1">// 按 z_i 排序</span>
    <span class="n">accumulate_colors</span><span class="p">(</span><span class="n">indices</span><span class="p">,</span> <span class="n">weights</span><span class="p">,</span> <span class="n">colors</span><span class="p">);</span> <span class="c1">// alpha 混合</span>
</code></pre></div> </div> </li> </ul> </li> <li> <strong>频率</strong>：每个 batch 的 <code class="language-plaintext highlighter-rouge">training_step()</code> 调用 <code class="language-plaintext highlighter-rouge">render()</code>，触发一次排序（~100 次/epoch）。</li> </ul> <h4 id="13-频率总结"><strong>1.3 频率总结</strong></h4> <ul> <li> <strong>训练</strong>：每 step（batch）排序一次，30,000 步 → 30,000 次排序。</li> <li> <strong>验证</strong>：每 1000 步（可调，<code class="language-plaintext highlighter-rouge">val_interval</code>），~30 次。</li> <li> <strong>渲染/Viewer</strong>：每帧一次（视频 100 帧 → 100 次，viewer 60 FPS → 60 次/秒）。</li> <li> <strong>配置调整</strong>：<code class="language-plaintext highlighter-rouge">configs/blender.yaml</code> 的 <code class="language-plaintext highlighter-rouge">batch_size</code> 或 <code class="language-plaintext highlighter-rouge">val_interval</code> 影响频率，但排序本身不可跳过（alpha 混合依赖正确顺序）。</li> </ul> <hr> <h4 id="2-排序的可微性排序是可微的吗">2. <strong>排序的可微性：排序是可微的吗？</strong> </h4> <p><strong>简答</strong>：排序（sorting）是<strong>不可微的</strong>（non-differentiable），因为它是一个离散操作（改变高斯索引顺序），无法定义连续的导数。但在 3DGS 中，排序不影响反向传播的可微性，因为梯度流绕过了排序步骤，只依赖数值计算（权重 \(w_i\) 和透射率 \(T_i\)）。这与投影和 alpha 混合的可微性不同。</p> </div> </article> <br> <hr> <br> <ul class="list-disc pl-8"></ul> <h2 class="text-3xl font-semibold mb-4 mt-12">Enjoy Reading This Article?</h2> <p class="mb-2">Here are some more articles you might like to read next:</p> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2026/optical_flow/">Optical_Flow</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2026/Teaching-Tailored-to-Talent/">Teaching Tailored To Talent</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2025/VINS-and-ESVO2/">Vins And Esvo2</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2025/dino/">DINO 如何用于密集预测</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2025/3dtasks/">3D 任务：SFM, MVS, NVS, VO, VIO, SLAM</a> </li> </div> </div> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2026 Erkang Chen. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script defer src="/assets/js/bootstrap-toc.min.js?c82ff4de8b0955d6ff14f5b05eed7eb6"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>addBackToTop();</script> <script type="module" src="/assets/js/search/ninja-keys.min.js?a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script>let searchTheme=determineComputedTheme();const ninjaKeys=document.querySelector("ninja-keys");"dark"===searchTheme?ninjaKeys.classList.add("dark"):ninjaKeys.classList.remove("dark");const openSearchModal=()=>{const e=$("#navbarNav");e.hasClass("show")&&e.collapse("hide"),ninjaKeys.open()};</script> <script>const ninja=document.querySelector("ninja-keys");ninja.data=[{id:"nav-about",title:"about",section:"Navigation",handler:()=>{window.location.href="/"}},{id:"nav-blog",title:"blog",description:"",section:"Navigation",handler:()=>{window.location.href="/blog/"}},{id:"nav-publications",title:"publications",description:"publications by categories in reversed chronological order. generated by jekyll-scholar.",section:"Navigation",handler:()=>{window.location.href="/publications/"}},{id:"nav-projects",title:"projects",description:"A growing collection of your cool projects.",section:"Navigation",handler:()=>{window.location.href="/projects/"}},{id:"post-optical-flow",title:"Optical_Flow",description:"RAFT, SEA-RAFT, NeuFlow, FlowSeek",section:"Posts",handler:()=>{window.location.href="/blog/2026/optical_flow/"}},{id:"post-teaching-tailored-to-talent",title:"Teaching Tailored To Talent",description:"\u7b80\u8981\u4ecb\u7ecd",section:"Posts",handler:()=>{window.location.href="/blog/2026/Teaching-Tailored-to-Talent/"}},{id:"post-vins-and-esvo2",title:"Vins And Esvo2",description:"\u7b80\u8981\u4ecb\u7ecd",section:"Posts",handler:()=>{window.location.href="/blog/2025/VINS-and-ESVO2/"}},{id:"post-dino-\u5982\u4f55\u7528\u4e8e\u5bc6\u96c6\u9884\u6d4b",title:"DINO \u5982\u4f55\u7528\u4e8e\u5bc6\u96c6\u9884\u6d4b",description:"\u5982\u4f55\u4f7f\u7528DINO, DPT, RoPE",section:"Posts",handler:()=>{window.location.href="/blog/2025/dino/"}},{id:"post-3d-\u4efb\u52a1-sfm-mvs-nvs-vo-vio-slam",title:"3D \u4efb\u52a1\uff1aSFM, MVS, NVS, VO, VIO, SLAM",description:"\u591a\u89c6\u89d2\u51e0\u4f55\uff0c\u65b0\u89c6\u89d2\u751f\u6210",section:"Posts",handler:()=>{window.location.href="/blog/2025/3dtasks/"}},{id:"post-matplotlib\u8f93\u51fa\u4e2d\u6587",title:"Matplotlib\u8f93\u51fa\u4e2d\u6587",description:"\u7b80\u8981\u4ecb\u7ecd",section:"Posts",handler:()=>{window.location.href="/blog/2025/matplotlib%E8%BE%93%E5%87%BA%E4%B8%AD%E6%96%87/"}},{id:"post-mamba",title:"Mamba",description:"\u7b80\u8981\u4ecb\u7ecd",section:"Posts",handler:()=>{window.location.href="/blog/2025/mamba/"}},{id:"post-flow",title:"Flow",description:"\u7b80\u8981\u4ecb\u7ecd",section:"Posts",handler:()=>{window.location.href="/blog/2025/flow/"}},{id:"post-diffusion",title:"Diffusion",description:"\u7b80\u8981\u4ecb\u7ecd",section:"Posts",handler:()=>{window.location.href="/blog/2025/diffusion/"}},{id:"post-nerf-and-gaussian-splatting",title:"NeRF and Gaussian Splatting",description:"Gaussian Splatting, NeRF, Alpha-blending, Point-Based Rendering, Jacobian",section:"Posts",handler:()=>{window.location.href="/blog/2025/gaussianSplatting/"}},{id:"post-colmap",title:"COLMAP",description:"SFM",section:"Posts",handler:()=>{window.location.href="/blog/2025/sfm-mvs-rendering/"}},{id:"post-\u51b2\u6fc0\u4fe1\u53f7\u7684\u5c3a\u5ea6\u53d8\u6362",title:"\u51b2\u6fc0\u4fe1\u53f7\u7684\u5c3a\u5ea6\u53d8\u6362",description:"this is what included images could look like",section:"Posts",handler:()=>{window.location.href="/blog/2025/impulse/"}},{id:"post-\u4fe1\u53f7\u4e0e\u7cfb\u7edf\u8bfe\u7a0b\u7684\u6570\u5b66\u77e5\u8bc6",title:"\u4fe1\u53f7\u4e0e\u7cfb\u7edf\u8bfe\u7a0b\u7684\u6570\u5b66\u77e5\u8bc6",description:"this is what included images could look like",section:"Posts",handler:()=>{window.location.href="/blog/2025/math/"}},{id:"post-fisheye",title:"Fisheye",description:"\u7b80\u8981\u4ecb\u7ecd",section:"Posts",handler:()=>{window.location.href="/blog/2024/fisheye/"}},{id:"post-montecarlo",title:"Montecarlo",description:"\u7b80\u8981\u4ecb\u7ecd",section:"Posts",handler:()=>{window.location.href="/blog/2024/MonteCarlo/"}},{id:"post-\u5c0f\u6ce2\u5206\u6790",title:"\u5c0f\u6ce2\u5206\u6790",description:"\u7b80\u8981\u4ecb\u7ecd",section:"Posts",handler:()=>{window.location.href="/blog/2024/%E5%B0%8F%E6%B3%A2%E5%88%86%E6%9E%90/"}},{id:"post-lifeifei",title:"Lifeifei",description:"\u7b80\u8981\u4ecb\u7ecd",section:"Posts",handler:()=>{window.location.href="/blog/2024/Lifeifei/"}},{id:"post-orgmode",title:"Orgmode",description:"\u7b80\u8981\u4ecb\u7ecd",section:"Posts",handler:()=>{window.location.href="/blog/2024/orgmode/"}},{id:"post-python\u8fd0\u884c\u811a\u672c\u6216\u6a21\u5757",title:"Python\u8fd0\u884c\u811a\u672c\u6216\u6a21\u5757",description:"\u7b80\u8981\u4ecb\u7ecd",section:"Posts",handler:()=>{window.location.href="/blog/2024/Python%E8%BF%90%E8%A1%8C%E8%84%9A%E6%9C%AC%E6%88%96%E6%A8%A1%E5%9D%97/"}},{id:"post-proximal",title:"Proximal",description:"\u7b80\u8981\u4ecb\u7ecd",section:"Posts",handler:()=>{window.location.href="/blog/2024/proximal/"}},{id:"post-visualtransformer",title:"Visualtransformer",description:"\u7b80\u8981\u4ecb\u7ecd",section:"Posts",handler:()=>{window.location.href="/blog/2024/VisualTransformer/"}},{id:"post-pytorch-note",title:"Pytorch Note",description:"\u7b80\u8981\u4ecb\u7ecd",section:"Posts",handler:()=>{window.location.href="/blog/2024/Pytorch-note/"}},{id:"post-android-opencv-ndk",title:"Android Opencv Ndk",description:"\u7b80\u8981\u4ecb\u7ecd",section:"Posts",handler:()=>{window.location.href="/blog/2024/android-opencv-ndk/"}},{id:"post-repvgg",title:"Repvgg",description:"\u7b80\u8981\u4ecb\u7ecd",section:"Posts",handler:()=>{window.location.href="/blog/2024/RepVGG/"}},{id:"post-popularlibrary",title:"Popularlibrary",description:"\u7b80\u8981\u4ecb\u7ecd",section:"Posts",handler:()=>{window.location.href="/blog/2024/popularLibrary/"}},{id:"post-\u5148\u8fdb\u7684\u5b66\u4e60\u65b9\u6cd5",title:"\u5148\u8fdb\u7684\u5b66\u4e60\u65b9\u6cd5",description:"\u7b80\u8981\u4ecb\u7ecd",section:"Posts",handler:()=>{window.location.href="/blog/2024/%E5%85%88%E8%BF%9B%E7%9A%84%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/"}},{id:"post-one-stage-detection",title:"One Stage Detection",description:"\u7b80\u8981\u4ecb\u7ecd",section:"Posts",handler:()=>{window.location.href="/blog/2024/one-stage-detection/"}},{id:"post-polarization",title:"Polarization",description:"\u7b80\u8981\u4ecb\u7ecd",section:"Posts",handler:()=>{window.location.href="/blog/2024/polarization/"}},{id:"post-vae-vqvae-vagan",title:"Vae Vqvae Vagan",description:"\u7b80\u8981\u4ecb\u7ecd",section:"Posts",handler:()=>{window.location.href="/blog/2024/vae-vqvae-vagan/"}},{id:"post-multiple-object-tracking",title:"Multiple Object Tracking",description:"\u7b80\u8981\u4ecb\u7ecd",section:"Posts",handler:()=>{window.location.href="/blog/2024/Multiple-Object-Tracking/"}},{id:"post-\u77e9\u9635",title:"\u77e9\u9635",description:"Matrix",section:"Posts",handler:()=>{window.location.href="/blog/2024/Matrix/"}},{id:"post-typora-and-jekyll",title:"Typora and Jekyll",description:"this is what included images could look like",section:"Posts",handler:()=>{window.location.href="/blog/2024/images/"}},{id:"news-a-simple-inline-announcement",title:"A simple inline announcement.",description:"",section:"News"},{id:"news-a-long-announcement-with-details",title:"A long announcement with details",description:"",section:"News",handler:()=>{window.location.href="/news/announcement_2/"}},{id:"news-a-simple-inline-announcement-with-markdown-emoji-sparkles-smile",title:'A simple inline announcement with Markdown emoji! <img class="emoji" title=":sparkles:" alt=":sparkles:" src="https://github.githubassets.com/images/icons/emoji/unicode/2728.png" height="20" width="20"> <img class="emoji" title=":smile:" alt=":smile:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f604.png" height="20" width="20">',description:"",section:"News"},{id:"projects-project-1",title:"project 1",description:"with background image",section:"Projects",handler:()=>{window.location.href="/projects/1_project/"}},{id:"projects-project-2",title:"project 2",description:"a project with a background image and giscus comments",section:"Projects",handler:()=>{window.location.href="/projects/2_project/"}},{id:"projects-project-3-with-very-long-name",title:"project 3 with very long name",description:"a project that redirects to another website",section:"Projects",handler:()=>{window.location.href="/projects/3_project/"}},{id:"projects-project-4",title:"project 4",description:"another without an image",section:"Projects",handler:()=>{window.location.href="/projects/4_project/"}},{id:"projects-project-5",title:"project 5",description:"a project with a background image",section:"Projects",handler:()=>{window.location.href="/projects/5_project/"}},{id:"projects-project-6",title:"project 6",description:"a project with no image",section:"Projects",handler:()=>{window.location.href="/projects/6_project/"}},{id:"projects-project-7",title:"project 7",description:"with background image",section:"Projects",handler:()=>{window.location.href="/projects/7_project/"}},{id:"projects-project-8",title:"project 8",description:"an other project with a background image and giscus comments",section:"Projects",handler:()=>{window.location.href="/projects/8_project/"}},{id:"projects-project-9",title:"project 9",description:"another project with an image \ud83c\udf89",section:"Projects",handler:()=>{window.location.href="/projects/9_project/"}},{id:"socials-email",title:"Send email",section:"Socials",handler:()=>{window.open("mailto:%63%65%6B%78%6D@%71%71.%63%6F%6D","_blank")}},{id:"socials-google-scholar",title:"Google Scholar",section:"Socials",handler:()=>{window.open("https://scholar.google.com/citations?user=hWo1RTsAAAAJ","_blank")}},{id:"light-theme",title:"Change theme to light",description:"Change the theme of the site to Light",section:"Theme",handler:()=>{setThemeSetting("light")}},{id:"dark-theme",title:"Change theme to dark",description:"Change the theme of the site to Dark",section:"Theme",handler:()=>{setThemeSetting("dark")}},{id:"system-theme",title:"Use system default theme",description:"Change the theme of the site to System Default",section:"Theme",handler:()=>{setThemeSetting("system")}}];</script> <script src="/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> </body> </html>