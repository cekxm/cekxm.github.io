<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> DINO 如何用于密集预测 | 计算机视觉 </title> <meta name="author" content="Erkang Chen"> <meta name="description" content="如何使用DINO, DPT, RoPE"> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link defer href="/assets/css/bootstrap-toc.min.css?6f5af0bb9aab25d79b2448143cbeaa88" rel="stylesheet"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://cekxm.github.io/blog/2025/dino/"> <script src="/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>initTheme();</script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> 计算机视觉 </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/">blog </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications </a> </li> <li class="nav-item "> <a class="nav-link" href="/projects/">projects </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="row"> <div class="col-sm-3"> <nav id="toc-sidebar" class="sticky-top"></nav> </div> <div class="col-sm-9"> <div class="post"> <header class="post-header"> <h1 class="post-title">DINO 如何用于密集预测</h1> <p class="post-meta"> Created in December 26, 2025 </p> <p class="post-tags"> <a href="/blog/2025"> <i class="fa-solid fa-calendar fa-sm"></i> 2025 </a> </p> </header> <article class="post-content"> <div id="markdown-content"> <h2 id="资料">资料</h2> <ul> <li><a href="https://zhuanlan.zhihu.com/p/1933583851923439816" rel="external nofollow noopener" target="_blank">(3 封私信 / 80 条消息) 万字长文超详解读之DINO全系列—视觉表征对比学习的高峰 - 知乎</a></li> <li><a href="https://zhuanlan.zhihu.com/p/1940400858836742367" rel="external nofollow noopener" target="_blank">(3 封私信 / 80 条消息) 万字长文超详解之DINO-V3（DINO全系列之补充篇） - 知乎</a></li> <li><a href="https://www.youtube.com/watch?v=j2_42Yx_1_w" rel="external nofollow noopener" target="_blank">Inside DINOv2: Architecture Analysis + CIFAR-10 Experiment - YouTube</a></li> <li><a href="https://mashaan14.github.io/YouTube-channel/self_supervised_learning/2025_05_19_SSL" rel="external nofollow noopener" target="_blank">Self-Supervised Learning Review: from SimCLR to DINOv2 | Mashaan blog</a></li> </ul> <blockquote> <p>DINOv3 的发布，标志着计算机视觉进入了类似 NLP 的“GPT-3 时刻”<sup id="fnref:1" role="doc-noteref"><a href="#fn:1" class="footnote" rel="footnote">1</a></sup>。</p> <p><strong>对于学术界：</strong></p> <ul> <li> <strong>Bad News</strong>：传统的“设计一个新 Backbone”、“魔改 Transformer 模块”刷点数的路子越来越窄了。在 7B 模型面前，微小的架构创新几乎没有意义。</li> <li> <strong>Good News</strong>：新的研究方向被打开了。 <ul> <li> <strong>Post-training</strong>：如何更高效地利用这些冻结特征？</li> <li> <strong>多模态对齐</strong>：DINOv3 展示了初步的文本对齐能力，但这方面远未饱和。</li> <li> <strong>视频理解</strong>：利用 DINOv3 强大的时序一致性做原生的视频大模型。</li> </ul> </li> </ul> <p><strong>对于工业界/工程师：</strong></p> <ul> <li> <strong>这是巨大的利好</strong>。你不再需要收集几十万张标注数据去训练一个分割模型。直接下载 DINOv3 的权重，冻结它，用几百张图训练一个轻量级 Head，你就能得到工业级可用的效果。</li> <li> <strong>Deployment</strong>：Meta 提供的蒸馏版小模型（特别是 ViT-Small 和 Base）将是边缘端部署的神器。</li> </ul> <p><strong>DINOv3 并没有让天塌下来，它只是铺平了地基。</strong> 它把提取“好特征”这件最脏最累最费算力的事做完了。现在的我们，可以站在 70 亿参数的肩膀上，去探索视觉智能更上层的逻辑——这何尝不是一种幸运？</p> </blockquote> <h2 id="如何使用-dino">如何使用 DINO</h2> <p>对于 dense prediction，一般要使用多个层的特征，比如 VGGT，以及 dinov3 中的应用部分有提及。</p> <ol> <li> <strong>多层特征提取：</strong> 在 VGGT 的实现细节中，为了生成高分辨率的密集输出（如深度图和点图），模型将来自 DINOv2 骨干网络不同阶段的特征提供给 <strong>DPT（密集预测 Transformer）头</strong>进行处理。具体而言，VGGT 会提取 DINOv2（ViT-L/14）中<strong>第 4、11、17 和 23 块（blocks，实际上就是layer）</strong>的令牌（tokens），并将这些中间层的特征输入 DPT 进行上采样。</li> <li> <strong>与 DINOv3 结合时的用法：</strong> 在 DINOv3 的后续实验中，研究人员将 VGGT 的图像特征提取器更换为 DINOv3 ViT-L。在这种配置下，他们同样使用了 <strong>4 个中间层特征的拼接（concatenation）</strong> 作为下游模块的输入，而不是仅使用最后一层。实验发现，这种使用多个中间层的方法对 DINOv3 带来了性能提升。</li> </ol> <h2 id="dpt">DPT</h2> <p>R. Ranftl, A. Bochkovskiy, and V. Koltun, “Vision transformers for dense prediction,” in <em>Proceedings of the IEEE/CVF International Conference on Computer Vision</em>, 2021, pp. 12173-12183.</p> <p><img src="/images/2025-12-26-dino/image-20251226103424453.png" alt="image-20251226103424453" class="img-fluid"></p> <h3 id="encoder">Encoder</h3> <p>DPT共需要4层的特征，如果用ViT/dino，那这四层的尺寸是一样的。</p> <h3 id="reassemble">Reassemble</h3> <p>Read-&gt;Concatenate-&gt;Resample</p> <p>为了更清楚地理解，可以看它在完整流程中的作用：</p> <ol> <li> <strong>Read：</strong> 处理 CLS 令牌（这里可能涉及拼接投影等线性运算）。</li> <li> <strong>Concatenate：</strong> 将令牌<strong>摆放</strong>回网格位置。</li> <li> <strong>Resamples：</strong> 使用 \(1 \times 1\) 和 \(3 \times 3\) 卷积进行通道投影及空间缩放（这里才进行真正的<strong>卷积运算</strong>）。</li> </ol> <p><strong>总结：</strong> Concatenate 阶段就像是<strong>拼图</strong>。Read 操作决定了每一块拼图（token）上的内容，而 Concatenate 只是<strong>按照位置把拼图摆好</strong>。真正的“修图”和“放大”工作是由接下来的 Resamples 卷积层完成的。</p> <h4 id="read">Read</h4> <p>在 DPT（Dense Prediction Transformer）架构中，<strong>Read 操作</strong>是其核心组件“重组操作”（Reassemble）的<strong>第一阶段</strong>。它的主要任务是处理 Vision Transformer (ViT) 输出的特殊令牌，并将令牌序列转换为可以进行空间排列的形式。</p> <p>以下是 Read 操作的详细介绍：</p> <h5 id="1-核心定义与目的">1. 核心定义与目的</h5> <p>在 ViT 中，输出包含 \(N_p\) 个图像块令牌（patch tokens）和 <strong>1 个特殊的“读取令牌”（readout token，通常指 CLS token）</strong>。</p> <ul> <li> <strong>输入：</strong> \(N_p + 1\) 个令牌。</li> <li> <strong>目的：</strong> 将这 \(N_p + 1\) 个令牌映射回 \(N_p\) 个令牌，以便后续的“拼接操作”（Concatenate）能将它们按照原始图像位置还原成特征图。</li> <li> <strong>数学表达式：</strong> \(Read: \mathbb{R}^{(N_p+1) \times D} \to \mathbb{R}^{N_p \times D}\)。</li> </ul> <h5 id="2-三种实现方案">2. 三种实现方案</h5> <p>DPT 论文评估了处理读取令牌（\(t_0\)）与图像块令牌（\(t_1, \dots, t_{N_p}\)）之间关系的三种不同方式：</p> <ul> <li> <strong>Readignore（忽略）：</strong> 直接<strong>丢弃读取令牌</strong>，只保留 \(N_p\) 个图像块令牌。这是最简单的方法，即 \(Read_{ignore}(t) = {t_1, \dots, t_{N_p}}\)。</li> <li> <strong>Readadd（相加）：</strong> 将读取令牌的信息<strong>加到所有其他令牌上</strong>。即 \(Read_{add}(t) = {t_1 + t_0, \dots, t_{N_p} + t_0}\)。</li> <li> <strong>Readproj（投影/默认方案）：</strong> 通过<strong>拼接后投影</strong>的方式融合信息。将读取令牌与每个图像块令牌拼接，然后通过一个线性层（MLP）将维度投影回原始大小 \(D\)。其公式为：\(Read_{proj}(t) = {mlp(cat(t_1, t_0)), \dots, mlp(cat(t_{N_p}, t_0))}\)。</li> </ul> <h5 id="3-性能表现与结论">3. 性能表现与结论</h5> <p>根据来源中的消融实验结果：</p> <ul> <li> <strong>Readproj 是默认的最优方案</strong>，在单目深度估计等任务中表现略优于其他方案，因为它能更有效地捕获并分配全局信息。</li> <li>相比之下，<code class="language-plaintext highlighter-rouge">Readadd</code> 的效果甚至差于完全忽略令牌的 <code class="language-plaintext highlighter-rouge">Readignore</code>。</li> </ul> <p><strong>总结：</strong> <strong>Read 操作</strong>就像是一个“令牌筛选与融合器”，它决定了如何将 Transformer 学习到的<strong>全局图像表示（读取令牌）*<em>回馈给各个*</em>局部特征（图像块令牌）</strong>，从而确保在进入后续的卷积解码阶段前，每个像素级别的特征都已融入了全局上下文信息。</p> <h4 id="concatenate">Concatenate</h4> <p>在 DPT（Dense Prediction Transformer）的 <strong>Reassemble</strong> 操作中，<strong>Concatenate（拼接）</strong> 阶段本身<strong>不涉及任何复杂的数学运算或学习参数</strong>，它的本质是一个<strong>形状变换（Reshape/Rearrange）</strong>过程。</p> <h4 id="resample">Resample</h4> <p>这一步才真正涉及空间缩放。</p> <ul> <li> <strong>输入：</strong> 空间排列好的特征图，尺寸为 \(\frac{H}{p} \times \frac{W}{p}\)，通道数为 \(D\)。</li> <li> <strong>输出：</strong> 缩放后的特征图，尺寸为 \(\frac{H}{s} \times \frac{W}{s}\)，通道数为 \(\hat{D}\)（DPT 默认 \(\hat{D} = 256\)）。</li> </ul> <p>Resample 通过两步卷积运算来完成变换：</p> <ol> <li> <p><strong>通道投影：</strong> 首先使用 <strong>1x1 卷积</strong>。这一步负责将来自不同 Transformer 层的令牌维度（如 ViT-Large 的 1024 维）投影到解码器所需的统一维度 \(\hat{D}\)。</p> </li> <li> <p>空间缩放：</p> <p>随后根据目标缩放比例 \(s\) 与初始图像块大小 \(p\) 的关系，使用</p> <p>3x3 卷积</p> <p>进行调整：</p> <ul> <li> <strong>下采样（\(s \ge p\)）：</strong> 使用<strong>步长（strided）为 3x3 的卷积</strong>来降低分辨率。</li> <li> <strong>上采样（\(s &lt; p\)）：</strong> 使用<strong>步长为 3x3 的转置卷积（transpose convolution）</strong>来提升分辨率。</li> </ul> </li> </ol> <h3 id="fusion">Fusion</h3> <p>每级上采样2倍。</p> <h2 id="multi-task-image-restoration-guided-by-robust-dino-features">Multi-task image restoration guided by robust DINO features</h2> <p>X. Lin, C. Ren, K. C. Chan, L. Qi, J. Pan, and M. H. Yang, “Multi-task image restoration guided by robust DINO features,” <em>arXiv preprint arXiv:2312.01677</em>, 2023 (v3 revised 2024).</p> <p><img src="/images/2025-12-26-dino/image-20251226133529550.png" alt="image-20251226133529550" class="img-fluid"></p> <p>其核心思路是：传统的图像恢复模型在任务数量增加时性能会下降，而 DINOv2 的深层特征对退化因素不敏感且保留了语义信息，浅层特征则捕获了像素级细节，因此可以作为一种<strong>退化无关的表示</strong>来引导恢复过程。</p> <p>以下是 DINO-IR 的具体实现方法和核心组件：</p> <h3 id="1-核心架构与模块">1. 核心架构与模块</h3> <p>DINO-IR 基于 <strong>Restormer</strong> 架构，并集成了以下三个关键组件：</p> <ul> <li>像素-语义融合模块 (PSF, Pixel-Semantic Fusion)： <ul> <li> <strong>目的：</strong> 动态融合 DINOv2 不同层级的特征。由于浅层包含像素信息，深层包含语义信息，该模块负责提取并加权这些特征。</li> <li> <strong>实现：</strong> 采用<strong>门控网络（Gating Network）*<em>和多个*</em>专家网络（Expert Networks）</strong>。门控网络会根据输入图像自适应地学习浅层、中层和深层特征的权重，将对恢复任务最有益的特征赋予更高的权重进行融合。</li> </ul> </li> <li>DINO-Restore (D-R) 适配与融合模块： <ul> <li> <strong>目的：</strong> 将 DINOv2 的特征集成到图像恢复主模型中。</li> <li> <strong>实现：</strong> 首先通过适配层调整 PSF 融合特征的通道数和尺度，使其与恢复模型对齐。然后采用<strong>基于自注意力的融合方式</strong>：将适配后的 DINO 特征作为 <strong>Query (Q)</strong>，而将恢复模型的中间特征作为 <strong>Key (K)</strong> 和 <strong>Value (V)</strong>，通过交叉注意力机制实现特征融合。</li> </ul> </li> </ul> <h3 id="2-dino-感知对比损失-dpc-loss">2. DINO 感知对比损失 (DPC Loss)</h3> <p>为了约束模型训练，DINO-IR 提出了一种基于 DINOv2 特征空间的<strong>对比学习损失</strong>：</p> <ul> <li> <strong>原理：</strong> 提取恢复后的输出图像、原始清晰图像（正样本）和退化输入图像（负样本）在 DINOv2 隐藏层中的特征。</li> <li> <strong>目标：</strong> 强制要求输出图像的 DINO 特征在空间中尽可能<strong>靠近清晰目标图像</strong>，并尽可能<strong>远离低质量输入图像</strong>。这种损失利用了 DINOv2 特征区分图像质量的能力来提升视觉效果。</li> </ul> <h3 id="3-方法优势">3. 方法优势</h3> <ul> <li> <strong>退化鲁棒性：</strong> DINOv2 特征在不同噪声水平和退化类型下表现出极高的稳定性（方差远低于图像像素特征），这使得模型在处理冲突任务（如去噪需要滤除高频，而去模糊需要增强高频）时更加稳定。</li> <li> <strong>泛化能力：</strong> 实验证明 DINO-IR 在<strong>未见过的退化级别</strong>（如更高强度的噪声）和<strong>未见过的测试数据集</strong>上具有更好的泛化效果。</li> <li> <strong>性能提升：</strong> 在 deraining, denoising, deblurring, dehazing 四项任务的平均 PSNR 表现上，DINO-IR 优于 AirNet 和 PromptIR 等现有先进的多任务恢复方法。</li> </ul> <h3 id="note">Note</h3> <p>作者有做额外实验，DINOv2 的深层特征对退化因素不敏感且保留了语义信息，浅层特征则捕获了像素级细节。</p> <p>It is known that the features extracted from shallow layersof DINOv2 (M, T, and T 2023) can discern low- and high-quality images。</p> <p>根据 DINO-IR（基于鲁棒 DINO 特征引导的多任务图像恢复）的研究资料，其提出的 <strong>DINO 感知对比损失（DINO Perception Contrastive Loss，简称 \(L_{DINO}\) 或 DPC Loss）</strong> 的公式及相关总损失公式如下：</p> <p>该损失函数旨在通过对比学习，使恢复后的图像在 DINOv2 的特征空间中靠近清晰图像，并远离退化的输入图像。公式表达为：</p> \[L_{DINO} = L(v, v^+, v^-) = \sum_{i=1}^n w_i \frac{D(\Psi_i(v), \Psi_i(v^+))}{D(\Psi_i(v), \Psi_i(v^-))}\] <p><strong>参数含义：</strong></p> <ul> <li> <strong>\(v\)</strong>：恢复模型生成的输出图像。</li> <li> <strong>\(v^+\)</strong>：正样本，即对应的<strong>清晰目标图像（Ground Truth）</strong>。</li> <li> <strong>\(v^-\)</strong>：负样本，即<strong>低质量的退化输入图像</strong>。</li> <li> <strong>\(\Psi_i\)</strong>：表示从固定的预训练 DINOv2 模型中提取的第 \(i\) 个隐藏层特征。</li> <li> <strong>\(D(x, y)\)</strong>：表示 \(x\) 与 \(y\) 之间的 <strong>\(L1\) 距离</strong>。</li> <li> <strong>\(w_i\)</strong>：对应层级的权重系数。</li> </ul> <p>作者并没有给出是第几层。但太深的层应该没用。</p> <h2 id="处理任意输入大小图片">处理任意输入大小图片</h2> <p>DINO（包括 DINOv2 和 DINOv3）处理任意大小图片的核心机制在于其 <strong>Transformer 架构的灵活性</strong>、<strong>分块（Patchification）策略</strong>以及<strong>位置编码的动态插值或旋转机制</strong>。</p> <p>以下是具体的实现方式：</p> <h3 id="1-灵活的序列长度处理set-to-set-架构">1. 灵活的序列长度处理（Set-to-set 架构）</h3> <p>DINO 系列模型基于 Vision Transformer (ViT)。与传统的卷积神经网络不同，Transformer 是一种<strong>“集合到集合”（set-to-set）的架构</strong>，它将图像视为一系列令牌（tokens）。</p> <ul> <li> <strong>分块机制：</strong> 图像被切分为固定大小的 patch（例如 DINOv2 使用 \(14 \times 14\)，DINOv3 使用 \(16 \times 16\)）。</li> <li> <strong>令牌数量随分辨率变化：</strong> 当输入图像变大时，模型只会产生更多的令牌，而 Transformer 的自注意力机制（Self-attention）天然可以处理任意长度的输入序列。</li> </ul> <h3 id="2-位置编码的适配核心技术">2. 位置编码的适配（核心技术）</h3> <p>由于 Transformer 本身无法感知令牌的空间顺序，必须加入位置编码。处理不同分辨率图像的关键在于如何让固定长度的位置编码适应变动的令牌数量：</p> <ul> <li> <strong>线性插值（DINOv2/DPT 方案）：</strong> 在 DINOv2 和 DPT 中，如果输入图像的分辨率与训练时的分辨率不同，模型会对预训练的<strong>位置嵌入（Position Embeddings）进行线性插值</strong>。这使得模型能够动态适配到新的令牌网格尺寸，确保每个令牌都能获得其在图像中相对位置的信息。</li> <li> <strong>旋转位置编码（DINOv3 的 RoPE 机制）：</strong> <strong>DINOv3</strong> 引入了更先进的 <strong>RoPE（Rotary Positional Embeddings）</strong> 机制。它将每个 patch 的坐标分配在一个归一化的 \([-1, 1]\) 框内，并在多头注意力操作中根据 patch 间的相对位置应用偏差。</li> <li> <strong>无缝缩放：</strong> 依靠 RoPE 和坐标框抖动（box jittering）技术，DINOv3 能够<strong>在不进行任何适配的情况下无缝处理不同分辨率的图像</strong>。实验显示，即使在远超训练分辨率（如 4k 分辨率）的情况下，DINOv3 仍能保持稳定的特征表现。</li> </ul> <h3 id="3-全局感受野的维持">3. 全局感受野的维持</h3> <p>在卷积网络中，感受野随层数增加而受限，但在 DINO 中，由于使用了全局自注意力机制，<strong>每一个阶段（stage）都拥有全局感受野</strong>。</p> <ul> <li>这意味着无论图像多大，每个令牌都能与图像中的所有其他令牌进行交互。</li> <li>这种特性确保了模型在处理任意大小图片时，都能产生<strong>全局连贯（globally coherent）</strong>且精细的预测结果。</li> </ul> <h3 id="总结">总结</h3> <p>DINO 处理任意大小图片的逻辑可以类比为<strong>“拼图”</strong>：</p> <ul> <li> <strong>分块</strong>是把图片切成小拼块，图越大拼块越多。</li> <li> <strong>Transformer</strong> 是拼图者，他能处理任意数量的拼块。</li> <li> <strong>RoPE 或插值编码</strong> 就像是在每一块拼图背面标注坐标的记号笔，通过动态缩放记号的刻度（坐标），拼图者总能知道每一块在大图中的精确位置。</li> </ul> <h3 id="dinov2-处理任意大小图像的代码">DINOv2 处理任意大小图像的代码</h3> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="n">torch</span>
<span class="kn">import</span> <span class="n">cv2</span>
<span class="kn">import</span> <span class="n">os</span>
<span class="kn">import</span> <span class="n">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="kn">from</span> <span class="n">PIL</span> <span class="kn">import</span> <span class="n">Image</span>
<span class="kn">from</span> <span class="n">sklearn.decomposition</span> <span class="kn">import</span> <span class="n">PCA</span>
<span class="kn">from</span> <span class="n">skimage.color</span> <span class="kn">import</span> <span class="n">hsv2rgb</span>
<span class="kn">from</span> <span class="n">transformers</span> <span class="kn">import</span> <span class="n">AutoImageProcessor</span><span class="p">,</span> <span class="n">AutoModel</span>

<span class="c1"># --- 1. 配置参数 ---
# 图像文件路径 (已设置为您的文件)
</span><span class="n">IMAGE_PATH</span> <span class="o">=</span> <span class="sh">'</span><span class="s">fruits.jpg</span><span class="sh">'</span> 
<span class="c1"># DINOv2 模型 ID (Base 版本，公开且无需权限)
</span><span class="n">MODEL_ID</span> <span class="o">=</span> <span class="sh">"</span><span class="s">facebook/dinov2-base</span><span class="sh">"</span> 
<span class="n">DEVICE</span> <span class="o">=</span> <span class="sh">"</span><span class="s">cuda</span><span class="sh">"</span> <span class="k">if</span> <span class="n">torch</span><span class="p">.</span><span class="n">cuda</span><span class="p">.</span><span class="nf">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="sh">"</span><span class="s">cpu</span><span class="sh">"</span>
<span class="c1"># DINOv2-base 默认 Patch size 为 14x14
</span><span class="n">PATCH_SIZE</span> <span class="o">=</span> <span class="mi">14</span> 
<span class="c1"># 设置一个最小的安全尺寸，防止原图太小
</span><span class="n">MIN_SIZE</span> <span class="o">=</span> <span class="mi">224</span> 

<span class="k">def</span> <span class="nf">visualize_dinov2_features_variable_res</span><span class="p">(</span><span class="n">image_path</span><span class="p">,</span> <span class="n">model_id</span><span class="p">,</span> <span class="n">device</span><span class="p">,</span> <span class="n">patch_size</span><span class="p">,</span> <span class="n">min_size</span><span class="p">):</span>
    <span class="sh">"""</span><span class="s">
    加载 DINOv2 模型，提取 Patch 特征，使用 PCA 降维并可视化。
    图像尺寸会调整到最接近原始尺寸且是 Patch Size 的整数倍。
    </span><span class="sh">"""</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">os</span><span class="p">.</span><span class="n">path</span><span class="p">.</span><span class="nf">exists</span><span class="p">(</span><span class="n">image_path</span><span class="p">):</span>
        <span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">错误: 图像文件未找到于 </span><span class="sh">'</span><span class="si">{</span><span class="n">image_path</span><span class="si">}</span><span class="sh">'</span><span class="s">。请检查路径并重试。</span><span class="sh">"</span><span class="p">)</span>
        <span class="k">return</span>

    <span class="c1"># --- 2. 初始化模型和处理器 ---
</span>    <span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">正在加载 DINOv2 模型: </span><span class="si">{</span><span class="n">model_id</span><span class="si">}</span><span class="s"> 到 </span><span class="si">{</span><span class="n">device</span><span class="si">}</span><span class="s">...</span><span class="sh">"</span><span class="p">)</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="n">processor</span> <span class="o">=</span> <span class="n">AutoImageProcessor</span><span class="p">.</span><span class="nf">from_pretrained</span><span class="p">(</span><span class="n">model_id</span><span class="p">)</span>
        <span class="n">model</span> <span class="o">=</span> <span class="n">AutoModel</span><span class="p">.</span><span class="nf">from_pretrained</span><span class="p">(</span><span class="n">model_id</span><span class="p">).</span><span class="nf">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="n">model</span><span class="p">.</span><span class="nf">eval</span><span class="p">()</span> <span class="c1"># 评估模式
</span>    <span class="k">except</span> <span class="nb">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
        <span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">模型加载失败。请检查模型 ID 或网络连接。</span><span class="se">\n</span><span class="s">错误信息: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>
        <span class="k">return</span>

    <span class="c1"># --- 3. 图像处理与特征提取 (重点修改部分) ---
</span>    <span class="n">img</span> <span class="o">=</span> <span class="n">Image</span><span class="p">.</span><span class="nf">open</span><span class="p">(</span><span class="n">image_path</span><span class="p">).</span><span class="nf">convert</span><span class="p">(</span><span class="sh">"</span><span class="s">RGB</span><span class="sh">"</span><span class="p">)</span>
    <span class="n">W_orig</span><span class="p">,</span> <span class="n">H_orig</span> <span class="o">=</span> <span class="n">img</span><span class="p">.</span><span class="n">size</span>
    <span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">原始图像尺寸 (W x H): </span><span class="si">{</span><span class="n">W_orig</span><span class="si">}</span><span class="s"> x </span><span class="si">{</span><span class="n">H_orig</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>

    <span class="c1"># a. 计算目标输入尺寸 (必须是 PATCH_SIZE 的整数倍)
</span>    <span class="c1"># 取最接近原始尺寸且小于等于原始尺寸的 PATCH_SIZE 倍数
</span>    <span class="n">H_target</span> <span class="o">=</span> <span class="p">(</span><span class="n">H_orig</span> <span class="o">//</span> <span class="n">patch_size</span><span class="p">)</span> <span class="o">*</span> <span class="n">patch_size</span>
    <span class="n">W_target</span> <span class="o">=</span> <span class="p">(</span><span class="n">W_orig</span> <span class="o">//</span> <span class="n">patch_size</span><span class="p">)</span> <span class="o">*</span> <span class="n">patch_size</span>
    
    <span class="c1"># 确保尺寸不小于最小安全尺寸
</span>    <span class="n">H_target</span> <span class="o">=</span> <span class="nf">max</span><span class="p">(</span><span class="n">H_target</span><span class="p">,</span> <span class="n">min_size</span><span class="p">)</span>
    <span class="n">W_target</span> <span class="o">=</span> <span class="nf">max</span><span class="p">(</span><span class="n">W_target</span><span class="p">,</span> <span class="n">min_size</span><span class="p">)</span>

    <span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">模型目标输入尺寸 (W x H): </span><span class="si">{</span><span class="n">W_target</span><span class="si">}</span><span class="s"> x </span><span class="si">{</span><span class="n">H_target</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>
    
    <span class="c1"># b. 预处理
</span>    <span class="c1"># 显式传递 size 和 crop_size 参数，控制预处理器的缩放行为
</span>    <span class="n">inputs</span> <span class="o">=</span> <span class="nf">processor</span><span class="p">(</span>
        <span class="n">images</span><span class="o">=</span><span class="n">img</span><span class="p">,</span> 
        <span class="n">return_tensors</span><span class="o">=</span><span class="sh">"</span><span class="s">pt</span><span class="sh">"</span><span class="p">,</span>
        <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">H_target</span><span class="p">,</span> <span class="n">W_target</span><span class="p">),</span> <span class="c1"># 缩放或调整到目标尺寸
</span>        <span class="n">crop_size</span><span class="o">=</span><span class="p">(</span><span class="n">H_target</span><span class="p">,</span> <span class="n">W_target</span><span class="p">),</span> <span class="c1"># 确保不进行中心裁剪
</span>        <span class="n">do_center_crop</span><span class="o">=</span><span class="bp">False</span> <span class="c1"># 明确禁用中心裁剪
</span>    <span class="p">).</span><span class="nf">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

    <span class="c1"># 实际输入模型张量的尺寸
</span>    <span class="n">h_input</span> <span class="o">=</span> <span class="n">inputs</span><span class="p">[</span><span class="sh">'</span><span class="s">pixel_values</span><span class="sh">'</span><span class="p">].</span><span class="n">shape</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span>
    <span class="n">w_input</span> <span class="o">=</span> <span class="n">inputs</span><span class="p">[</span><span class="sh">'</span><span class="s">pixel_values</span><span class="sh">'</span><span class="p">].</span><span class="n">shape</span><span class="p">[</span><span class="mi">3</span><span class="p">]</span>
    
    <span class="c1"># 重新计算 Patch 网格尺寸 (H, W)
</span>    <span class="n">h</span> <span class="o">=</span> <span class="n">h_input</span> <span class="o">//</span> <span class="n">patch_size</span>
    <span class="n">w</span> <span class="o">=</span> <span class="n">w_input</span> <span class="o">//</span> <span class="n">patch_size</span>
    
    <span class="c1"># c. 提取特征
</span>    <span class="k">with</span> <span class="n">torch</span><span class="p">.</span><span class="nf">no_grad</span><span class="p">():</span>
        <span class="c1"># **inputs 解包字典作为命名参数
</span>        <span class="n">outputs</span> <span class="o">=</span> <span class="nf">model</span><span class="p">(</span><span class="o">**</span><span class="n">inputs</span><span class="p">)</span> 
        <span class="n">features</span> <span class="o">=</span> <span class="n">outputs</span><span class="p">.</span><span class="n">last_hidden_state</span><span class="p">.</span><span class="nf">squeeze</span><span class="p">(</span><span class="mi">0</span><span class="p">).</span><span class="nf">cpu</span><span class="p">().</span><span class="nf">numpy</span><span class="p">()</span>

    <span class="c1"># d. 移除 CLS Token
</span>    <span class="k">if</span> <span class="n">features</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="n">h</span> <span class="o">*</span> <span class="n">w</span> <span class="o">+</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">features</span> <span class="o">=</span> <span class="n">features</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span> 
        <span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">已移除 CLS Token。剩余 Patch 特征形状: </span><span class="si">{</span><span class="n">features</span><span class="p">.</span><span class="n">shape</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">Patch 特征形状: </span><span class="si">{</span><span class="n">features</span><span class="p">.</span><span class="n">shape</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>

    <span class="c1"># --- 4. PCA 降维 ---
</span>    <span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">正在进行 PCA 降维...</span><span class="sh">"</span><span class="p">)</span>
    <span class="n">pca</span> <span class="o">=</span> <span class="nc">PCA</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="mi">3</span><span class="p">).</span><span class="nf">fit</span><span class="p">(</span><span class="n">features</span><span class="p">)</span>
    <span class="n">pca_features</span> <span class="o">=</span> <span class="n">pca</span><span class="p">.</span><span class="nf">transform</span><span class="p">(</span><span class="n">features</span><span class="p">)</span>

    <span class="c1"># 归一化到 [0, 1] 范围
</span>    <span class="n">pca_min</span> <span class="o">=</span> <span class="n">pca_features</span><span class="p">.</span><span class="nf">min</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">pca_max</span> <span class="o">=</span> <span class="n">pca_features</span><span class="p">.</span><span class="nf">max</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">denominator</span> <span class="o">=</span> <span class="n">pca_max</span> <span class="o">-</span> <span class="n">pca_min</span>
    <span class="n">denominator</span><span class="p">[</span><span class="n">denominator</span> <span class="o">==</span> <span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="mf">1e-8</span> 
    <span class="n">pca_features_norm</span> <span class="o">=</span> <span class="p">(</span><span class="n">pca_features</span> <span class="o">-</span> <span class="n">pca_min</span><span class="p">)</span> <span class="o">/</span> <span class="n">denominator</span>

    <span class="c1"># --- 5. 可视化映射 ---
</span>
    <span class="c1"># a. 重塑为网格形状 (H, W, 3)
</span>    <span class="n">pca_grid</span> <span class="o">=</span> <span class="n">pca_features_norm</span><span class="p">.</span><span class="nf">reshape</span><span class="p">(</span><span class="n">h</span><span class="p">,</span> <span class="n">w</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>

    <span class="c1"># b. 映射到 HSV 颜色空间 
</span>    <span class="n">hsv_image</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">zeros_like</span><span class="p">(</span><span class="n">pca_grid</span><span class="p">)</span>
    <span class="n">hsv_image</span><span class="p">[...,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">pca_grid</span><span class="p">[...,</span> <span class="mi">0</span><span class="p">]</span>  <span class="c1"># Hue (色调)
</span>    <span class="n">hsv_image</span><span class="p">[...,</span> <span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="mf">0.8</span>              <span class="c1"># Saturation (饱和度)
</span>    <span class="n">hsv_image</span><span class="p">[...,</span> <span class="mi">2</span><span class="p">]</span> <span class="o">=</span> <span class="n">pca_grid</span><span class="p">[...,</span> <span class="mi">1</span><span class="p">]</span>  <span class="c1"># Value (亮度)
</span>
    <span class="c1"># 转换为 RGB 颜色
</span>    <span class="n">rgb_vis</span> <span class="o">=</span> <span class="nf">hsv2rgb</span><span class="p">(</span><span class="n">hsv_image</span><span class="p">)</span>
    
    <span class="c1"># c. 缩放可视化结果到原始图像大小
</span>    <span class="n">rgb_vis_upscaled</span> <span class="o">=</span> <span class="n">cv2</span><span class="p">.</span><span class="nf">resize</span><span class="p">(</span>
        <span class="n">rgb_vis</span><span class="p">,</span> 
        <span class="p">(</span><span class="n">W_orig</span><span class="p">,</span> <span class="n">H_orig</span><span class="p">),</span> <span class="c1"># 使用原图尺寸进行缩放
</span>        <span class="n">interpolation</span><span class="o">=</span><span class="n">cv2</span><span class="p">.</span><span class="n">INTER_NEAREST</span> <span class="c1"># 最近邻插值保持 Patch 块状效果
</span>    <span class="p">)</span>

    <span class="c1"># --- 6. 显示和保存结果 ---
</span>    <span class="n">plt</span><span class="p">.</span><span class="nf">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>

    <span class="n">plt</span><span class="p">.</span><span class="nf">subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="nf">imshow</span><span class="p">(</span><span class="n">img</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="nf">title</span><span class="p">(</span><span class="sh">"</span><span class="s">原始图像 (Original Image: fruits.jpg)</span><span class="sh">"</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="nf">axis</span><span class="p">(</span><span class="sh">'</span><span class="s">off</span><span class="sh">'</span><span class="p">)</span>

    <span class="n">plt</span><span class="p">.</span><span class="nf">subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="nf">imshow</span><span class="p">(</span><span class="n">rgb_vis_upscaled</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="nf">title</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">DINOv2 特征 PCA 可视化 (</span><span class="si">{</span><span class="n">W_target</span><span class="si">}</span><span class="s">x</span><span class="si">{</span><span class="n">H_target</span><span class="si">}</span><span class="s"> 输入)</span><span class="sh">"</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="nf">axis</span><span class="p">(</span><span class="sh">'</span><span class="s">off</span><span class="sh">'</span><span class="p">)</span>

    <span class="n">plt</span><span class="p">.</span><span class="nf">tight_layout</span><span class="p">()</span>
    <span class="n">output_filename</span> <span class="o">=</span> <span class="sh">"</span><span class="s">dinov2_fruits_pca_visualization.png</span><span class="sh">"</span>
    <span class="n">plt</span><span class="p">.</span><span class="nf">savefig</span><span class="p">(</span><span class="n">output_filename</span><span class="p">)</span>
    <span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">可视化结果已保存为 </span><span class="si">{</span><span class="n">output_filename</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>


<span class="k">if</span> <span class="n">__name__</span> <span class="o">==</span> <span class="sh">"</span><span class="s">__main__</span><span class="sh">"</span><span class="p">:</span>
    <span class="nf">visualize_dinov2_features_variable_res</span><span class="p">(</span><span class="n">IMAGE_PATH</span><span class="p">,</span> <span class="n">MODEL_ID</span><span class="p">,</span> <span class="n">DEVICE</span><span class="p">,</span> <span class="n">PATCH_SIZE</span><span class="p">,</span> <span class="n">MIN_SIZE</span><span class="p">)</span>
</code></pre></div></div> <div class="footnotes" role="doc-endnotes"> <ol> <li id="fn:1" role="doc-endnote"> <p><a href="https://zhuanlan.zhihu.com/p/1986387271688139358" rel="external nofollow noopener" target="_blank">(3 封私信 / 80 条消息) DINOv3 is All You Need? 为什么 DINOv3 发布后，CV 圈感觉“天塌了”？ - 知乎</a> <a href="#fnref:1" class="reversefootnote" role="doc-backlink">↩</a></p> </li> </ol> </div> </div> </article> <br> <hr> <br> <ul class="list-disc pl-8"></ul> <h2 class="text-3xl font-semibold mb-4 mt-12">Enjoy Reading This Article?</h2> <p class="mb-2">Here are some more articles you might like to read next:</p> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2026/uie/">Under water enhancement</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2026/optical_flow/">Optical Flow</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2026/Teaching-Tailored-to-Talent/">Teaching Tailored To Talent</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2025/VINS-and-ESVO2/">Vins And Esvo2</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2025/3dtasks/">3D 任务：SFM, MVS, NVS, VO, VIO, SLAM</a> </li> </div> </div> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2026 Erkang Chen. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script defer src="/assets/js/bootstrap-toc.min.js?c82ff4de8b0955d6ff14f5b05eed7eb6"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>addBackToTop();</script> <script type="module" src="/assets/js/search/ninja-keys.min.js?a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script>let searchTheme=determineComputedTheme();const ninjaKeys=document.querySelector("ninja-keys");"dark"===searchTheme?ninjaKeys.classList.add("dark"):ninjaKeys.classList.remove("dark");const openSearchModal=()=>{const e=$("#navbarNav");e.hasClass("show")&&e.collapse("hide"),ninjaKeys.open()};</script> <script>const ninja=document.querySelector("ninja-keys");ninja.data=[{id:"nav-about",title:"about",section:"Navigation",handler:()=>{window.location.href="/"}},{id:"nav-blog",title:"blog",description:"",section:"Navigation",handler:()=>{window.location.href="/blog/"}},{id:"nav-publications",title:"publications",description:"publications by categories in reversed chronological order. generated by jekyll-scholar.",section:"Navigation",handler:()=>{window.location.href="/publications/"}},{id:"nav-projects",title:"projects",description:"A growing collection of your cool projects.",section:"Navigation",handler:()=>{window.location.href="/projects/"}},{id:"post-under-water-enhancement",title:"Under water enhancement",description:"UIE, U-trans, DNnet, Five A+",section:"Posts",handler:()=>{window.location.href="/blog/2026/uie/"}},{id:"post-optical-flow",title:"Optical Flow",description:"RAFT, SEA-RAFT, Neuflow",section:"Posts",handler:()=>{window.location.href="/blog/2026/optical_flow/"}},{id:"post-teaching-tailored-to-talent",title:"Teaching Tailored To Talent",description:"Prompt, Depth-Anything, Diffusion, Image Restoration",section:"Posts",handler:()=>{window.location.href="/blog/2026/Teaching-Tailored-to-Talent/"}},{id:"post-vins-and-esvo2",title:"Vins And Esvo2",description:"VINS, ESVO, SFM",section:"Posts",handler:()=>{window.location.href="/blog/2025/VINS-and-ESVO2/"}},{id:"post-dino-\u5982\u4f55\u7528\u4e8e\u5bc6\u96c6\u9884\u6d4b",title:"DINO \u5982\u4f55\u7528\u4e8e\u5bc6\u96c6\u9884\u6d4b",description:"\u5982\u4f55\u4f7f\u7528DINO, DPT, RoPE",section:"Posts",handler:()=>{window.location.href="/blog/2025/dino/"}},{id:"post-3d-\u4efb\u52a1-sfm-mvs-nvs-vo-vio-slam",title:"3D \u4efb\u52a1\uff1aSFM, MVS, NVS, VO, VIO, SLAM",description:"\u591a\u89c6\u89d2\u51e0\u4f55\uff0c\u65b0\u89c6\u89d2\u751f\u6210",section:"Posts",handler:()=>{window.location.href="/blog/2025/3dtasks/"}},{id:"post-matplotlib\u8f93\u51fa\u4e2d\u6587",title:"Matplotlib\u8f93\u51fa\u4e2d\u6587",description:"\u7b80\u8981\u4ecb\u7ecd",section:"Posts",handler:()=>{window.location.href="/blog/2025/matplotlib%E8%BE%93%E5%87%BA%E4%B8%AD%E6%96%87/"}},{id:"post-mamba",title:"Mamba",description:"\u7b80\u8981\u4ecb\u7ecd",section:"Posts",handler:()=>{window.location.href="/blog/2025/mamba/"}},{id:"post-flow",title:"Flow",description:"\u7b80\u8981\u4ecb\u7ecd",section:"Posts",handler:()=>{window.location.href="/blog/2025/flow/"}},{id:"post-diffusion",title:"Diffusion",description:"\u7b80\u8981\u4ecb\u7ecd",section:"Posts",handler:()=>{window.location.href="/blog/2025/diffusion/"}},{id:"post-nerf-and-gaussian-splatting",title:"NeRF and Gaussian Splatting",description:"Gaussian Splatting, NeRF, Alpha-blending, Point-Based Rendering, Jacobian",section:"Posts",handler:()=>{window.location.href="/blog/2025/gaussianSplatting/"}},{id:"post-colmap",title:"COLMAP",description:"SFM",section:"Posts",handler:()=>{window.location.href="/blog/2025/sfm-mvs-rendering/"}},{id:"post-\u51b2\u6fc0\u4fe1\u53f7\u7684\u5c3a\u5ea6\u53d8\u6362",title:"\u51b2\u6fc0\u4fe1\u53f7\u7684\u5c3a\u5ea6\u53d8\u6362",description:"this is what included images could look like",section:"Posts",handler:()=>{window.location.href="/blog/2025/impulse/"}},{id:"post-\u4fe1\u53f7\u4e0e\u7cfb\u7edf\u8bfe\u7a0b\u7684\u6570\u5b66\u77e5\u8bc6",title:"\u4fe1\u53f7\u4e0e\u7cfb\u7edf\u8bfe\u7a0b\u7684\u6570\u5b66\u77e5\u8bc6",description:"this is what included images could look like",section:"Posts",handler:()=>{window.location.href="/blog/2025/math/"}},{id:"post-fisheye",title:"Fisheye",description:"\u7b80\u8981\u4ecb\u7ecd",section:"Posts",handler:()=>{window.location.href="/blog/2024/fisheye/"}},{id:"post-montecarlo",title:"Montecarlo",description:"\u7b80\u8981\u4ecb\u7ecd",section:"Posts",handler:()=>{window.location.href="/blog/2024/MonteCarlo/"}},{id:"post-\u5c0f\u6ce2\u5206\u6790",title:"\u5c0f\u6ce2\u5206\u6790",description:"\u7b80\u8981\u4ecb\u7ecd",section:"Posts",handler:()=>{window.location.href="/blog/2024/%E5%B0%8F%E6%B3%A2%E5%88%86%E6%9E%90/"}},{id:"post-lifeifei",title:"Lifeifei",description:"\u7b80\u8981\u4ecb\u7ecd",section:"Posts",handler:()=>{window.location.href="/blog/2024/Lifeifei/"}},{id:"post-orgmode",title:"Orgmode",description:"\u7b80\u8981\u4ecb\u7ecd",section:"Posts",handler:()=>{window.location.href="/blog/2024/orgmode/"}},{id:"post-python\u8fd0\u884c\u811a\u672c\u6216\u6a21\u5757",title:"Python\u8fd0\u884c\u811a\u672c\u6216\u6a21\u5757",description:"\u7b80\u8981\u4ecb\u7ecd",section:"Posts",handler:()=>{window.location.href="/blog/2024/Python%E8%BF%90%E8%A1%8C%E8%84%9A%E6%9C%AC%E6%88%96%E6%A8%A1%E5%9D%97/"}},{id:"post-proximal",title:"Proximal",description:"\u7b80\u8981\u4ecb\u7ecd",section:"Posts",handler:()=>{window.location.href="/blog/2024/proximal/"}},{id:"post-visualtransformer",title:"Visualtransformer",description:"\u7b80\u8981\u4ecb\u7ecd",section:"Posts",handler:()=>{window.location.href="/blog/2024/VisualTransformer/"}},{id:"post-pytorch-note",title:"Pytorch Note",description:"\u7b80\u8981\u4ecb\u7ecd",section:"Posts",handler:()=>{window.location.href="/blog/2024/Pytorch-note/"}},{id:"post-android-opencv-ndk",title:"Android Opencv Ndk",description:"\u7b80\u8981\u4ecb\u7ecd",section:"Posts",handler:()=>{window.location.href="/blog/2024/android-opencv-ndk/"}},{id:"post-repvgg",title:"Repvgg",description:"\u7b80\u8981\u4ecb\u7ecd",section:"Posts",handler:()=>{window.location.href="/blog/2024/RepVGG/"}},{id:"post-popularlibrary",title:"Popularlibrary",description:"\u7b80\u8981\u4ecb\u7ecd",section:"Posts",handler:()=>{window.location.href="/blog/2024/popularLibrary/"}},{id:"post-\u5148\u8fdb\u7684\u5b66\u4e60\u65b9\u6cd5",title:"\u5148\u8fdb\u7684\u5b66\u4e60\u65b9\u6cd5",description:"\u7b80\u8981\u4ecb\u7ecd",section:"Posts",handler:()=>{window.location.href="/blog/2024/%E5%85%88%E8%BF%9B%E7%9A%84%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/"}},{id:"post-one-stage-detection",title:"One Stage Detection",description:"\u7b80\u8981\u4ecb\u7ecd",section:"Posts",handler:()=>{window.location.href="/blog/2024/one-stage-detection/"}},{id:"post-polarization",title:"Polarization",description:"\u7b80\u8981\u4ecb\u7ecd",section:"Posts",handler:()=>{window.location.href="/blog/2024/polarization/"}},{id:"post-vae-vqvae-vagan",title:"Vae Vqvae Vagan",description:"\u7b80\u8981\u4ecb\u7ecd",section:"Posts",handler:()=>{window.location.href="/blog/2024/vae-vqvae-vagan/"}},{id:"post-multiple-object-tracking",title:"Multiple Object Tracking",description:"\u7b80\u8981\u4ecb\u7ecd",section:"Posts",handler:()=>{window.location.href="/blog/2024/Multiple-Object-Tracking/"}},{id:"post-\u77e9\u9635",title:"\u77e9\u9635",description:"Matrix",section:"Posts",handler:()=>{window.location.href="/blog/2024/Matrix/"}},{id:"post-typora-and-jekyll",title:"Typora and Jekyll",description:"this is what included images could look like",section:"Posts",handler:()=>{window.location.href="/blog/2024/images/"}},{id:"news-a-simple-inline-announcement",title:"A simple inline announcement.",description:"",section:"News"},{id:"news-a-long-announcement-with-details",title:"A long announcement with details",description:"",section:"News",handler:()=>{window.location.href="/news/announcement_2/"}},{id:"news-a-simple-inline-announcement-with-markdown-emoji-sparkles-smile",title:'A simple inline announcement with Markdown emoji! <img class="emoji" title=":sparkles:" alt=":sparkles:" src="https://github.githubassets.com/images/icons/emoji/unicode/2728.png" height="20" width="20"> <img class="emoji" title=":smile:" alt=":smile:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f604.png" height="20" width="20">',description:"",section:"News"},{id:"projects-project-1",title:"project 1",description:"with background image",section:"Projects",handler:()=>{window.location.href="/projects/1_project/"}},{id:"projects-project-2",title:"project 2",description:"a project with a background image and giscus comments",section:"Projects",handler:()=>{window.location.href="/projects/2_project/"}},{id:"projects-project-3-with-very-long-name",title:"project 3 with very long name",description:"a project that redirects to another website",section:"Projects",handler:()=>{window.location.href="/projects/3_project/"}},{id:"projects-project-4",title:"project 4",description:"another without an image",section:"Projects",handler:()=>{window.location.href="/projects/4_project/"}},{id:"projects-project-5",title:"project 5",description:"a project with a background image",section:"Projects",handler:()=>{window.location.href="/projects/5_project/"}},{id:"projects-project-6",title:"project 6",description:"a project with no image",section:"Projects",handler:()=>{window.location.href="/projects/6_project/"}},{id:"projects-project-7",title:"project 7",description:"with background image",section:"Projects",handler:()=>{window.location.href="/projects/7_project/"}},{id:"projects-project-8",title:"project 8",description:"an other project with a background image and giscus comments",section:"Projects",handler:()=>{window.location.href="/projects/8_project/"}},{id:"projects-project-9",title:"project 9",description:"another project with an image \ud83c\udf89",section:"Projects",handler:()=>{window.location.href="/projects/9_project/"}},{id:"socials-email",title:"Send email",section:"Socials",handler:()=>{window.open("mailto:%63%65%6B%78%6D@%71%71.%63%6F%6D","_blank")}},{id:"socials-google-scholar",title:"Google Scholar",section:"Socials",handler:()=>{window.open("https://scholar.google.com/citations?user=hWo1RTsAAAAJ","_blank")}},{id:"light-theme",title:"Change theme to light",description:"Change the theme of the site to Light",section:"Theme",handler:()=>{setThemeSetting("light")}},{id:"dark-theme",title:"Change theme to dark",description:"Change the theme of the site to Dark",section:"Theme",handler:()=>{setThemeSetting("dark")}},{id:"system-theme",title:"Use system default theme",description:"Change the theme of the site to System Default",section:"Theme",handler:()=>{setThemeSetting("system")}}];</script> <script src="/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> </body> </html>