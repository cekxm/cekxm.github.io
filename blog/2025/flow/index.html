<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Flow | 计算机视觉 </title> <meta name="author" content="Erkang Chen"> <meta name="description" content="简要介绍"> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link defer href="/assets/css/bootstrap-toc.min.css?6f5af0bb9aab25d79b2448143cbeaa88" rel="stylesheet"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://cekxm.github.io/blog/2025/flow/"> <script src="/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>initTheme();</script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> 计算机视觉 </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/">blog </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications </a> </li> <li class="nav-item "> <a class="nav-link" href="/projects/">projects </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="row"> <div class="col-sm-3"> <nav id="toc-sidebar" class="sticky-top"></nav> </div> <div class="col-sm-9"> <div class="post"> <header class="post-header"> <h1 class="post-title">Flow</h1> <p class="post-meta"> Created in December 25, 2025 </p> <p class="post-tags"> <a href="/blog/2025"> <i class="fa-solid fa-calendar fa-sm"></i> 2025 </a> </p> </header> <article class="post-content"> <div id="markdown-content"> <h1 id="flow-matching">Flow matching</h1> <h2 id="参考资料">参考资料</h2> <h3 id="论文和博客">论文和博客</h3> <p>[1] <a href="https://medium.com/@nikolaus.correll/flow-matching-for-generative-models-from-scratch-8264bad4e0ba" rel="external nofollow noopener" target="_blank">Flow Matching For Generative Models From Scratch | by Nikolaus Correll | Toward Humanoids | Medium</a></p> <p>[2] <a href="https://dl.heeere.com/conditional-flow-matching/blog/conditional-flow-matching/" rel="external nofollow noopener" target="_blank">A Visual Dive into Conditional Flow Matching | ICLR Blogposts 2025</a></p> <h3 id="toy-example">toy example</h3> <p><a href="https://github.com/Whalefishin/Latent_Flow_Matching_MNIST" rel="external nofollow noopener" target="_blank">GitHub - Whalefishin/Latent_Flow_Matching_MNIST: A minimal example for training a flow matching model in a pretrained VAE’s latent space to generate MNIST digits.</a></p> <p><a href="https://github.com/lebellig/discrete-fm" rel="external nofollow noopener" target="_blank">GitHub - lebellig/discrete-fm: Educational implementation of the Discrete Flow Matching paper</a></p> <h2 id="理论">理论</h2> <h3 id="continuous-normalizing-flows">Continuous Normalizing Flows</h3> <p>以下主要参考 [2]</p> <p><img src="/images/2025-12-25-flow/image-20250911165058417.png" alt="image-20250911165058417" class="img-fluid"></p> <p>首先要理解这个图。</p> <ul> <li> <p>概率路径 \(p_t\) 指 \(t\) 时刻 \(x\) 的概率分布 \(p_t(x)\)，一般令 \(p_0(t)\) 是一个标准的高斯分布，\(p_1(t)\) 是我们要建模的、未知的分布。概率路径就是从0时刻到1时刻，概率分布的变化过程。</p> </li> <li> <p>速度场 \(u(x,t)\) 比较好理解</p> </li> <li> <p>flow 就是流，类似水流，水流中 \(x\) 位置的一个水滴（假设它有独特的标记），经过 \(t\) 时候，会跟随水流移动到 \(f(x,t)\) 位置。 \(f(x,t)\) 可以看成一个映射，\(f^u: \mathbb{R}^d \times[0, 1] \to \mathbb{R}^d\)</p> </li> <li> <p>和 flow 有关系的另一个变量是 \(x(t)\) ,也是表示原处于 \(x_0\) 位置的点随时间t的变化，见下面这个常微分方程（ODE），它很好理解，速度是位置的导数。</p> </li> </ul> \[\begin{cases} x(0) = x_0 \\ \partial_t x(t) = u(x(t), t) \quad \forall t \in [0, 1] \end{cases}\] <p>在文献[2]中，\(\partial_t\) 就是指 \(\frac{\partial}{\partial t}\)。上式也叫 initial value problem（初值问题）。flow \(f^u(x,t)\) defined as the solution at time \(t\) to the initial value problem driven by \(u\) with initial condition \(x(0)=x\).</p> <p>上面这个图，三个要素形成三角关系。</p> <ul> <li>flow 和速度场之间是 ODE 的关系，知道速度场，可以求解 flow。\(f^u(x,t)\) 是它的解，\(x\) 实际上是初值。</li> <li>概率路径和速度场之间满足连续性方程</li> </ul> \[\begin{equation}\label{eq:continuity_eq} \partial_t p_t + \nabla\cdot u_t p_t = 0 \end{equation}\] <p>其中 \(\nabla\cdot\) 表示散度。这个方程保证了概率质量的守恒：概率密度在空间中的变化（通过时间导数 \(\frac{\partial p_t(x)}{\partial t}\)）由概率流量的散度决定。</p> <ul> <li>概率路径和flow之间满足 <em>change-of-variable formula</em>，也称为 pushforward \(p_t = f^u(\cdot, t)\# p_0\)。就是说通过这个流，把 \(p_0\) 经时间t，变为 \(p_t\)。</li> </ul> <p>以下是AI关于change-of-variable formula的介绍。</p> <p><strong>Change-of-variable formula</strong> 描述了概率密度如何随这种映射变化。对于一个可逆的映射 \(\phi_t: x_0 \mapsto x_t\) （可逆映射在这边就是flow，它是一个映射，并且是可逆的），概率密度 \(p_t(x_t)\) 与初始密度 \(p_0(x_0)\) 的关系为： \(p_t(x_t) = p_0(x_0) \cdot \left| \det\left( \frac{\partial \phi_t^{-1}}{\partial x_t} \right) \right| = p_0(\phi_t^{-1}(x_t)) \cdot \left| \det\left( \frac{\partial x_0}{\partial x_t} \right) \right|\) 其中：</p> <ul> <li>\(\phi_t^{-1}\) 是逆映射，从 \(x_t\) 映射回 \(x_0\)。</li> <li>\(\det\left( \frac{\partial x_0}{\partial x_t} \right)\) 是逆映射的雅可比行列式的绝对值。</li> </ul> <p>在流匹配中，雅可比行列式反映了流映射如何缩放空间，从而影响概率密度。</p> <blockquote> <p>我之前有疑问，从 \(x_0\) 到 \(x_t\) 可能经过了很长的距离变化，怎么这两个位置之间的密度能建立联系？答案可能是因为流是连续的，\(x_0\) 附近的质量都会流到 \(x_t\) 附近，这个变化由雅可比行列式来决定。</p> </blockquote> <h3 id="conditional-flow-matching">Conditional Flow Matching</h3> <p>可能，flow matching 就是指 conditional flow matching.</p> <p>CFM 核心思想是选择一个条件变量 \(z\)，以及一个条件概率路径 \(p(x\mid t,z)\)，满足两点</p> <ol> <li>由 \(p(x\mid t,z)\)​ 推导出的全局概率路径 \(p(x\mid t)\)​ 可以把 \(p_0\)​ 转化为 \(p_{data}\)​。即要求 \(p(x\mid t,z)\) 在 t=0,t=1 的边际概率 \(p(x\mid t=0)\)，\(p(x\mid t=1)\)符合</li> </ol> \[\begin{align*} \forall x \space E_z [ p(x \vert z, t=0) ] = p_0(x) , \\ \forall x \space E_z [ p(x \vert z, t=1) ] = p_{data}(x). \end{align*}\] <ol> <li>\(p(x\mid t,z)\) 对应的条件速度场 \(u^{cond}(x,t,z)\) （回忆一下，二者的关系是连续性方程）具有一个解析的形式，这是因为要使用一个神经网络来回归条件速度场。</li> </ol> <p>文中用下图进行概括：</p> <p><img src="/images/2025-12-25-flow/image-20250911233204539.png" alt="image-20250911233204539" class="img-fluid"></p> <ul> <li> <p>首先，要做出 choice 1</p> </li> <li> <p>然后做出 choice 2（必须满足要求1）</p> </li> <li> <p>\(p(x\mid t,z)\) 能够确定 \(u^{cond}(x,t,z)\) ，它们之间满足连续性方程</p> </li> <li> <p>\(p(x\mid t,z)\) 边际化 \(z\) 可以获得 \(p(x\mid t)\)</p> </li> <li> <p>\(p(x\mid t)\) 和速度场 \(u(x,t)\) 之间满足连续性方程</p> </li> <li> <p>\(u(x,t)\)可由 \(u^{cond}(x,t,z)\)​ 显式的表达，这个关系就是文中的Theorem 1:</p> </li> </ul> \[\begin{align} \forall t, x, \, \, u(x,t) &amp;= E_{z\mid x, t} {u^{cond} }(x,t,z) \end{align}\] <ul> <li>实际计算中，并不是通过这个表达式去获得 \(u(x,t)\)。而是使用一个神经网络来回归条件速度场。那回归条件速度场有什么用呢？这个解释是文中的 Theorem 2. 即使用下面这个Loss来回归条件速度场，</li> </ul> \[\begin{aligned} \mathcal{L}^{\mathrm{CFM}}(\theta) &amp; \overset{\mathrm{def}}{=} E_{ \substack{t \sim \mathcal{U}([0, 1]) \\ z \sim p_z \\ x \sim p( \cdot \mid t, z) } }{\lVert u_\theta^{CFM}(x,t) - \underbrace{u^{cond}(x,t,z)}_{\substack{ \text{chosen to be} \\ \text{explictly defined}, \\ \text{cheap to compute}, \\ \text{e.g., } x_1 - x_0}} \rVert^2} \enspace, \end{aligned}\] <p>等价于回归不可知的速度场</p> \[\begin{align*} \mathcal{L}^{\mathrm{CFM}}(\theta) &amp; \underset{(\text{proof below})}{=} E_{\substack{ t \sim \mathcal{U}([0, 1]) \\ x \sim p_t} } \Vert{u_\theta^{CFM}(x,t) - \underbrace{u(x,t)}_{\substack{\text{implicitly defined,} \\ \text{hard/expensive} \\ \text{to compute}}}}\Vert^2 + \underbrace{C}_{\text{indep. of } \theta} \end{align*}\] <p>Theorem 2 的证明使用了Theorem 1.</p> <p>因此，我们用神经网络去逼近条件速度 \(u^{cond}(x,t,z)\)，最终学习得到的是经过点 \((x,t)\) 的所有轨迹的平均速度，这个平均速度也就是 \(u(x,t)\)。</p> <h1 id="mean-flow">Mean flow</h1> <h2 id="mean-flow-论文中的-flow-matching-定义">mean flow 论文中的 flow matching 定义</h2> <p>flow 的 0 时刻为 \(p_{data}(x)\)，1 时刻为 \(p_{prior}(\epsilon)\)。flow 是把数据映射为先验（一版是高斯噪声），和之前定义的映射反过来了。给定\(x\sim p_{prior}(\epsilon)\)， \(x\sim p_{data}(x)\)，定义 flow path: \(z_t=a_t x+b_t \epsilon\)，其中 \(a_t\) , \(b_t\) 是 predifined schedules.</p> <blockquote> <p>可能，只要满足 \(z_0=\epsilon\), \(z_1=x\) 就行。</p> </blockquote> <p>比较常用的是，\(a_t=1-t\), \(b_t=t\)。由于速度 \(v_t = z'_t=a'_t x+b'_t \epsilon\)，因此 \(v_t = \epsilon - x\)。</p> <p>给定速度场 \(v(z_t,t)\)，通过求解 ODE 来进行数据采样 \(z_t\): \(\frac{d}{dt} z_t=v(z_t,t)\) starting from \(z_1=\epsilon\)。注意，这个初值问题的初值是 \(z_1\)。所以是从 \(t=1\) 倒推的。解可以写成 \(z_r=z_t - \int_r^t v(z_r,r)dr\) 实现时，是用数值解，比如欧拉法 \(z_{t_{i+1}}=z_{t_{i}}+(t_{i+1}-t_i)v(z_{t_{i}},t_i)\) 注意，这两个式子没有矛盾。倒推时，\(t_{i+1}-t_i&lt;0\)，速度取的时间是 \(t_i\)。</p> <h2 id="mean-flows">mean flows</h2> <p>定义平均速度 \(u\)： \(u(z_t,r,t) \triangleq \frac{1}{t-r}\int_r^tv(z_r,r)dr\) 用一个神经网络 \(u_\theta(z_t,r,t)\) 来预测平均速度 \(u\)。在训练时，就需要它的真值。经过推导可得 \(u(z_t,r,t) = v(z_t,t)-(t-r)\frac{d}{dt}u(z_t,r,t)\)</p> \[\frac{d}{dt}u(z_t,r,t) =v(z_t,t)\partial_z u +\partial_t u\] <p>可以看出，要知道真值，需要真值对时间的微分，这没法获得。所以实际使用的真值是 \(u_{tgt} = v(z_t,t)-(t-r)(v(z_t,t)\partial_z u_\theta +\partial_t u_\theta)\) 即在计算微分时，用参数化的 \(\partial u_\theta\) 来代替 \(\partial u\)。并且回顾一下神经网络的训练，真值用于计算 loss，它本身一般是一个固定值。而在这边真值和 \(u_\theta\) 有关系，所以需要额外设定它不参与微分计算，否则就会 “double backpropagation”。 \(\mathcal{L}(\theta)=E\parallel u_\theta(z_t,r,t) - sg(u_{tgt})\parallel_2^2\) <img src="/images/2025-12-25-flow/image-20251012141549566.png" alt="image-20251012141549566" class="img-fluid"></p> <h2 id="mean-flows-with-guidance">Mean Flows with Guidance</h2> <p>classifier-free guidance</p> <p>推导看得不是很懂，但是训练过程，如下</p> <p><img src="/images/2025-12-25-flow/image-20251013095354856.png" alt="image-20251013095354856" class="img-fluid"></p> <p>有区别的地方在于式（19），\(v_t\) 是 \(\epsilon -x\)，\(u_\theta^{cfg}(z_t,t,t)\)注意后面的两个时间都是 t，它是一个速度。</p> <p>上面 \(\omega\) 表示引导的强度。对照原版的CFG，原版的CFG还在训练时是没有 \(\omega\) 的，只在采样时使用，在训练时，有一步骤是以一定概率不给class，即 \(c=\empty\)。此处，同样有这步。</p> <h1 id="2025-cvpr-reversing-flow-for-image-restoration">2025 CVPR Reversing Flow for Image Restoration</h1> <p>论文强调了<strong>不确定范围（uncertainty scope）</strong>的概念（如图1所示）：从HQ到LQ的退化过程遵循数据处理不等式（Data Processing Inequality, DPI），即HQ与中间图像之间的互信息（mutual information）逐渐减少。随着退化加深，LQ图像的“不确定范围”扩大——多个HQ图像可能退化到相似的LQ图像（例如，不同清晰图像添加雾霾后变得相似）。图1直观描绘了这一过程：灰色区域表示从中间状态的不确定范围，随着从LQ向HQ逆转，不确定范围缩小，互信息增加。</p> <p>现有生成模型（如扩散模型或分数匹配模型）通常将退化过程建模为<strong>随机变换（stochastic transformation）</strong>，从高斯噪声开始逆向生成HQ图像。这引入了不必要的复杂性和计算开销（如数百步采样），因为<strong>LQ图像已提供结构信息，无需从纯噪声重构</strong>。论文指出，这种随机性导致训练和推理效率低下，且忽略了退化过程的确定性本质。</p> <p>ResFlow的核心动机：将退化过程重新定义为<strong>确定性路径（deterministic path）</strong>，使用连续归一化流（Continuous Normalizing Flows）实现可逆映射，从而高效逆转退化，仅需少于4步采样。</p> <blockquote> <p>这是论文的第一个评论，扩散模型属于随机前向过程，论文认为是不好的。flow matching 是确定性前向过程。但这个评论和从高斯噪声开始采样不是同一个问题。</p> <p>论文认为，从高斯噪声开始采样没有必要，因为LQ图像已提供结构信息。</p> <p>有一些扩散模型的方法从LQ图像开始恢复，比如论文第二页罗列的一些。但是论文说这些方法依然是随机前向过程。However, these approaches still treat the degradation process as a progressively diffusing stochastic forward process, which seems unnecessary and introduces additional complexity and inefficiency. Given that the degraded image is already known, the degradation process could be redefined as a deterministic forward process.</p> </blockquote> <table> <thead> <tr> <th>方法</th> <th>t=0 分布（起始/目标分布）</th> <th>t=T 分布（结束/噪声分布）</th> <th>关键特点</th> </tr> </thead> <tbody> <tr> <td><strong>DDRM [38]</strong></td> <td>清晰图像分布（HQ/clean image distribution）。恢复过程的最终输出 x_0 是估计的 HQ 图像。</td> <td>近似噪声分布（approximated noise distribution，通常高斯噪声 N(0, I)）。x_T 是 Markov 链的起始，条件于退化观测 y = H x + z（H 是退化算子，z 是已知噪声）。</td> <td>基于预训练 DDPM，解决线性逆问题（如去模糊、超分辨率）。前向从 HQ 扩散到噪声；逆向从噪声恢复 HQ，条件于 LQ（degraded image）。</td> </tr> <tr> <td><strong>IR-SDE [64]</strong></td> <td>清晰图像分布（HQ/high-quality image x(0)）。</td> <td>退化图像的噪声版本（LQ + fixed Gaussian noise, μ + ε，其中 μ 是 LQ，ε ~ N(0, σ²I)）。</td> <td>使用 mean-reverting SDE 建模退化过程，从 HQ 扩散到 noisy LQ。逆向从 noisy LQ 开始恢复 HQ。非 Markov 链，而是连续 SDE。</td> </tr> <tr> <td><strong>I2SB [55]</strong></td> <td>一个给定分布（通常清晰图像分布 HQ/clean data distribution）。</td> <td>另一个给定分布（退化图像分布 LQ/degraded data distribution）。</td> <td>构建 Schrödinger bridge（扩散桥），直接连接两个分布（clean 和 degraded）。非线性扩散过程，从 LQ 桥接到 HQ。边界对：t=0 为 clean，t=T 为 degraded（或反之）。</td> </tr> <tr> <td><strong>ResShift [112]</strong></td> <td>高分辨率图像分布（HR/high-resolution image distribution）。初始状态近似 HR。</td> <td>低分辨率图像分布（LR/low-resolution image distribution）。最终状态近似 LR。</td> <td>通过 shifting residual 在 HR 和 LR 之间构建 Markov 链。针对超分辨率（SR），减少步数；t=0 为 HR，t=T 为 LR。</td> </tr> <tr> <td><strong>RDDM [57]</strong></td> <td>目标图像分布（HQ/target image distribution）。</td> <td>纯噪声分布（pure noise, N(0, I)）用于生成；或噪声携带的输入图像（noise-carrying input, LQ + noise）用于恢复。</td> <td>双重扩散：residual diffusion（从 HQ 到 LQ 的定向扩散）和 noise diffusion（随机扰动）。统一生成和恢复；t=T 根据任务调整（纯噪声或 noisy LQ）。</td> </tr> <tr> <td><strong>Resfusion [89]</strong></td> <td>原图像分布（ground truth/original image distribution）。</td> <td>noisy degraded 图像分布（noisy degraded images, LQ + weighted residual noise）。</td> <td>将 residual term 引入前向过程，从 noisy LQ 开始逆过程。预测 resnoise（weighted residual + noise）；t=0 为 HQ，t=T 为 noisy LQ。统一训练/推理。</td> </tr> </tbody> </table> <p>因此论文，要 reverses the deterministic paths between HQ and LQ images for image restoration。即要使用flow matching 方法，同时从 LQ开始进行恢复。这样的问题是前面谈到的不确定范围。</p> <p>但直接用flow来建模HQ到LQ的退化是不可以的。这是因为退化导致互信息下降（信息处理不等式），而flow对应的ODE却会保持互信息不变。见命题1</p> <h2 id="命题1">命题1</h2> <p>flow 的 OED 保持互信息不变。 \(MI(z_{t_1}, r) = MI(z_{t_2}, r),\) 其中：</p> <p>\(z_t\) 是随时间 \(t\) 变化的随机过程（random process），由普通微分方程（ODE）定义：\(\frac{\partial z_t}{\partial t} = v(z_t, t)\)。 \(r\) 是任意参考随机变量（reference random variable），可以是 \(z_t\) 的任意状态（如 \(z_0\) 或其他 \(z_{t'}\)）。 \(MI(\cdot, \cdot)\) 表示互信息，定义为两个随机变量之间的共同信息量，数学上等价于： \(MI(X, Y) = H(X) + H(Y) - H(X, Y),\) 其中 \(H(X)\) 和 \(H(Y)\) 分别是 \(X\) 和 \(Y\) 的熵，\(H(X, Y)\) 是联合熵。</p> <h2 id="逆转流的基本形式reversing-flow-for-image-restoration">逆转流的基本形式（Reversing Flow for Image Restoration）</h2> <p>退化过程定义为随机过程{zt | 0 ≤ t ≤ 1}上的ODE： \(\frac{\partial z_t}{\partial t} = v(z_t, t); \quad 0 \leq t \leq 1,\) 其中v是速度场（velocity field），z_0对应HQ图像x_HQ，z_1对应LQ图像x_LQ。</p> <table> <tbody> <tr> <td>为使过程可逆，引入辅助过程{yt</td> <td>0 ≤ t ≤ 1}，增强状态：</td> </tr> </tbody> </table> \[z_t^T = [x_t^T; y_t^T], \quad z_0^T = [x_{HQ}^T; y_0^T], \quad z_1^T = [x_{LQ}^T; y_1^T].\] <p>yt编码“信息丢失”，与不确定范围耦合：当x_t接近x_LQ时，y_t与x_0的互信息增加，以保持整体MI(z_t, z_0)恒定</p> <p>。图2框架：zt由数据组件x_t（HQ到LQ）和辅助组件y_t（不确定范围缩小）组成。前向过程通过插值定义，逆向过程通过匹配速度场学习。神经网络v_θ估计速度： \(\frac{\partial [x_t^T; y_t^T]^T}{\partial t} = v_\theta(x_t, y_t, t).\)</p> <p>在实际实现中，\(y_0=0\), \(y_1\sim N(0,I)\).从 \(y_0\) 到 \(y_1\) 熵是增加的。</p> <h2 id="resflow-训练过程算法步骤">ResFlow 训练过程算法步骤</h2> <p>论文中的训练过程基于速度场匹配（velocity field matching），通过最小化Eq. (9)的损失函数实现。采用U-Net架构作为v_θ，Adam优化器，训练在256分辨率图像crops上进行。以下是算法步骤伪代码： text算法: ResFlow 训练过程</p> <p>输入: HQ-LQ图像对数据集 {(x0, x1)}，超参数 β=10, γ=1.75, 学习率 (详见Appendix C) 输出: 训练好的速度场网络 v_θ</p> <ol> <li> <p>初始化神经网络 v_θ (采用DDPM的U-Net架构，timestep t 通过adaptive layer normalization嵌入)</p> </li> <li> <p>对于每个训练epoch: a. 从数据集采样一个batch的HQ-LQ对 (x0, x1) b. 对于每个样本: i. 设置 y0 = 0 (零向量) ii. 采样 y1 ~ N(0, I) (标准高斯分布) iii. 定义退化调度: α^x_t = 1 - t, σ^x_t = t (对于数据组件 x) α^y_t = 1 - σ^y_t, σ^y_t = β / (1 - t + β) (对于辅助组件 y, 熵保持) iv. 计算路径点 (geodesics): x_t = α^x_t * x0 + σ^x_t * x1 y_t = α^y_t * y0 + σ^y_t * y1 z_t = [x_t; y_t] (增强状态) ˙z_t = [˙α^x_t * x0 + ˙σ^x_t * x1; ˙α^y_t * y0 + ˙σ^y_t * y1] (真实速度) v. 通过网络预测速度: v_θ(x_t, y_t, t) vi. 计算时间权重: λ(t) = [cos(π/2 * (t - 2)) + 1]^γ (强调t接近1) vii. 计算损失: L = ∫_0^1 λ(t) * ||v_θ(x_t, y_t, t) - ˙z_t||^2_2 dt (积分近似或蒙特卡罗采样t) c. 平均batch损失 d. 使用Adam优化器更新 θ (反向传播)</p> </li> <li> <p>重复步骤2直到收敛 (详见Appendix C的超参数，如学习率、batch size) 注意：损失优化确保凸传输成本非增，且无需模拟ODE（与传统流方法不同）。训练强调t接近1的困难样本，以平衡梯度。 ResFlow 采样过程算法步骤 论文中的采样（推理）过程基于逆向求解ODE Eq. (6)，从LQ图像开始，仅需4步采样（uniform time schedule）。以下是算法步骤伪代码： text算法: ResFlow 采样过程 (图像恢复)</p> </li> </ol> <p>输入: 低质量图像 x1 (LQ), 训练好的 v_θ, 步数 N=4 (默认) 输出: 恢复的高质量图像 ˆx0 (HQ)</p> <ol> <li> <p>采样辅助变量: y1 ~ N(0, I) (标准高斯分布)</p> </li> <li> <p>初始化增强状态: z1 = [x1; y1]</p> </li> <li> <p>设置时间步: t 从1到0，分N=4步 (uniform schedule, e.g., Δt = 1/N)</p> </li> <li> <p>对于每个时间步 i 从1到N: a. 当前 t = 1 - (i-1)/N b. 预测速度: v = v_θ(z_t 的 x 组件, z_t 的 y 组件, t) c. 更新状态: z_{t-Δt} = z_t - v * Δt (Euler方法或更高阶如Heun求解ODE dz/dt = v(z, t)) d. (可选) 替换中间 ˆy_t 为 ground-truth y_t = α^y_t * 0 + σ^y_t * y1 (基于Eq.(5)，但概念上丢弃 ˆy_t)</p> </li> <li> <p>从最终 z0 提取 ˆx0 (丢弃 ˆy0)</p> </li> <li> <p>输出 ˆx0 作为恢复图像 (全分辨率测试) 注意：采样是确定性的（无随机噪声注入），通过辅助y消除不确定性。论文实验显示此过程在&lt;4步内完成，适用于实时应用。</p> </li> </ol> <h1 id="pnp-flow-plug-and-play-image-restoration-with-flow-matching">PNP-FLOW: PLUG-AND-PLAY IMAGE RESTORATION WITH FLOW MATCHING</h1> <p>pnp 方法的洞见是 <em>the proximal</em> step on the regularization term is effectively a denoising operation. 因此近端算子可以用BM3D或神经网络。</p> <p>本文的出发点是，近来生成模型提供了智能的框架来从数据直接学习 priors，可以超越人工设计或神经网络去噪器。</p> <h2 id="图像恢复的数学问题">图像恢复的数学问题</h2> <p>在论文的引言部分，图像恢复（image restoration）问题被表述为从退化观测（degraded observation）\(y\) 恢复未知图像 \(x\) 的逆问题（inverse problem），其中 \(y = Hx + \xi\) 这里，\(H\) 是一个（线性）退化算子（degradation operator），\(\xi\) 表示加性噪声（additive noise）模型。由于该问题是病态的（ill-posed）和高维的，求解具有挑战性。 论文假设图像 \(x\) 来自具有密度 \(p_X\) 的随机变量 \(X\)，观测 \(y\) 来自具有密度 \(p_Y\) 的随机变量 \(Y\)。然后，使用最大后验（maximum a posteriori, MAP）估计器求解具有最高后验概率的值： \(\arg\max_{x \in \mathbb{R}^d} \left[ \log p_{X\mid Y=y}(x) \right] = \arg\max_{x \in \mathbb{R}^d} \left[ \log p_{Y\mid X=x}(y) + \log p_X(x) \right],\) 其中右侧第一项是数据保真（fidelity to the data），第二项是图像的先验分布（prior distribution）。 由于 \(p_X\) 通常未知，且缺乏训练数据，论文转而考虑一个正则化优化问题（regularized optimization problem）： \(\arg\min_{x \in \mathbb{R}^d} \left\{ F(x) + R(x) \right\},\) 其中 \(F(x) := -\log p_{Y\mid X=x}(y)\) 表示数据保真项（data-fidelity term），\(R : \mathbb{R}^d \to \mathbb{R}\) 通常强制对解的一些假设（enforces some assumptions on the solution），以确保（唯一）最小化器的存在。例如，对于高斯噪声 \(\mathcal{N}(0, \sigma^2 I_d)\)，数据保真项对应 \(F(x) = \frac{1}{2\sigma^2} \\mid Hx - y\\mid ^2.\) 该优化问题可以通过近端分裂方法（proximal splitting methods）有效求解。</p> <h2 id="pnp方法">PNP方法</h2> <p><img src="/images/2025-12-25-flow/image-20251014191145906.png" alt="image-20251014191145906" class="img-fluid"></p> <h2 id="pnp-meets-flow-matching"> <em>P<strong>N</strong>P</em> <em>MEETS</em> FLOW <em>MATCHING</em> </h2> <p>PnP-Flow定义时间相关去噪器： \(D_t := \mathrm{Id} + (1 - t) v^\theta_t,\)</p> <blockquote> <p>这个去噪器的前提是直线路径，所以训练这个去噪器使用OT coupling 或 reflow. \(\pi\) 是耦合（optimal transport耦合可产生直线路径）。</p> </blockquote> <blockquote> <p>对于最优传输（OT）耦合，有：</p> </blockquote> \[v_t(f(t, x)) = T(x) - x, \tag{5}\] <blockquote> <p>其中 \(T\) 是Monge映射。</p> </blockquote> <p>在理想情况下： \(D_t(x) = \mathbb{E}[X_1 \mid X_t = x],\) 其中 \(X_t = (1-t)X_0 + t X_1\)。对于直线路径，去噪损失为0（Proposition 1）。</p> <p><img src="/images/2025-12-25-flow/image-20251014220345497.png" alt="image-20251014220345497" class="img-fluid"></p> <p>注意：</p> <ol> <li>PnP flow 中的flow 是预训练的。上述算法没有训练，而是迭代的图像恢复过程。</li> <li>其中 \(t_n\) 从小到大。其中 \(\tilde{z}^n\) 这一步有使用插值，使用插值的原因在下一小节。\(t_n\) 越小，插值时，加的噪声越大。</li> </ol> <p><img src="/images/2025-12-25-flow/image-20251014230941949.png" alt="image-20251014230941949" class="img-fluid"></p> <p>注意 \(t=0\) 时，\(\tilde{z}^n=\epsilon\)，从噪声直接去噪，再指向 \(y\)。</p> <h2 id="为什么要插值">为什么要插值</h2> <p>在PnP-Flow算法中，插入插值步（interpolation step）的目的是确保去噪器 \(D_t\) 能够有效工作，这与Flow Matching（FM）模型的特性以及算法的迭代过程密切相关。以下是详细的解释：</p> <h3 id="原因与背景">原因与背景</h3> <p>PnP-Flow结合了PnP框架与FM模型，其中去噪器 \(D_t\) 是基于预训练的FM速度场 \(v^\theta_t\) 定义的： \(D_t = \mathrm{Id} + (1 - t) v^\theta_t. \tag{6}\) 理想情况下，\(D_t(x)\) 将路径上的点 \(X_t = (1-t)X_0 + t X_1\) 投影回目标分布 \(P_1\) 的样本 \(X_1\)，其中 \(X_0 \sim P_0\)（潜在分布），\(X_1 \sim P_1\)（数据分布），\((X_0, X_1) \sim \pi\)（耦合）。然而，传统PnP-FBS算法的迭代点（通过梯度步更新后）不一定位于FM路径 \(X_t\) 上，而 \(D_t\) 的设计假设输入点在该路径上。如果输入点偏离 \(X_t\) 的支持集，去噪效果会显著下降。</p> <h3 id="插值步的必要性">插值步的必要性</h3> <p>论文在第5页（Section 3.2）中指出，经典PnP-FBS直接在梯度步后应用去噪器，但由于 \(D_t\) 针对 \(X_t\) 优化，若梯度步输出的 \(z\) 不位于 \(X_t\) 支持集，效果不佳。因此，引入插值步将 \(z\) “投影”回FM路径。</p> <h3 id="技术细节与动机">技术细节与动机</h3> <ul> <li> <strong>路径一致性</strong>：FM模型（尤其是OT-FM）产生直线路径 \(X_t = (1-t)X_0 + t X_1\)。插值步确保迭代点与此路径对齐，从而利用 \(D_t\) 的最佳性能（Proposition 1表明直线路径下去噪损失为0）。</li> <li> <strong>避免退化</strong>：若不插值，\(D_t\) 可能将 \(z^n\) 映射到不相关区域，特别是在 \(t\) 接近1时，\(D_t\) 趋于恒等变换（\(D_1 = \mathrm{Id}\)），导致算法退化为仅依赖数据保真项。</li> <li> <strong>噪声引入</strong>：\(\epsilon \sim P_0\) 的随机性模拟FM的潜在分布采样，防止 \(D_t\) 简单地将 \(\tilde{z}^n\) 映射回 \(z^n\)（若 \(\epsilon\) 与 \(z^n\) 耦合，效果会抵消，详见论文Remark 2）。</li> </ul> <h2 id="讨论">讨论</h2> <p>pnp 方法，需要知道 \(H\)，这个比较难办?</p> <h1 id="posterior-mean-rectified-flow">POSTERIOR-MEAN RECTIFIED FLOW</h1> <p>论文《Posterior-Mean Rectified Flow: Towards Minimum MSE Photo-Realistic Image Restoration》（PMRF）关注照片真实图像恢复（Photo-Realistic Image Restoration, PIR）问题，即从退化测量（如噪声、模糊图像）中重建视觉上吸引人的图像。该领域算法通常通过失真度量（如PSNR、SSIM、LPIPS）和感知质量度量（如FID、KID、NIQE）评估，目标是实现最低失真而不牺牲感知质量（即重建图像看起来自然）。 现有方法的局限性：</p> <p>后验采样（Posterior Sampling）：许多扩散或流模型（如DPS、DDS）尝试从后验分布 \(p_{X\mid Y}\) 采样，理论上可实现完美感知指数（即重建分布 \(p_{\hat{X}} = p_X\)，其中 \(p_X\) 是真实图像分布）。然而，根据Blau &amp; Michaeli (2018)，其MSE（均方误差）是无约束最小MSE（MMSE）的两倍，即 \(\mathbb{E}[\\mid X - \hat{X}\\mid ^2] = 2 \times \mathrm{MMSE}\)。 GAN+失真损失：优化失真（如MSE）和感知（如GAN）损失的加权和，可遍历失真-感知权衡曲线（Distortion-Perception Tradeoff），但GAN优化困难，尤其当感知损失权重较大时，实际性能不如后验采样。</p> <p>论文的核心动机：针对完美感知指数约束下最小化MSE的最优估计器 \(\hat{X}_0\)，定义为： \(\hat{X}_0 = \arg\min_{p_{\hat{X}\mid Y}} \mathbb{E}[\\mid X - \hat{X}\\mid ^2] \quad \mathrm{s.t.} \quad p_{\hat{X}} = p_X.\) Freirich et al. (2021)证明，\(\hat{X}_0\) 可通过先预测后验均值 \(\hat{X}^* = \mathbb{E}[X\mid Y]\)（MMSE估计），然后将其最优传输（Optimal Transport）到真实分布 \(p_X\) 来构建。该MSE通常严格小于后验采样的MSE（如图1所示）。 受此启发，PMRF提出一个简单高效算法：使用整流流（Rectified Flow）近似最优传输地图，将后验均值预测传输到高质量图像。论文通过理论分析（如Proposition 1）和实验证明，PMRF在去噪、超分辨率、补全、着色和盲面部恢复等任务中优于基线方法。 训练过程 PMRF训练分为两个阶段（见Algorithm 1），假设 \(X\) 是真实图像随机向量，\(Y\) 是退化测量。</p> <p>阶段1：后验均值预测 训练模型 \(f_\omega\) 最小化MSE损失，近似后验均值 \(\mathbb{E}[X\mid Y]\)： \(\omega^* = \arg\min_{\omega} \mathbb{E}\left[ \\mid X - f_\omega(Y)\\mid ^2 \right].\)</p> <p>此阶段可使用现成高PSNR模型跳过。 实际中，\(f_\omega\) 可为CNN或Transformer架构，优化目标是重建接近真实图像的平滑预测。</p> <p>阶段2：整流流模型训练 训练向量场 \(v_\theta\) （Rectified Flow模型），最小化流匹配损失： \(\theta^* = \arg\min_{\theta} \int_0^1 \mathbb{E}\left[ \\mid (X - Z_0) - v_\theta(Z_t, t)\\mid ^2 \right] \, dt,\) 其中：</p> <p>\(Z_t = t X + (1-t) Z_0\)，为直线路径前向过程。 \(Z_0 = f_{\omega^*}(Y) + \sigma_s \epsilon\)，\(\epsilon \sim \mathcal{N}(0, I)\)，\(\sigma_s\) 是小噪声超参数（缓解源/目标分布维数不匹配引起的奇异性）。 \(t \sim \mathcal{U}[0,1]\)。 此损失训练 \(v_\theta\) 预测从后验均值到真实图像的直线方向，近似最优传输地图。</p> <p>训练中，\(v_\theta\) 通常为U-Net架构，输入包括 \(Z_t\) 和时间 \(t\)（通过位置编码嵌入）。 推理过程 推理时，给定退化测量 \(y\)，PMRF解决ODE生成重建图像 \(\hat{x}\)： \(\frac{d \hat{Z}_t}{dt} = v_{\theta^*}(\hat{Z}_t, t), \quad \hat{Z}_0 = f_{\omega^*}(y) + \sigma_s \epsilon,\) 其中 \(\epsilon \sim \mathcal{N}(0, I)\)。 使用Euler方法离散求解（K步）：</p> <p>采样 \(\epsilon \sim \mathcal{N}(0, I)\)。 初始化 \(\hat{x} = f_{\omega^*}(y) + \sigma_s \epsilon\)。 对于 \(i = 0\) 到 \(K-1\)： \(\hat{x} \leftarrow \hat{x} + \frac{1}{K} v_{\theta^*}\left( \hat{x}, \frac{i}{K} \right).\)</p> <p>返回 \(\hat{x}\)。</p> <p>此过程从后验均值开始，通过整流流逐步“校正”到真实分布，生成低失真、高感知质量图像。论文实验显示，PMRF在CelebA-Test盲面部恢复基准上达到SOTA（如表1所示）。</p> </div> </article> <br> <hr> <br> <ul class="list-disc pl-8"></ul> <h2 class="text-3xl font-semibold mb-4 mt-12">Enjoy Reading This Article?</h2> <p class="mb-2">Here are some more articles you might like to read next:</p> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2026/Teaching-Tailored-to-Talent/">Teaching Tailored To Talent</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2025/VINS-and-ESVO2/">Vins And Esvo2</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2025/dino/">DINO 如何用于密集预测</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2025/3dtasks/">3D 任务：SFM, MVS, NVS, VO, VIO, SLAM</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2025/matplotlib%E8%BE%93%E5%87%BA%E4%B8%AD%E6%96%87/">Matplotlib输出中文</a> </li> </div> </div> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2026 Erkang Chen. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script defer src="/assets/js/bootstrap-toc.min.js?c82ff4de8b0955d6ff14f5b05eed7eb6"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>addBackToTop();</script> <script type="module" src="/assets/js/search/ninja-keys.min.js?a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script>let searchTheme=determineComputedTheme();const ninjaKeys=document.querySelector("ninja-keys");"dark"===searchTheme?ninjaKeys.classList.add("dark"):ninjaKeys.classList.remove("dark");const openSearchModal=()=>{const e=$("#navbarNav");e.hasClass("show")&&e.collapse("hide"),ninjaKeys.open()};</script> <script>const ninja=document.querySelector("ninja-keys");ninja.data=[{id:"nav-about",title:"about",section:"Navigation",handler:()=>{window.location.href="/"}},{id:"nav-blog",title:"blog",description:"",section:"Navigation",handler:()=>{window.location.href="/blog/"}},{id:"nav-publications",title:"publications",description:"publications by categories in reversed chronological order. generated by jekyll-scholar.",section:"Navigation",handler:()=>{window.location.href="/publications/"}},{id:"nav-projects",title:"projects",description:"A growing collection of your cool projects.",section:"Navigation",handler:()=>{window.location.href="/projects/"}},{id:"post-teaching-tailored-to-talent",title:"Teaching Tailored To Talent",description:"\u7b80\u8981\u4ecb\u7ecd",section:"Posts",handler:()=>{window.location.href="/blog/2026/Teaching-Tailored-to-Talent/"}},{id:"post-vins-and-esvo2",title:"Vins And Esvo2",description:"\u7b80\u8981\u4ecb\u7ecd",section:"Posts",handler:()=>{window.location.href="/blog/2025/VINS-and-ESVO2/"}},{id:"post-dino-\u5982\u4f55\u7528\u4e8e\u5bc6\u96c6\u9884\u6d4b",title:"DINO \u5982\u4f55\u7528\u4e8e\u5bc6\u96c6\u9884\u6d4b",description:"\u5982\u4f55\u4f7f\u7528DINO, DPT, RoPE",section:"Posts",handler:()=>{window.location.href="/blog/2025/dino/"}},{id:"post-3d-\u4efb\u52a1-sfm-mvs-nvs-vo-vio-slam",title:"3D \u4efb\u52a1\uff1aSFM, MVS, NVS, VO, VIO, SLAM",description:"\u591a\u89c6\u89d2\u51e0\u4f55\uff0c\u65b0\u89c6\u89d2\u751f\u6210",section:"Posts",handler:()=>{window.location.href="/blog/2025/3dtasks/"}},{id:"post-matplotlib\u8f93\u51fa\u4e2d\u6587",title:"Matplotlib\u8f93\u51fa\u4e2d\u6587",description:"\u7b80\u8981\u4ecb\u7ecd",section:"Posts",handler:()=>{window.location.href="/blog/2025/matplotlib%E8%BE%93%E5%87%BA%E4%B8%AD%E6%96%87/"}},{id:"post-mamba",title:"Mamba",description:"\u7b80\u8981\u4ecb\u7ecd",section:"Posts",handler:()=>{window.location.href="/blog/2025/mamba/"}},{id:"post-flow",title:"Flow",description:"\u7b80\u8981\u4ecb\u7ecd",section:"Posts",handler:()=>{window.location.href="/blog/2025/flow/"}},{id:"post-diffusion",title:"Diffusion",description:"\u7b80\u8981\u4ecb\u7ecd",section:"Posts",handler:()=>{window.location.href="/blog/2025/diffusion/"}},{id:"post-nerf-and-gaussian-splatting",title:"NeRF and Gaussian Splatting",description:"Gaussian Splatting, NeRF, Alpha-blending, Point-Based Rendering, Jacobian",section:"Posts",handler:()=>{window.location.href="/blog/2025/gaussianSplatting/"}},{id:"post-colmap",title:"COLMAP",description:"SFM",section:"Posts",handler:()=>{window.location.href="/blog/2025/sfm-mvs-rendering/"}},{id:"post-\u51b2\u6fc0\u4fe1\u53f7\u7684\u5c3a\u5ea6\u53d8\u6362",title:"\u51b2\u6fc0\u4fe1\u53f7\u7684\u5c3a\u5ea6\u53d8\u6362",description:"this is what included images could look like",section:"Posts",handler:()=>{window.location.href="/blog/2025/impulse/"}},{id:"post-\u4fe1\u53f7\u4e0e\u7cfb\u7edf\u8bfe\u7a0b\u7684\u6570\u5b66\u77e5\u8bc6",title:"\u4fe1\u53f7\u4e0e\u7cfb\u7edf\u8bfe\u7a0b\u7684\u6570\u5b66\u77e5\u8bc6",description:"this is what included images could look like",section:"Posts",handler:()=>{window.location.href="/blog/2025/math/"}},{id:"post-fisheye",title:"Fisheye",description:"\u7b80\u8981\u4ecb\u7ecd",section:"Posts",handler:()=>{window.location.href="/blog/2024/fisheye/"}},{id:"post-montecarlo",title:"Montecarlo",description:"\u7b80\u8981\u4ecb\u7ecd",section:"Posts",handler:()=>{window.location.href="/blog/2024/MonteCarlo/"}},{id:"post-\u5c0f\u6ce2\u5206\u6790",title:"\u5c0f\u6ce2\u5206\u6790",description:"\u7b80\u8981\u4ecb\u7ecd",section:"Posts",handler:()=>{window.location.href="/blog/2024/%E5%B0%8F%E6%B3%A2%E5%88%86%E6%9E%90/"}},{id:"post-lifeifei",title:"Lifeifei",description:"\u7b80\u8981\u4ecb\u7ecd",section:"Posts",handler:()=>{window.location.href="/blog/2024/Lifeifei/"}},{id:"post-orgmode",title:"Orgmode",description:"\u7b80\u8981\u4ecb\u7ecd",section:"Posts",handler:()=>{window.location.href="/blog/2024/orgmode/"}},{id:"post-python\u8fd0\u884c\u811a\u672c\u6216\u6a21\u5757",title:"Python\u8fd0\u884c\u811a\u672c\u6216\u6a21\u5757",description:"\u7b80\u8981\u4ecb\u7ecd",section:"Posts",handler:()=>{window.location.href="/blog/2024/Python%E8%BF%90%E8%A1%8C%E8%84%9A%E6%9C%AC%E6%88%96%E6%A8%A1%E5%9D%97/"}},{id:"post-proximal",title:"Proximal",description:"\u7b80\u8981\u4ecb\u7ecd",section:"Posts",handler:()=>{window.location.href="/blog/2024/proximal/"}},{id:"post-visualtransformer",title:"Visualtransformer",description:"\u7b80\u8981\u4ecb\u7ecd",section:"Posts",handler:()=>{window.location.href="/blog/2024/VisualTransformer/"}},{id:"post-pytorch-note",title:"Pytorch Note",description:"\u7b80\u8981\u4ecb\u7ecd",section:"Posts",handler:()=>{window.location.href="/blog/2024/Pytorch-note/"}},{id:"post-android-opencv-ndk",title:"Android Opencv Ndk",description:"\u7b80\u8981\u4ecb\u7ecd",section:"Posts",handler:()=>{window.location.href="/blog/2024/android-opencv-ndk/"}},{id:"post-repvgg",title:"Repvgg",description:"\u7b80\u8981\u4ecb\u7ecd",section:"Posts",handler:()=>{window.location.href="/blog/2024/RepVGG/"}},{id:"post-popularlibrary",title:"Popularlibrary",description:"\u7b80\u8981\u4ecb\u7ecd",section:"Posts",handler:()=>{window.location.href="/blog/2024/popularLibrary/"}},{id:"post-\u5148\u8fdb\u7684\u5b66\u4e60\u65b9\u6cd5",title:"\u5148\u8fdb\u7684\u5b66\u4e60\u65b9\u6cd5",description:"\u7b80\u8981\u4ecb\u7ecd",section:"Posts",handler:()=>{window.location.href="/blog/2024/%E5%85%88%E8%BF%9B%E7%9A%84%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/"}},{id:"post-one-stage-detection",title:"One Stage Detection",description:"\u7b80\u8981\u4ecb\u7ecd",section:"Posts",handler:()=>{window.location.href="/blog/2024/one-stage-detection/"}},{id:"post-polarization",title:"Polarization",description:"\u7b80\u8981\u4ecb\u7ecd",section:"Posts",handler:()=>{window.location.href="/blog/2024/polarization/"}},{id:"post-vae-vqvae-vagan",title:"Vae Vqvae Vagan",description:"\u7b80\u8981\u4ecb\u7ecd",section:"Posts",handler:()=>{window.location.href="/blog/2024/vae-vqvae-vagan/"}},{id:"post-multiple-object-tracking",title:"Multiple Object Tracking",description:"\u7b80\u8981\u4ecb\u7ecd",section:"Posts",handler:()=>{window.location.href="/blog/2024/Multiple-Object-Tracking/"}},{id:"post-\u77e9\u9635",title:"\u77e9\u9635",description:"Matrix",section:"Posts",handler:()=>{window.location.href="/blog/2024/Matrix/"}},{id:"post-typora-and-jekyll",title:"Typora and Jekyll",description:"this is what included images could look like",section:"Posts",handler:()=>{window.location.href="/blog/2024/images/"}},{id:"news-a-simple-inline-announcement",title:"A simple inline announcement.",description:"",section:"News"},{id:"news-a-long-announcement-with-details",title:"A long announcement with details",description:"",section:"News",handler:()=>{window.location.href="/news/announcement_2/"}},{id:"news-a-simple-inline-announcement-with-markdown-emoji-sparkles-smile",title:'A simple inline announcement with Markdown emoji! <img class="emoji" title=":sparkles:" alt=":sparkles:" src="https://github.githubassets.com/images/icons/emoji/unicode/2728.png" height="20" width="20"> <img class="emoji" title=":smile:" alt=":smile:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f604.png" height="20" width="20">',description:"",section:"News"},{id:"projects-project-1",title:"project 1",description:"with background image",section:"Projects",handler:()=>{window.location.href="/projects/1_project/"}},{id:"projects-project-2",title:"project 2",description:"a project with a background image and giscus comments",section:"Projects",handler:()=>{window.location.href="/projects/2_project/"}},{id:"projects-project-3-with-very-long-name",title:"project 3 with very long name",description:"a project that redirects to another website",section:"Projects",handler:()=>{window.location.href="/projects/3_project/"}},{id:"projects-project-4",title:"project 4",description:"another without an image",section:"Projects",handler:()=>{window.location.href="/projects/4_project/"}},{id:"projects-project-5",title:"project 5",description:"a project with a background image",section:"Projects",handler:()=>{window.location.href="/projects/5_project/"}},{id:"projects-project-6",title:"project 6",description:"a project with no image",section:"Projects",handler:()=>{window.location.href="/projects/6_project/"}},{id:"projects-project-7",title:"project 7",description:"with background image",section:"Projects",handler:()=>{window.location.href="/projects/7_project/"}},{id:"projects-project-8",title:"project 8",description:"an other project with a background image and giscus comments",section:"Projects",handler:()=>{window.location.href="/projects/8_project/"}},{id:"projects-project-9",title:"project 9",description:"another project with an image \ud83c\udf89",section:"Projects",handler:()=>{window.location.href="/projects/9_project/"}},{id:"socials-email",title:"Send email",section:"Socials",handler:()=>{window.open("mailto:%63%65%6B%78%6D@%71%71.%63%6F%6D","_blank")}},{id:"socials-google-scholar",title:"Google Scholar",section:"Socials",handler:()=>{window.open("https://scholar.google.com/citations?user=hWo1RTsAAAAJ","_blank")}},{id:"light-theme",title:"Change theme to light",description:"Change the theme of the site to Light",section:"Theme",handler:()=>{setThemeSetting("light")}},{id:"dark-theme",title:"Change theme to dark",description:"Change the theme of the site to Dark",section:"Theme",handler:()=>{setThemeSetting("dark")}},{id:"system-theme",title:"Use system default theme",description:"Change the theme of the site to System Default",section:"Theme",handler:()=>{setThemeSetting("system")}}];</script> <script src="/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> </body> </html>