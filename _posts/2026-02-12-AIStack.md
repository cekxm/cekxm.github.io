---
layout: post
title: "AI Stack"
date: 2026-02-12 10:56:54 +0800
categories: []
description: LLM, Agent, Diffusion, JEPA, world model, SSM
tags: 
thumbnail: 
toc:
  sidebar: left
typora-root-url: ../
---

## AI Stack
**AI 正在从“会聊天的幻觉机器（LLM）”进化为“懂物理规律的系统化大脑（AI Stack）”**。

### 1. 为什么“经典 LLM”已经不够用了？
材料指出，传统的 LLM（如 GPT 系列）虽然强大，但存在本质缺陷：
- **预测的是字词（Tokens），而非现实：** 它们在学习概率分布，而不是理解物理世界的运行逻辑。
- **缺乏“世界模型”：** 它们无法进行长期规划、自主决策或处理复杂的因果关系。
- **单体局限：** 真正的智能无法仅存在于一个模型中，而应是一个系统。

### 2. 核心范式转移：从语言模型到世界模型
AI 架构正在经历从“文本预测”向“现实建模”的跨越：
- **目标转变：** 从**预测 Token** 转向 **预测潜在语义（Latent Meaning）**。
- **本质转变：** 从**语言建模（Language Modeling）** 转向 **世界建模（World Modeling）**。
- **形态转变：** AI 不再是一个单纯的模型，而是一个由多个组件构成的**系统（System）**。

### 3. 未来 AI Stack 的 6 大架构支柱
材料提出了构建未来智能系统的六个核心家族：
1. **世界模型（World Models）：** 学习现实世界的运行规律。
2. **JEPA (联合嵌入预测架构)：** 学习事物的“意义”和特征，而非死磕像素。
3. **重新定义的扩散模型（Diffusion Models）：** 不再只画图，而是用于**规划和动作生成**。
4. **推理模型（Reasoning Models）：** 负责抽象思维、解释和系统编排。
5. **状态空间模型（SSM）：** 提供更高效的实时处理能力。
6. **智能体架构（Agent Architectures）：** 通过系统间的交互实现复杂的任务目标。

### 4. 统一的智能堆栈（Unified AI Stack）
未来的 AI 智能将由以下模块协同产生，而不再是“一个对话框”：
> **感知 $$\rightarrow$$ 世界理解 $$\rightarrow$$ 预测 $$\rightarrow$$ 规划 $$\rightarrow$$ 推理 $$\rightarrow$$ 动作（工具、API、智能体）**


### 5. 展望 2026：AI 的终局
- **单模型时代结束：** 模块化、智能体化（Agentic）的系统是必然趋势。
- **形态演变：** 到 2026 年，AI 的运作方式将**更像生物大脑**，而非简单的聊天机器人。
- **智能的本质：** 智能是一个堆栈（Stack），而不仅仅是对话。

## OpenClaw
OpenClaw（曾用名 Clawdbot / Moltbot）在 2026 年被视为“具身智能（Embodied AI）”在数字操作系统层面的代表作。它的构架设计体现了从“聊天机器人”向“自主系统”转化的核心思路。
根据最新的技术文档和社区实践，OpenClaw 的构架可以被拆解为以下六层体系：

### 1. 核心构架六层模型
OpenClaw 并不是一个简单的程序，而是一个高度模块化的**智能体运行时（Agent Runtime）**：
- **网关层 (Gateway):** 系统的“感官与通道”。作为一个长驻后台的 TypeScript 进程，它负责连接 WhatsApp、Telegram、Discord 等消息平台，处理消息的流入（Ingress）与流出（Egress）。
- **路由与会话层 (Routing & Sessions):** 负责多用户/多任务管理，决定哪一个智能体实例或会话历史应该响应当前的指令。
- **智能体运行时 (Agent Runtime):** 系统的“中枢神经”。它接收上下文（系统提示词 + 历史记录 + 附件），调用底层模型，并处理模型的工具调用（Tool Call）请求。
- **大脑与模型解析器 (Brain & Model Resolver):** 模型中立（Model-agnostic）层。它可以根据任务复杂度自动路由：简单任务用本地 Llama 4，复杂推理用云端 Claude 4.5。
- **技能与工具集 (Skills & Tools):** 系统的“手脚”。包括网页爬虫、文件管理、Shell 执行等。它支持 **MCP (Model Context Protocol)** 协议，使其能无缝接入全球开发者贡献的工具服务器。
- **交互界面 (Surfaces):** 用户接触点，包括命令行（CLI）、Web 仪表盘及各类聊天 App。

### 2. 关键技术组件
OpenClaw 的卓越稳定性源于其内部的几个核心组件：
| **组件名称**              | **功能描述**                                         | **核心价值**                                           |
| - | ---- |  |
| **Lane Queue (车道队列)** | 强制所有执行动作进入串行队列。                       | 防止多个动作竞争导致的系统死锁或逻辑冲突。             |
| **Docker Sandbox**        | 所有的文件读写和 Shell 脚本都在 Docker 容器中执行。  | **安全隔离**，即便 AI 误操作也不会格式化用户的宿主机。 |
| **双层记忆系统**          | JSONL 原始日志 + Markdown 提炼记忆 (`MEMORY.md`)。   | 兼顾了“事实审计”与“长程经验总结”的平衡。               |
| **Semantic Snapshots**    | 网页浏览时只解析“可访问性树（Accessibility Tree）”。 | 极大地降低了 Token 消耗，比直接识别截图更精准。        |

### 3. 工作流程：从感知到执行
当你在 WhatsApp 上发一句“帮我把最近三封邮件汇总并存入 Notion”时，OpenClaw 内部会经历以下循环：
1. **感知 (Perception):** Gateway 捕获消息，将其归一化为标准的事件格式。
2. **规划 (Planning):** 智能体运行时结合 **Memory** 检索相关上下文，由 **Brain** 拆解为：`List Emails` $$\rightarrow$$ `Summarize` $$\rightarrow$$ `Write Notion`。
3. **预测与决策 (Prediction):** 通过 **Prompt Builder** 组装工具调用指令。
4. **沙盒执行 (Action):** 在 **Sandbox** 中安全运行脚本，并通过 **MCP** 协议与外部 API 通信。
5. **反馈 (Feedback):** 如果执行失败，Lane Queue 会触发重试逻辑或向用户报错。

## MCP 协议
MCP（Model Context Protocol，模型上下文协议）是 OpenClaw 这种 Agent 能够快速“进化”出各种能力的核心秘密。你可以把 MCP 想象成 AI 界的 **“通用 USB 接口”**。
在 OpenClaw 的架构中，它通过 **MCP 客户端（Client）** 的身份，与无数个独立的 **MCP 服务器（Server）** 通信。以下是它扩展插件的具体运作机制：

### 1. “客户端-服务器”架构：能力的解耦
OpenClaw 本身不需要知道如何查天气、如何读 SQL 数据库或如何搜索网页。
- **OpenClaw (Client):** 负责与模型（如 Claude 4）对话。它告诉模型：“我有这些工具，你可以用。”
- **MCP Servers (Plugins):** 这是一个个独立运行的微型程序。比如，有一个专门负责 Google 搜索的服务器，另一个负责管理本地 Notion 的服务器。
- **连接方式：** OpenClaw 通过标准化的 JSON-RPC 协议与这些服务器通信。

### 2. 插件扩展的三个核心维度
通过 MCP，OpenClaw 可以从服务器那里“继承”三种能力：
1. **Resources（资源）:** 允许模型**读取数据**。比如，一个 MCP 插件可以把你的本地 GitHub 仓库变成模型可以直接读取的资源。
2. **Tools（工具）:** 允许模型**执行动作**。比如，模型调用 `execute_python` 或 `create_linear_ticket` 这样的命令。
3. **Prompts（提示词模版）:** 插件可以提供预设的指令模版，告诉模型如何更好地处理特定任务（如“以资深架构师的身份审核这段代码”）。

### 3. 插件的“发现”与调用流程
当你在 OpenClaw 中配置了一个新的 MCP 插件（例如 `mcp-server-google-search`）后，会发生以下过程：
- **第一步：动态握手（Discovery）**
  OpenClaw 启动时，会询问 MCP 服务器：“你能干什么？”服务器返回一份清单（JSON 格式），包含工具名、描述和参数定义。
- **第二步：能力注入**
  OpenClaw 把这份清单“塞”进发给 LLM 的 System Prompt 中。现在模型知道：“原来我可以搜索 Google，只需要输出特殊的 `call_tool` 指令。”
- **第三步：安全执行（Execution）**
  如果模型决定搜索，它会发出请求。OpenClaw 接收到请求，转发给本地运行的 MCP 搜索服务器。服务器去执行搜索，再把结果返回给 OpenClaw，最后转给模型。

### 4. 为什么这对开发者来说是“杀手锏”？
- **语言无关性：** 你可以用 Python 写一个处理图像的插件，用 Rust 写一个读数据库的插件。只要它们符合 MCP 协议，OpenClaw 就能直接用。
- **生态复用：** 既然 MCP 是 Anthropic 推动的标准，OpenClaw 可以直接复用社区里现成的数千个 MCP 插件（比如官方提供的文件系统服务器、SQL 服务器等），而不需要自己重写。
- **安全隔离：** MCP 服务器通常运行在独立的进程中。这意味着即便一个复杂的数据库插件崩溃了，也不会导致 OpenClaw 的主进程崩溃。
