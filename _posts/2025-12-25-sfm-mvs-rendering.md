---
layout: post
title: "SFM MVS Rendering"
date: 2025-12-25 20:25:10 +0800
categories: []
description: 简要介绍
tags: 
thumbnail: 
toc:
  sidebar: left # or right
typora-root-url: ../
---

## 资源

1. https://www.youtube.com/watch?v=diBxFGgqAT0
2. https://mashaan14.github.io/YouTube-channel/nerf/2025_01_25_sfm

这个资源解释了 SFM，two view Geometry. 结合camera_and_stereo.pdf 进行理解。

## 多视角几何（MVS），新视角生成（NVS）对比

<img src="/images/2025-12-25-sfm-mvs-rendering/d3dcd8d3-35cb-403b-998d-64256b21ba06.png" alt="drawings-02 001" style="zoom:50%;" />



简而言之：**(MVS)SfM** 是传统的“几何尺子”；**VGGT** 是现代的“几何大模型”；而 **NVS** 是“虚拟照相机”。

### (MVS)SfM vs. VGGT vs. NVS (NeRF/GS) 综合对比表

| **维度**         | **(MVS) SfM (如 COLMAP)**                                    | **VGGT (Visual Geometry Grounded Transformer)**              | **NVS (NeRF / 3D GS)**                                       |
| ---------------- | ------------------------------------------------------------ | ------------------------------------------------------------ | ------------------------------------------------------------ |
| **核心任务目标** | **三维重建**：求解精确的相机姿态和场景几何（点云/深度）。    | **统一几何推断**：一站式、秒级预测相机、点图、深度图和追踪。 | **新视角合成**：在未拍摄过的角度生成照片级逼真的图像。       |
| **底层表示**     | **离散几何**：稀疏或稠密的 3D 点云、深度图。                 | **稠密几何图**：Point Maps ($$H \times W \times 3$$) 和 Depth Maps。 | **光场表示**：NeRF 使用 MLP（隐式）；GS 使用高斯球（显式）。 |
| **运行机制**     | **优化驱动**：基于特征匹配 + 束调整 (Bundle Adjustment) 迭代求解。 | **前馈推理 (Feed-forward)**：一次性通过 Transformer 模型直接“看”出几何。 | **视图对齐优化**：通过渲染结果与原图的颜色误差来反向训练。   |
| **对相机的需求** | **未知或已知**：通常用于解算未知相机参数。                   | **无需预设**：直接预测相机的 9 维参数（内外参）。            | **必须已知**：通常依赖 SfM (COLMAP) 提供位姿初始化。         |
| **几何精确度**   | **高（度量级）**：数学推导严谨，但易受弱纹理、模糊影响。     | **高且鲁棒**：利用 DINOv2 先验，在挑战性场景下比传统方法更稳。 | **中/低**：主要优化视觉效果，几何结构往往存在“漂浮物”或误差。 |
| **渲染视觉效果** | **差**：只有离散点，无法生成连续、真实的图像。               | **中**：提供稠密几何，但主要用于几何任务而非美学渲染。       | **极高**：支持照片级渲染、阴影、反射和透明效果。             |
| **处理速度**     | **极慢**：通常需要数分钟到数小时。                           | **极快**：全流程通常在 **1 秒以内**。                        | **训练慢/渲染快**：NeRF 训练慢，GS 渲染极快，但都需要初始化。 |

------

## COLMAP

![image](/images/2025-12-25-sfm-mvs-rendering/35285f8e-982b-4ad8-96f7-1c4c5d09b5c7.png)

在 COLMAP 的三维重建流水线中，**BA（Bundle Adjustment，捆绑调整）** 是最核心的优化环节。它的基本原理是通过**非线性最小二乘法**，同时优化相机的姿态、内参以及三维点的坐标，从而使重建结果达到最高的几何一致性。

------

### 1. BA 的数学原理

BA 的本质是一个**重投影误差（Reprojection Error）**最小化问题。

### 重投影误差公式

假设我们有 $$n$$ 个三维点 $$X_j$$ 和 $$m$$ 张图像。对于每一张图像 $$i$$ 和它观察到的点 $$j$$，其观测到的像素坐标为 $$x_{ij}$$。而根据当前估计的相机姿态 $$R_i, t_i$$、内参 $$K_i$$ 和点 $$X_j$$ 计算出的**理论投影坐标**为 $$\hat{x}_{ij} = \pi(K_i, R_i, t_i, X_j)$$。

BA 的目标函数可以表示为：



$$\min_{K_i, R_i, t_i, X_j} \sum_{i=1}^m \sum_{j=1}^n \rho \left( \| x_{ij} - \pi(K_i, R_i, t_i, X_j) \|^2 \right)$$

- **$$\pi$$**：投影函数（将 3D 点映射到 2D 像素平面）。
- **$$\| x_{ij} - \hat{x}_{ij} \|^2$$**：重投影误差。
- **$$\rho$$**：鲁棒核函数（如 Huber loss），用于减少外点（错误匹配）对优化的干扰。

### 优化算法

由于投影方程是非线性的，COLMAP 调用 **Ceres Solver** 库，使用 **Levenberg-Marquardt (LM)** 算法进行迭代求解。

------

### 2. BA 在 COLMAP 中的作用

BA 贯穿于 COLMAP 的增量式重建（Incremental SfM）全过程，主要起到以下作用：

- **消除累积误差（去漂移）**：在逐张添加图像的过程中，误差会不断累积。BA 能够通过全局约束，将这些微小的误差平摊，防止模型“弯曲”或“变形”。
- **精细化参数**：初始的相机姿态通常由 PnP 算法得到，三维点坐标由三角化得到。BA 能够将这些“毛坯”数据进一步精细化，提高点云的精度。
- **自标定（Self-Calibration）**：如果相机内参未知或不准，BA 可以通过优化过程自动校正焦距（Focal Length）和畸变参数。
- **剔除外点**：在 BA 优化后，重投影误差依然很大的点会被视为无效点（Outliers）并被剔除，从而保证重建的鲁棒性。

------

### 3. COLMAP 中的两种 BA 策略

为了平衡计算速度和精度，COLMAP 将 BA 分为两个级别：

| **类型**                | **触发时机**           | **优化范围**                         | **目的**                                       |
| ----------------------- | ---------------------- | ------------------------------------ | ---------------------------------------------- |
| **局部 BA (Local BA)**  | 每注册一张新图像后     | 当前图像及其邻近图像、可见的三维点   | 确保新加入的图像能够稳定地融合进当前模型。     |
| **全局 BA (Global BA)** | 模型增长达到一定比例时 | **所有**已注册的图像、**所有**三维点 | 消除全局漂移，确保整个场景的几何结构严丝合缝。 |

### 4. 估计的 $$K, R, t, X$$ 是作为 BA 的初值吗？

**是的。** BA 本质上是一个**非线性优化**过程，非线性优化必须依赖一个合理的**初始值**（Initial Guess）才能收敛到全局最优解，否则很容易陷入局部极小值。

在 COLMAP 的增量式重建流程中，这些初值的来源如下：

- **相机姿态 ($$R, t$$)**：通过 **PnP (Perspective-n-Point)** 算法获得。当一张新图像被注册到现有模型时，系统利用已有的 3D 点和该图像中的 2D 特征匹配点，计算出该图像的位姿。
- **三维点坐标 ($$X$$)**：通过 **三角化 (Triangulation)** 获得。利用多张图像的相机中心和匹配特征射线的交点来估计点的空间位置。
- **内参 ($$K$$)**：通常来源于图像的 **EXIF 信息**（如焦距）或预设的相机模型。在 BA 过程中，这些参数可以被进一步精细化。

**一句话总结：** PnP 和三角化为 BA 提供了“毛坯”模型，而 BA 负责“精加工”。

------

### 5. BA 是逐一优化还是同时优化？

BA 是**同时优化（Joint Optimization）**所有参数的。这意味着在同一个优化循环中，相机参数和三维点坐标是同时更新的。

#### 为什么要同时优化？

如果采用“逐一优化”（先固定点优化相机，再固定相机优化点），模型收敛速度会极慢，且容易陷入死循环或无法达到全局最优，这种方法被称为“坐标下降法”。

#### 使用的数学技巧：舒尔补 (Schur Complement)

由于 BA 涉及成千上万个三维点和数百个相机位姿，直接求逆巨大的海森矩阵（Hessian Matrix）在计算上是不可行的。为了实现高效的**同时优化**，COLMAP（通过其背后的 **Ceres Solver**）使用了一个核心数学技巧：**利用稀疏结构的舒尔补（Schur Complement）**。

#### 核心步骤：

1. 稀疏性分析：

   在 BA 中，一个 3D 点的投影只与观察到它的相机有关，与其他点无关；同样，一个相机的残差只与它看到的点有关。这导致其对应的正态方程（Normal Equations）具有极其显著的块稀疏结构。

   $$\begin{bmatrix}  B & E \\  E^T & C  \end{bmatrix}  \begin{bmatrix}  \Delta x_c \\  \Delta x_p  \end{bmatrix}  =  \begin{bmatrix}  v \\  w  \end{bmatrix}$$

   其中 $$B$$ 是相机参数块，$$C$$ 是三维点参数块（它是对角块矩阵，求逆非常快）。

2. 边缘化（Marginalization）：

   利用舒尔补将三维点块 $$C$$ 消去，得到一个只包含相机参数的缩减相机系统（Reduced Camera System）：

   

   $$(B - EC^{-1}E^T) \Delta x_c = v - EC^{-1}w$$

   

   这个矩阵的维度大大降低（仅取决于相机的数量），求解出相机的增量 $$\Delta x_c$$ 后，再通过代回（Back-substitution）快速算出所有点的增量 $$\Delta x_p$$。

#### 其他关键技术：

- **Levenberg-Marquardt (LM) 算法**：一种介于高斯-牛顿法和梯度下降法之间的信赖域方法，保证了在远离最优解时也能稳健收敛。
- **鲁棒核函数 (Robust Loss)**：如 Huber 或 Cauchy 损失，用来自动降低那些误匹配点（Outliers）在优化中的权重，防止它们带偏整个模型。

在 COLMAP 的流水线中，参与 BA 的图像数量并不是一个固定值，它取决于**你所处的重建阶段**以及**场景的规模**。

COLMAP 作为一种**增量式 SfM（Incremental SfM）**工具，它通过两种不同规模的 BA 来平衡精度和效率：

### 6. 局部 BA (Local Bundle Adjustment)

- **图像数量：通常为 10 到 30 张左右。**
- **原理：** 每当 COLMAP 成功注册（添加）一张新图像并进行三角化后，它不会立即对全场进行优化（太慢了），而是执行一次局部 BA。
- **范围：** 仅包含**当前图像及其在共视图中最近的邻居图像**。
- **作用：** 确保新加入的图像能够正确地锚定在现有模型上，防止局部结构发生剧烈畸变。

### 7. 全局 BA (Global Bundle Adjustment)

- **图像数量：所有已注册的图像（从几十张到上万张不等）。**
- **原理：** 当模型增长到一定程度（例如图像数量增加了 10%，或者达到了特定的步长），COLMAP 会触发全局 BA。
- **范围：** 优化当前已成功进入模型的所有相机位姿和所有 3D 点。
- **规模示例：**
  - **小型物体：** 50 - 200 张图像。
  - **中型场景（如建筑）：** 500 - 2,000 张图像。
  - **大型城市/测绘：** 5,000 - 10,000+ 张图像。
- **作用：** 消除长时间增量重建积累的“漂移”误差，确保模型整体的闭环精度。

------

### 8. 影响参与 BA 图像数量的瓶颈

虽然理论上可以有成千上万张图像参与 BA，但实际操作中受以下因素限制：

1. **内存（RAM）与显存：**
   - BA 需要构建庞大的 Jacobi 矩阵。虽然有“舒尔补”技巧减小计算量，但当图像超过 **2,000-3,000 张**时，对内存的需求会显著增加。
   - COLMAP 默认使用 **Ceres Solver**，如果内存不足，BA 可能会失败或运行极其缓慢。
2. **计算时间：**
   - 全局 BA 是 SfM 中最耗时的部分。对于上万张图的场景，一次全局 BA 可能需要几小时甚至更久。
3. **连接性（Connectivity）：**
   - 如果图像之间没有共同的特征点（即没有“边”连接），这些图像就不会在同一个 BA 块中被优化。COLMAP 会将它们拆分成不同的子模型（Sub-models）。

## 研究方向

在 2025 年的时间节点上，**Novel View Synthesis (NVS)** 在学术热度和资本市场显然更“火”，但 **Multi-View Stereo (MVS)** 作为底层基石，正在经历从“传统算法”向“几何大模型”的深刻转型。

这两者并非孤立竞争，而是呈现出一种**深度融合**的趋势。以下是从热门程度、技术前景和应用价值三个维度的详细对比：

------

### 1. 热门程度：Novel View Synthesis (NVS) 占据 C 位

**核心技术：3D Gaussian Splatting (3DGS), NeRF, Generative 3D**

- **学术热度：** 2024-2025 年，视觉顶级会议（CVPR, ICCV）中关于 **3DGS (3D 高斯溅射)** 和 **生成式新视角合成** 的论文数量呈爆炸式增长。
- **AIGC 助力：** 随着视频生成模型（如 Sora, Kling）的爆发，如何从单张图或一段视频生成可交互的 3D 场景（即 **Generative NVS**）成了最热门的方向。
- **用户感知度：** NVS 能生成“照片级”的视觉效果，普通人一眼就能看出好坏，因此在 VR/AR、数字孪生、影视特效领域极具吸引力。

### 2. 发展前景：MVS 正在向“几何大模型”进化

**核心技术：VGGT, MVSNet 系列, Foundation Models for Geometry**

- **从“工具”到“大脑”：** 传统的 MVS（如 COLMAP）依赖复杂的数学优化。2025 年的趋势是像 **VGGT** 这样，利用大规模预训练（如 DINOv2）将 MVS 变成一个**前馈网络（Feed-forward）**。
- **解决“不可能任务”：** 传统的 MVS 在面对弱纹理（白墙）、反光（玻璃）时会失败。2025 年的发展方向是利用先验知识（Priors）来预测这些区域的几何。
- **工业刚需：** 无论 NVS 渲染得多么好看，自动驾驶、无人机导航、工业精密测量、建筑 BIM 仍然需要 MVS 提供的**精确绝对坐标（Metric Geometry）**。

------

### 3. 2025 年的关键趋势：两者边界的模糊（融合）

如果你在考虑职业发展或研究方向，**“几何感知的 NVS” (Geometry-aware NVS)** 是 2025 年最具前景的方向。

1. **MVS 为前，NVS 为后：** 就像您之前提到的，用 VGGT（MVS 思路）快速初始化几何，再用 3DGS（NVS 思路）进行精修和渲染。这是目前 3D 重建最前沿的 Pipeline。
2. **可推广性 (Generalizability)：** 以前的 NeRF/GS 需要针对每个场景单独训练。2025 年的突破点在于 **LRM (Large Reconstruction Models)**，即输入几张图，模型直接秒级输出可渲染的 3D 表示，这背后本质上是 MVS 与生成式架构的结合。
3. **动态场景：** 静态场景的重建基本解决，2025 年的蓝海是**动态 4D 重建**（例如重建一个正在运动的人或动物），这同时需要 MVS 的点追踪（Point Tracking）能力和 NVS 的实时渲染能力。

------

### 总结建议

- **如果你追求“视觉震撼”和“快速产出”：** 选择 **Novel View Synthesis (尤其是 3DGS)**。这是目前 AIGC 落地最快的方向，适合互联网、游戏、广告和元宇宙行业。
- **如果你追求“底层技术”和“稳健性”：** 选择 **MVS/几何大模型**。这是 3D 视觉的根基。虽然它可能没有渲染图那么惊艳，但在自动驾驶、机器人和空间计算领域，它的不可替代性极高。
- **最具潜力的路径：** 研究**如何将 MVS 的几何约束引入 NVS**（例如 VGGT 的思路）。这种既有“精确骨架（MVS）”又有“华丽皮肤（NVS）”的技术架构，是 2025 年 3D 视觉的终极答案。

**结论：** **NVS 更“热门”（Hotter）**，但 **MVS 的“底座”地位在 2025 年因大模型的介入而重新变得极具“前景”（More Promising）**。